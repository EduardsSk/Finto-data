{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#!/usr/bin/env python3\n",
    "\n",
    "from rdflib import Graph, Namespace, URIRef, BNode, Literal, RDF\n",
    "from rdflib.namespace import SKOS, XSD, OWL, DC\n",
    "from rdflib.namespace import DCTERMS as DCT\n",
    "from SPARQLWrapper import SPARQLWrapper, SPARQLExceptions\n",
    "from pymarc import Record, Field, XMLWriter, MARCReader\n",
    "import xml.etree.ElementTree as ET\n",
    "import shutil\n",
    "\n",
    "import argparse\n",
    "import unicodedata\n",
    "from configparser import ConfigParser, ExtendedInterpolation\n",
    "import sys\n",
    "import logging\n",
    "from datetime import datetime, date\n",
    "import subprocess\n",
    "import urllib\n",
    "from collections import namedtuple, Sequence\n",
    "from html.parser import HTMLParser\n",
    "\n",
    "# globaalit muuttujat\n",
    "CONVERSION_PROCESS = \"Finto SKOS to MARC 0.80\"\n",
    "CONVERSION_URI = \"https://www.kiwi.fi/x/XoK6B\" # konversio-APIn uri tai muu dokumentti, jossa kuvataan konversio\n",
    "CREATOR_AGENCY = \"FI-NL\" # Tietueen luoja/omistaja & luetteloiva organisaatio, 003 & 040 kentat\n",
    "\n",
    "DEFAULTCREATIONDATE = \"1980-01-01\"\n",
    "KEEPDEPRECATEDAFTER = \"ALL\"\n",
    "ENDPOINT_ADDRESS = \"http://api.dev.finto.fi/sparql\"\n",
    "ENDPOINTGRAPHS = [] # palvelupisteen graafien osoitteet, jotka ladataan läpikäytäviin muihin graafeihin\n",
    "IGNOREOTHERGRAPHWARNINGS = False # lokitetaanko virheet muissa, kuin prosessoitavassa graafissa\n",
    "NORMALIZATION_FORM = \"NFD\" # käytetään UTF8-merkkien dekoodauksessa\n",
    "\n",
    "YSO=Namespace('http://www.yso.fi/onto/yso/')\n",
    "YSOMETA=Namespace('http://www.yso.fi/onto/yso-meta/')\n",
    "YSOPAIKATGRAPH=Namespace(\"http://www.yso.fi/onto/yso-paikat/\")\n",
    "YSA=Namespace('http://www.yso.fi/onto/ysa/')\n",
    "YSAMETA=Namespace('http://www.yso.fi/onto/ysa-meta/')\n",
    "ALLARS=Namespace('http://www.yso.fi/onto/allars/')\n",
    "ALLARSMETA=Namespace(\"http://www.yso.fi/onto/allars-meta/\")\n",
    "KOKO=Namespace('http://www.yso.fi/onto/koko/')\n",
    "LCSH=Namespace(\"http://id.loc.gov/authorities/subjects/\")\n",
    "LCGF=Namespace(\"http://id.loc.gov/authorities/genreForms/\")\n",
    "RDAU=Namespace('http://rdaregistry.info/Elements/u/')\n",
    "ISOTHES=Namespace('http://purl.org/iso25964/skos-thes#')\n",
    "SKOSEXT=Namespace('http://purl.org/finnonto/schema/skosext#')\n",
    "SLM=Namespace(\"http://urn.fi/URN:NBN:fi:au:slm:\")\n",
    "UDC=Namespace(\"http://udcdata.info/\")\n",
    "\n",
    "LANGUAGES = {\n",
    "    'fi': 'fin',\n",
    "    'sv': 'swe',\n",
    "    'en': 'eng',\n",
    "    'de': 'ger',\n",
    "    'et': 'est',\n",
    "    'fr': 'fre',\n",
    "    'it': 'ita',\n",
    "    'ru': 'rus',\n",
    "#    'se': 'sme', # pohjoissaami\n",
    "    'sme': 'sme', # pohjoissaami\n",
    "    'sma': 'sma', # etalasaami\n",
    "    'smn': 'smn', # inarinsaami,\n",
    "    'sms': 'sms', # koltansaami,\n",
    "    'smj': 'smj', # luulajansaami\n",
    "}\n",
    "\n",
    "#LCSH mäpättävät 1xx-kentät\n",
    "LCSH_1XX_FIELDS = [\"100\", \"110\", \"111\", \"130\", \"147\", \"148\", \"150\", \"151\", \"155\", \"162\", \"180\", \"181\", \"182\", \"185\"]\n",
    "\n",
    "TRANSLATIONS = {\n",
    "    SKOSEXT.partOf: {\n",
    "        \"fi\": \"osa kokonaisuutta/käsitettä\",\n",
    "        \"sv\": \"är en del av\",\n",
    "        \"en\": \"is part of\"\n",
    "    },\n",
    "    \"682iDEFAULT\": {\n",
    "        \"fi\": \"Käytöstä poistetun termin korvaava termi\",\n",
    "        \"sv\": \"Termen som ersättar den avlagda termen\",\n",
    "        \"en\": \"Term replacing the deprecated term\"\n",
    "    },\n",
    "    \"688aCREATED\": {\n",
    "        \"fi\": \"Luotu\",\n",
    "        \"sv\": \"Skapad\",\n",
    "        \"en\": \"Created\"\n",
    "    },\n",
    "    \"688aMODIFIED\": {\n",
    "        \"fi\": \"Viimeksi muokattu\",\n",
    "        \"sv\": \"Senast editerad\",\n",
    "        \"en\": \"Last modified\"\n",
    "    }\n",
    "}\n",
    "\n",
    "# arvot tulevat osakentan $w 1. merkkipaikkaan\n",
    "SEEALSOPROPS = {\n",
    "    SKOS.broader : 'g',\n",
    "    SKOS.narrower : 'h',\n",
    "    SKOS.related : 'n',\n",
    "    RDAU.P60683 : 'a',\n",
    "    RDAU.P60686 : 'b',\n",
    "    SKOSEXT.partOf : 'i',\n",
    "    ISOTHES.broaderPartitive : \"g\",\n",
    "    ISOTHES.narrowerPartitive : \"h\"\n",
    "}\n",
    "\n",
    "SORT_5XX_W_ORDER = {\n",
    "    'g': '001',\n",
    "    'h': '002',\n",
    "    'n': '003',\n",
    "    'i': '004',\n",
    "    'a': '005',\n",
    "    'b': '006'\n",
    "}\n",
    "\n",
    "#katso-viittauksen kentän tyyppi - selite\n",
    "TERMGROUP = {\n",
    "    SKOS.altLabel: {\n",
    "        \"fi\": \"ohjaustermi\",\n",
    "        \"sv\": \"hänvisningsterm\",\n",
    "        \"en\": \"entry term\"\n",
    "    },\n",
    "    SKOS.hiddenLabel: {\n",
    "        \"fi\": \"piilotermi\",\n",
    "        \"sv\": \"dold term\",\n",
    "        \"en\": \"hidden term\"\n",
    "    },\n",
    "    YSOMETA.singularPrefLabel: {\n",
    "        \"fi\": \"käytettävän termin yksikkömuoto\",\n",
    "        \"sv\": \"föredragen term i singular\",\n",
    "        \"en\": \"singular entry term\"\n",
    "    },\n",
    "    YSOMETA.singularAltLabel: {\n",
    "        \"fi\": \"ohjaustermin yksikkömuoto\",\n",
    "        \"sv\": \"hänvisningsterm term i singular\",\n",
    "        \"en\": \"singular entry term\"\n",
    "    }\n",
    "}\n",
    "\n",
    "# paikka 5, 'n' = uusi, 'c' = muuttunut/korjattu, d = poistettu (ei seuraajia), x = 1 seuraaja, s = >= 2 seuraajaa\n",
    "LEADERNEW = '00000nz  a2200000n  4500'\n",
    "LEADERCHANGED = '00000cz  a2200000n  4500'\n",
    "LEADERDELETED0 = '00000dz  a2200000n  4500'\n",
    "LEADERDELETED1 = '00000xz  a2200000n  4500'\n",
    "LEADERDELETED2 = '00000sz  a2200000n  4500'\n",
    "\n",
    "CATALOGCODES = '|n|anznnbabn           | ana      '\n",
    "CATALOGCODES_NA = '|n|enznnbbbn           | ana      '\n",
    "\n",
    "GROUPINGCLASSES = [ISOTHES.ConceptGroup, ISOTHES.ThesaurusArray, SKOS.Collection]\n",
    "\n",
    "# tuple helpottamaan getValues-apufunktion arvojen käsittelyä\n",
    "ValueProp = namedtuple(\"ValueProp\", ['value', 'prop'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# apufunktiot\n",
    "\n",
    "def readCommandLineArguments():\n",
    "    parser = argparse.ArgumentParser(description=\"Program for converting Finto SKOS-vocabularies into MARC (.mrcx).\")\n",
    "    parser.add_argument(\"-c\", \"--config\",\n",
    "        help=\"Config file location. The key/value pairs defined in the config file are overwritten with possible CLI key/value pairs.\")\n",
    "    parser.add_argument(\"-cs\", \"--config_section\",\n",
    "        help=\"Config section identifier. Set if vocabulary code is different from section identifier.\")    \n",
    "    parser.add_argument(\"-e\", \"--endpoint\", help=\"Endpoint address to be used for querying linked concepts.\")\n",
    "    parser.add_argument(\"-eg\", \"--endpoint_graphs\",\n",
    "        help=\"The graphs one wants to query from the endpoint, e.g., http://www.yso.fi/onto/yso/. In case of multiple, separate them with space.\")\n",
    "    parser.add_argument(\"-ignoreOtherGraphWarnings\", \"--ignore_other_graph_warnings\",\n",
    "        help=\"Do you want ignore warnings produced whilst processing other graphs? Set this flag only if you want to ignore.\", action=\"store_true\")\n",
    "    parser.add_argument(\"-i\", \"--input\", help=\"Input file location, e.g., yso-skos.ttl\")\n",
    "    parser.add_argument(\"-if\", \"--input_format\", help=\"Input file format. Default: turtle\")\n",
    "    parser.add_argument(\"-o\", \"--output\", help=\"Output file name, e.g., yso.mrcx.\")\n",
    "    parser.add_argument(\"-vocId\", \"--vocabulary_code\", help=\"MARC code used in tag 040 subfield f.\", required=True)\n",
    "    parser.add_argument(\"-lang\", \"--languages\",\n",
    "        help=\"The RDF language tag of the language one is willing to convert. In case of multiple, separate them with space.\")\n",
    "    parser.add_argument(\"-m\", \"--multilanguage_vocabulary\", action='store_true',\n",
    "        help=\"Is the vocabulary using language specified vocabulary codes, e.g., yso/fin? Set this flag only if it is.\")\n",
    "    parser.add_argument(\"-gc\", \"--grouping_classes\",\n",
    "        help=\"Types of classes not meant for describing/cataloging items in the vocabulary, e.g, hierarchical ones. In case of multiple, seperate them with space.\")\n",
    "    parser.add_argument(\"-log\", \"--log_file\", help=\"Log file location.\")\n",
    "    parser.add_argument(\"-locDir\", \"--loc_directory\",\n",
    "        help=\"Library of Congress directory from which to look for and download to LoC marcxml files. One shall not set if one does not want LoC links.\")\n",
    "    parser.add_argument(\"-defaultCreationDate\", \"--default_creation_date\",\n",
    "        help=\"Default creation date (set in YYYY-MM-DD format) for a concept if it has not been declared explicitly. Default: \" + DEFAULTCREATIONDATE)\n",
    "    parser.add_argument(\"-keepDeprecatedAfter\", \"--keep_deprecated_after\",\n",
    "        help=\"Keep deprecated concepts deprecated after (not inclusive) the date given (set in YYYY-MM-DD format). Set to 'ALL' for no limits and 'NONE' to discard all.\")\n",
    "    \n",
    "    args = parser.parse_args(sys.argv)\n",
    "    return args\n",
    "\n",
    "def readEndpointGraphs(settings): \n",
    "    sparql = SPARQLWrapper(settings.get(\"endpoint\"))\n",
    "    queryStart = \"\"\"\n",
    "    PREFIX skos: <http://www.w3.org/2004/02/skos/core#>\n",
    "    PREFIX owl: <http://www.w3.org/2002/07/owl#>\n",
    "    CONSTRUCT {\n",
    "        ?concept skos:prefLabel ?prefLabel .\n",
    "        ?concept skos:inScheme ?inScheme .\n",
    "        ?concept owl:deprecated ?deprecated .\n",
    "        ?concept a ?types .\n",
    "    }\"\"\"\n",
    "\n",
    "    queryEnd = \"\"\"\n",
    "    WHERE {\n",
    "      ?concept a skos:Concept .\n",
    "      ?concept skos:prefLabel ?prefLabel .\n",
    "      ?concept a ?types .\n",
    "\n",
    "      OPTIONAL {?concept skos:inScheme ?inScheme .}\n",
    "      OPTIONAL {?concept owl:deprecated ?deprecated .}\n",
    "    }\n",
    "    \"\"\"\n",
    "    \n",
    "    queryFrom = \"\"\n",
    "    ret = Graph()\n",
    "    for endpointGraphIRI in settings.get(\"endpointGraphs\").split(\",\"):\n",
    "        sparql.setQuery(queryStart + \"\\nFROM <\" + str(endpointGraphIRI) + \">\" + queryEnd)\n",
    "        sparql.setMethod(\"GET\")\n",
    "        ret_length = len(ret)\n",
    "        try:\n",
    "            ret += sparql.query().convert()\n",
    "            if ret_length == len(ret):\n",
    "                logging.warning(\"Querying graph <\" + str(endpointGraphIRI) +\n",
    "                \"> from endpoint \" + settings.get(\"endpoint\") +\n",
    "                \" returned 0 triples. Continuing.\")\n",
    "        except (SPARQLExceptions.SPARQLWrapperException) as err:\n",
    "            logging.warning(\"Whilst querying endpoint \" + settings.get(\"endpoint\") + \n",
    "                  \" for graph <\" + str(endpointGraphIRI) +\n",
    "                  \"> the following error occurred: \" + err.__class__.__name__ + \": \" + err.msg + \n",
    "                  \". Skipping the graph.\")\n",
    "        except (urllib.error.HTTPError, urllib.error.URLError) as err:\n",
    "            logging.warning(\"SPARQL endpoint not found in url \" + settings.get(\"endpoint\") +\n",
    "                \". Skipping querying linked concepts.\")\n",
    "            break\n",
    "            \n",
    "    return ret\n",
    "\n",
    "# funktio konfiguraatiotiedostoissa olevien monimutkaisten merkkijonojen lukemiseen ja siistimiseen\n",
    "def readConfigVariable(string, separator=None):\n",
    "    if separator:\n",
    "        return [x.strip() for x in string.split(separator) if len(x.strip()) > 0]\n",
    "    else:\n",
    "        return string.strip()\n",
    "\n",
    "# funktio åäöÅÄÖ-kirjainten muuttamiseksi takaisin UTF8-merkeiksi (decomposed -> composed)\n",
    "def decomposedÅÄÖtoUnicodeCharacters(string):\n",
    "    return (string.replace(\"A\\u030a\", \"Å\").replace(\"a\\u030a\", \"å\").\n",
    "          replace(\"A\\u0308\", \"Ä\").replace(\"a\\u0308\", \"ä\").\n",
    "          replace(\"O\\u0308\", \"Ö\").replace(\"o\\u0308\", \"ö\"))\n",
    "    \n",
    "def getValues(graph, target, props, language=None, literal_datatype=None):\n",
    "    \"\"\"Given a subject, get all values for a list of properties\n",
    "    in the order in which those properties were defined.\n",
    "\n",
    "    Args:\n",
    "        graph (Graph): The graph from which to search for the properties of the target.\n",
    "        target (URIRef|BNode): Concept.\n",
    "        props (URIRef|sequence(URIRef)): Property or list of properties to search for.\n",
    "        language (str, optional): Language of literals. Defaults to None (return all literals with languages).\n",
    "            Set to empty string (\"\") for empty lang tag.\n",
    "        literal_datatype (URIRef, optional): Datatype of datatyped literals. Defaults to None (return all literals with datatypes).\n",
    "        \n",
    "    Returns:\n",
    "        list(TypeValue): List containing TypeValue namedtuples\n",
    "            prop (URIRef): Matched property\n",
    "            value (URIRef|BNode|Literal): For matched property, object value\n",
    "\n",
    "    Raises:\n",
    "        ValueError: If parameters do not respect the required types\n",
    "\n",
    "    \"\"\"\n",
    "    if isinstance(props, URIRef):\n",
    "        # cast to list in order to uniform code\n",
    "        props = [props]\n",
    "    \n",
    "    if not (isinstance(target, URIRef) or isinstance(target, BNode)):\n",
    "        raise ValueError(\"Parameter 'target' must be of type URIRef or BNode.\")\n",
    "    elif isinstance(props, str) or not isinstance(props, Sequence):\n",
    "        raise ValueError(\n",
    "            \"Type of parameter 'props' must be a URIRef or sequence; got %s.\" % (type(props)))\n",
    "    elif language is not None and not isinstance(language, str):\n",
    "        raise ValueError(\"Parameter 'language' must be string if set.\")\n",
    "    elif literal_datatype is not None and not isinstance(literal_datatype, URIRef):\n",
    "        raise ValueError(\"Parameter 'datatype' must be URIRef if set.\") \n",
    "    \n",
    "    v = []\n",
    "    \n",
    "    # setup the language filtering\n",
    "    if language is not None:\n",
    "        if language == '':  # we only want not language-tagged literals\n",
    "            langfilter = lambda l: l.language == None\n",
    "        else:\n",
    "            langfilter = lambda l: l.language == language\n",
    "    else:  # we don't care about language tags\n",
    "        langfilter = lambda l: True\n",
    "    \n",
    "    # setup the datatype filtering\n",
    "    if literal_datatype is not None:\n",
    "        typefilter = lambda l: l.datatype == literal_datatype\n",
    "    else:\n",
    "        typefilter = lambda l: True\n",
    "    \n",
    "    for prop in props:\n",
    "        if not isinstance(prop, URIRef):\n",
    "            raise ValueError(\n",
    "            \"Types of properties must be URIRefs; got %s from property '%s'.\" % (type(prop), str(prop)))\n",
    "        \n",
    "        # values that pass restrictions are returned\n",
    "        values = [l for l in graph.objects(target, prop) if \n",
    "                  (isinstance(l, URIRef) or isinstance(l, BNode)) or \n",
    "                  (l.datatype == None and langfilter(l)) or\n",
    "                  (l.datatype != None and typefilter(l))\n",
    "                 ]\n",
    "        \n",
    "        # loop through the values and add them to the list\n",
    "        for val in values:\n",
    "            v.append(ValueProp(value=val, prop=prop))\n",
    "    return v\n",
    "\n",
    "# apufunktio urlien parsimiseen merkkijonosta\n",
    "# mietittävä uudelleen, jos näitä rakenteistetaan\n",
    "def getURLs(string):\n",
    "    urls = []\n",
    "    for word in string:\n",
    "        if len(word) < 10:\n",
    "            continue\n",
    "        if word[0] in [\"(\", \"[\"]:\n",
    "            word = word[1:-1]\n",
    "        res = urllib.parse.urlparse(word)\n",
    "        if res.scheme in (\"http\", \"https\") and \\\n",
    "            len(res.netloc) > 3 and \".\" in res.netloc:\n",
    "            urls.append(word)\n",
    "    return urls\n",
    "\n",
    "class ConvertHTMLYSOATags(HTMLParser):\n",
    "    '''\n",
    "    Korvaa mahdolliset yso-linkit $a-osakenttämerkillä siten, että käytettävä termi\n",
    "    jää näkyviin. Muu osa tekstistä on $i-osakentissä. Käytetään mm. kentässä 680\n",
    "    \n",
    "    TODO: Virheiden käsittely ja HTML-erikoisentiteettien/kommenttien käsittely\n",
    "    '''\n",
    "    merkkijono = [\"$i\"]\n",
    "    in_a_yso = False\n",
    "    ended_a_yso = False\n",
    "    \n",
    "    def initialize(self):\n",
    "        self.merkkijono = [\"$i\"]\n",
    "        self.in_a_yso = False\n",
    "        self.ended_a_yso = False\n",
    "    \n",
    "    def handle_starttag(self, tag, attrs):\n",
    "        if tag == \"a\":\n",
    "            for attr in attrs:\n",
    "                if attr[0] == \"href\":\n",
    "                    link = attr[1]\n",
    "                    if link.startswith(YSO):\n",
    "                        self.in_a_yso = True\n",
    "                        self.merkkijono[-1] = self.merkkijono[-1].rstrip()\n",
    "                        self.merkkijono.append(\"$a\")\n",
    "                        return\n",
    "        \n",
    "        self.merkkijono.append(\"<\" + tag)\n",
    "        for attr in attrs:\n",
    "            self.merkkijono.append(\" \" + attr[0] + \"='\" + attr[1] + \"'\")\n",
    "        \n",
    "        self.merkkijono.append(\">\")\n",
    "        \n",
    "    def handle_endtag(self, tag):\n",
    "        if tag == \"a\" and self.in_a_yso:\n",
    "            self.in_a_yso = False\n",
    "            self.ended_a_yso = True\n",
    "        else:\n",
    "            self.merkkijono.append(\"</\" + tag + \">\")\n",
    "        \n",
    "        \n",
    "    def handle_data(self, data):\n",
    "        if self.ended_a_yso:\n",
    "            self.merkkijono.append(\"$i\")\n",
    "            self.ended_a_yso = False\n",
    "        \n",
    "        # korjaa normaalien tekstistä löytyvien '<'-merkkien käsittely\n",
    "        # TODO: Selvitä, tarvitseeko samanlainen korjaus tehdä myös alla\n",
    "        # määritellyille funktioille\n",
    "         \n",
    "        if self.merkkijono[-1] != \"$i\" and self.merkkijono[-1] != \"$a\":\n",
    "            self.merkkijono[-1] += data\n",
    "        else:\n",
    "            # tavallinen tapaus - lisätään vain käsitelty teksti uuteen osioon\n",
    "            self.merkkijono.append(data)\n",
    "        \n",
    "\n",
    "    def handle_comment(self, data):\n",
    "        self.merkkijono.append(data)\n",
    "\n",
    "    def handle_entityref(self, name):\n",
    "        # TODO: tarkista, mitä nämä esimerkkikoodit tekevät\n",
    "        #c = chr(name2codepoint[name])\n",
    "        self.merkkijono.append(name)\n",
    "\n",
    "    def handle_charref(self, name):\n",
    "        # TODO: tarkista, mitä nämä esimerkkikoodit tekevät\n",
    "        #if name.startswith('x'):\n",
    "        #    c = chr(int(name[1:], 16))\n",
    "        #else:\n",
    "        #    c = chr(int(name))\n",
    "        self.merkkijono.append(name)\n",
    "\n",
    "    def handle_decl(self, data):\n",
    "        self.merkkijono.append(data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pääfunktio\n",
    "def convert(cs, language, g, g2):\n",
    "    # kääntää graafin (g) kielellä (language) ConfigParser-sektion (cs) ohjeiden mukaisesti MARCXML-muotoon\n",
    "    # g2 sisältää vieraat graafit (poislukien mahdolliset lcsh & lcgf-viitteet), joista etsitään\n",
    "    # käytettyjä termejä 7XX kenttiin\n",
    "    \n",
    "    vocId = cs.get(\"vocabulary_code\")\n",
    "    \n",
    "    # variable for a bit complicated constants and casting/converting them to appropiate types\n",
    "    helper_variables = {\n",
    "        \"vocCode\" : (cs.get(\"vocabulary_code\") + \"/\" + LANGUAGES[language] \\\n",
    "            if cs.getboolean(\"multilanguage\", fallback=False) \\\n",
    "            else vocId),\n",
    "        \"groupingClasses\" : [URIRef(x) for x in cs.get(\"groupingClasses\", fallback=\",\".join(GROUPINGCLASSES)).split(\",\")],\n",
    "        \"groupingClassesDefault\" : [URIRef(x) for x in cs.parser.get(\"DEFAULT\", \"groupingClasses\", fallback=\",\".join(GROUPINGCLASSES)).split(\",\")],\n",
    "        'keepDeprecated' : cs.get(\"keepDeprecatedAfter\", fallback=KEEPDEPRECATEDAFTER).lower() != \"none\",\n",
    "        'write688created' : cs.get(\"defaultCreationDate\", fallback=None) != None\n",
    "    }\n",
    "    if helper_variables['keepDeprecated']:   \n",
    "        helper_variables['keepDeprecatedLimit'] = False \\\n",
    "        if cs.get(\"keepDeprecatedAfter\", fallback=KEEPDEPRECATEDAFTER).lower() == \"all\" \\\n",
    "        else datetime.date(datetime.strptime(cs.get(\"keepDeprecatedAfter\"), \"%Y-%m-%d\"))\n",
    "    \n",
    "    logging.info(\"Processing vocabulary with vocabulary code '%s' in language '%s'\" % (vocId, language))\n",
    "    incrementor = 0\n",
    "    deprecated_counter = 0\n",
    "    writer_records_counter = 0\n",
    "    ysoATagParser = ConvertHTMLYSOATags()\n",
    "    ET_namespaces = {\"marcxml\": \"http://www.loc.gov/MARC21/slim\"}\n",
    "    defaultOutputFileName = \"yso2marc-\" + cs.name.lower() + \"-\" + language + \".mrcx\"\n",
    "    \n",
    "    if cs.get(\"output\", fallback=None) == None:\n",
    "        try:\n",
    "            __IPYTHON__\n",
    "            handle = sys.stdout\n",
    "        except NameError:\n",
    "            handle = sys.stdout.buffer\n",
    "    else:\n",
    "        parts = cs.get(\"languages\").split(\",\")\n",
    "        if len(parts) > 1:\n",
    "            output = cs.get(\"output\")\n",
    "            if len(output.split(\".\")) > 1:\n",
    "                helper_variables[\"outputFileName\"] = \".\".join(output.split(\".\")[:-1]) + \"-\" + language + \".\" + output.split(\".\")[-1]\n",
    "                handle = open(helper_variables[\"outputFileName\"], \"wb\")\n",
    "            else:\n",
    "                helper_variables[\"outputFileName\"] = output + \"-\" + language\n",
    "                handle = open(helper_variables[\"outputFileName\"], \"wb\")\n",
    "        else:\n",
    "            handle = open(cs.get(\"output\", fallback=defaultOutputFileName), \"wb\")\n",
    "        \n",
    "    writer = XMLWriter(handle)\n",
    "    # käydään läpi käsitteet\n",
    "    for concept in sorted(g.subjects(RDF.type, SKOS.Concept)):\n",
    "        incrementor += 1\n",
    "        if incrementor % 1000 == 0:\n",
    "            logging.info(\"Processing %sth concept\" % (incrementor))\n",
    "        \n",
    "        # skipataan deprekoidut, jos niitä ei haluta mukaan\n",
    "        if (concept, OWL.deprecated, Literal(True)) in g:\n",
    "            if not helper_variables['keepDeprecated']:\n",
    "                deprecated_counter += 1\n",
    "                continue\n",
    "        \n",
    "        rec = Record()   \n",
    "        deprecatedString = \"\"\n",
    "        # Organisaation ISIL-tunniste -> 003\n",
    "        rec.add_field(\n",
    "            Field(\n",
    "                tag='003',\n",
    "                data = cs.get(\"creatorAgency\", fallback=CREATOR_AGENCY)\n",
    "            )\n",
    "        )\n",
    "        # dct:modified -> 005 EI TULOSTETA, 688 \n",
    "        # tutkitaan, onko käsite muuttunut vai alkuperäinen\n",
    "        # ja valitaan leader sen perusteella\n",
    "        mod = g.value(concept, DCT.modified, None)\n",
    "        if mod is None:\n",
    "            rec.leader = cs.get(\"leaderNew\", fallback=LEADERNEW)\n",
    "        else:\n",
    "            rec.leader = cs.get(\"leaderChanged\", fallback=LEADERCHANGED)\n",
    "            modified = mod.toPython() # datetime.date or datetime.datetime object\n",
    "            \n",
    "        # dct:created -> 008\n",
    "        crt = g.value(concept, DCT.created, None)\n",
    "        if crt is None:\n",
    "            created = datetime.date(datetime.strptime(cs.get(\"defaultCreationDate\", fallback=DEFAULTCREATIONDATE), \"%Y-%m-%d\"))\n",
    "        else:\n",
    "            created = crt.toPython() # datetime.date or datetime.datetime object\n",
    "            if type(created) == datetime:\n",
    "                created = datetime.date(created) # datetime.date\n",
    "        \n",
    "        code = cs.get(\"catalogCodes\", fallback=CATALOGCODES)\n",
    "        \n",
    "        # asetetaan kuvailukielto käsitteelle, jos tyypiä ryhmittelevä käsite\n",
    "        for conceptType in g.objects(concept, RDF.type):\n",
    "            if conceptType in helper_variables[\"groupingClasses\"]:\n",
    "                code = cs.get(\"catalogCodes_na\", fallback=CATALOGCODES_NA)\n",
    "                break\n",
    "        # jos kyseessä on poistettu käsite, asetetaan leaderit ja koodit asianmukaisesti\n",
    "        if (concept, OWL.deprecated, Literal(True)) in g:\n",
    "            replacers = sorted(g.objects(concept, DCT.isReplacedBy))\n",
    "            if len(replacers) == 0:\n",
    "                rec.leader = cs.get(\"leaderDeleted0\", fallback=LEADERDELETED0)\n",
    "            elif len(replacers) == 1:\n",
    "                rec.leader = cs.get(\"leaderDeleted1\", fallback=LEADERDELETED1)\n",
    "            else:\n",
    "                rec.leader = cs.get(\"leaderDeleted2\", fallback=LEADERDELETED2)\n",
    "             \n",
    "            code = cs.get(\"catalogCodes_na\", fallback=CATALOGCODES_NA)\n",
    "            \n",
    "            # jos on lisäksi asetettu jokin päivämäärärajoite\n",
    "            if helper_variables['keepDeprecatedLimit']:\n",
    "                # mikäli scopeNote puuttuu, poistettu tulkitaan uudeksi poistoksi ja sen tulkitaan\n",
    "                # \"ylittävän\" asetetun limitin eli jää tulosjoukkoon\n",
    "                for valueProp in sorted(getValues(g, concept, SKOS.scopeNote, language=\"\"),\n",
    "                                                           key=lambda o: str(o.value)):    \n",
    "                    if valueProp.value.startswith(\"deprecated on\"):\n",
    "                        deprecatedString = str(valueProp.value)\n",
    "                        break\n",
    "                if deprecatedString:\n",
    "                    deprecatedDateString = deprecatedString.split(\" \")[-1]\n",
    "                    try:\n",
    "                        # yritetään parsia päivämäärä kahdessa eri formaatissa\n",
    "                        deprecatedDate = datetime.date(datetime.strptime(deprecatedDateString, \"%d.%m.%Y\"))\n",
    "                        if helper_variables['keepDeprecatedLimit'] > deprecatedDate:\n",
    "                            deprecated_counter += 1\n",
    "                            continue # skipataan ennen vanhentamisrajaa vanhennetut termit\n",
    "                    except ValueError:\n",
    "                        try:\n",
    "                            deprecatedDate = datetime.date(datetime.strptime(deprecatedDateString, \"%Y-%m-%d\"))\n",
    "                            if helper_variables['keepDeprecatedLimit'] > deprecatedDate:\n",
    "                                deprecated_counter += 1\n",
    "                                continue # skipataan ennen vanhentamisrajaa vanhennetut termit\n",
    "                        except ValueError:\n",
    "                            logging.warning(\"Converting deprecated date failed for concept %s. Proceeding.\" %\n",
    "                          (concept))\n",
    "        \n",
    "        if not created and not helper_variables[\"write688created\"]:\n",
    "            logging.warning(\"No explicit creation date defined for concept %s. Using default value '%s' for character positions 00-05 in tag 008.\" % (\n",
    "                concept, datetime.date(datetime.strptime(DEFAULTCREATIONDATE, \"%Y-%m-%d\")).strftime('%y%m%d')))\n",
    "\n",
    "        rec.add_field(\n",
    "            Field(\n",
    "                tag='008',\n",
    "                data=created.strftime('%y%m%d') + code\n",
    "            )\n",
    "        )\n",
    "        \n",
    "        # 024 muut standarditunnukset - käsitteen URI tallennetaan tähän\n",
    "        rec.add_field(\n",
    "            Field(\n",
    "                tag='024',\n",
    "                indicators = ['7', ' '],\n",
    "                subfields = [\n",
    "                    'a', concept,\n",
    "                    '2', \"uri\"\n",
    "                ]\n",
    "            )\n",
    "        )\n",
    "        \n",
    "        # 034 paikkojen koordinaatit - yso-paikat?\n",
    "        # 035 yso-tietueen numero?\n",
    "        \n",
    "        # 040 luetteloiva organisaatio\n",
    "        rec.add_field(\n",
    "            Field(\n",
    "                tag='040',\n",
    "                indicators = [' ', ' '],\n",
    "                subfields = [\n",
    "                    'a', cs.get(\"creatorAgency\", fallback=CREATOR_AGENCY),\n",
    "                    'b', LANGUAGES[language],\n",
    "                    'f', helper_variables[\"vocCode\"]\n",
    "                ]\n",
    "            )\n",
    "        )\n",
    "        # 043 - ysopaikat, käytetäänkö\n",
    "        # http://marc21.kansalliskirjasto.fi/aukt/01X-09X.htm#043\n",
    "        \n",
    "        # 045 - yso-ajanjaksot, käytetäänkö\n",
    "        # http://marc21.kansalliskirjasto.fi/aukt/01X-09X.htm#045\n",
    "        \n",
    "        # 046 - erikoiskoodatut ajanjaksot? \n",
    "        \n",
    "        # 052 - maantieteellinen luokitus\n",
    "        # 7#$a(480)$2udc$0http://udcdata.info/004604\n",
    "        # jos 151 kaytossa, pitaisiko kayttaa? Jarmo: UDC-luokitus, Suomi \"(480)\"\n",
    "        \n",
    "        #ConceptGroup / skos:member -> 065 yso-aihealuekoodi\n",
    "        # vain siina tapauksessa, kun ne halutaan mukaan Asteriin\n",
    "        # jos luokkanumeroa ei löydy, ei tulosteta\n",
    "        # vain jos vocId = \"yso\", tehdään tämä\n",
    "        if vocId == \"yso\":\n",
    "            for group in sorted(g.subjects(SKOS.member, concept)):\n",
    "                if not helper_variables['keepDeprecated'] and \\\n",
    "                (group, OWL.deprecated, Literal(True)) in g:\n",
    "                    continue # skip deprecated group concepts\n",
    "                if (group, RDF.type, ISOTHES.ConceptGroup) not in g:\n",
    "                    continue\n",
    "                # ryhmätunnuksen ekstraktointi: yritä ensin kaivaa skos:notationista, muuten prefLabelista\n",
    "                groupno = g.value(group, SKOS.notation, None)\n",
    "                if groupno is None:\n",
    "                    valueProps = sorted(getValues(g, group, SKOS.prefLabel, language=language),\n",
    "                                       key=lambda o: o.value)\n",
    "\n",
    "                    if len(valueProps) == 0: \n",
    "                        logging.warning(\"Could not find preflabel for target %s in language: %s. Skipping property %s target for concept %s.\" %\n",
    "                          (group, language, SKOS.member, concept))\n",
    "                        continue\n",
    "                    elif len(valueProps) != 1:\n",
    "                        logging.warning(\"Multiple prefLabels detected for concept %s in language %s. Taking the first only.\" %\n",
    "                          (concept, language)) \n",
    "                    groupname = str(valueProps[0].value)\n",
    "                    try:\n",
    "                        groupno = str(groupname[0:groupname.index(\" \")])\n",
    "                        groupname = str(groupname[len(groupno) + 1:])\n",
    "                    except ValueError:\n",
    "                        logging.warning(\"Tried to parse group number for group %s from preflabel %s in language %s but failed.\" %\n",
    "                          (group, language))\n",
    "                        continue\n",
    "\n",
    "                rec.add_field(\n",
    "                    Field(\n",
    "                           tag='065',\n",
    "                           indicators = [' ', ' '],\n",
    "                           subfields = [\n",
    "                               'a', groupno,\n",
    "                               'c', decomposedÅÄÖtoUnicodeCharacters(unicodedata.normalize(NORMALIZATION_FORM, groupname)),\n",
    "                               #'c', groupname,\n",
    "                               '0', group,\n",
    "                               '2', vocId\n",
    "                           ]\n",
    "                    )\n",
    "                )\n",
    "        \n",
    "        # 080 - UDK-luokka. Asiasanaan liittyva UDK-luokka\n",
    "        \n",
    "        # 147 Tapahtuman nimi. Ei kayteta?\n",
    "        \n",
    "        # 148 Aikaa merkitseva termi. Selvitetaan.\n",
    "        \n",
    "        # skos:prefLabel -> 150 aihetta ilmaiseva termi\n",
    "        valueProps = sorted(getValues(g, concept, SKOS.prefLabel, language=language),\n",
    "                                   key=lambda o: o.value)\n",
    "        if len(valueProps) == 0:\n",
    "            logging.warning(\"Could not find preflabel for concept %s in language %s. Skipping the whole concept.\" %\n",
    "              (concept, language))\n",
    "            continue\n",
    "        elif len(valueProps) != 1:\n",
    "            logging.warning(\"Multiple prefLabels detected for concept %s in language %s. Choosing the first.\" %\n",
    "                  (concept, language)) \n",
    "            \n",
    "        # tunnistetaan käsitteen tyyppi (aika, yleinen, paikka, genre)\n",
    "        # -> 148, 150, 151, 155, 162\n",
    "        # tukee tällä hetkellä tavallisia asiasanoja (150), YSO-paikkoja (151) & SLM:ää (155)\n",
    "        tag = \"150\"\n",
    "        if (concept, SKOS.inScheme, YSO.places) in g:\n",
    "            tag = \"151\"\n",
    "        elif vocId == \"slm\":\n",
    "            tag = \"155\"\n",
    "\n",
    "        rec.add_field(\n",
    "            Field(\n",
    "                tag=tag,\n",
    "                indicators = [' ', ' '],\n",
    "                subfields=[\n",
    "                            'a', decomposedÅÄÖtoUnicodeCharacters(unicodedata.normalize(NORMALIZATION_FORM, str(valueProps[0].value)))\n",
    "                            #'a', str(valueProps[0].value)\n",
    "                          ]\n",
    "            )\n",
    "        )\n",
    "        \n",
    "        # skos:altLabel -> 447, 448, 450, 451, 455\n",
    "        # 450 katso-viittaus\n",
    "        # poistetaan toisteiset skos:hiddenLabelit\n",
    "        # OLETUS: poistettujen käsitteiden seuraajien tietoihin EI merkitä poistetun käsitteen\n",
    "        # skos:prefLabelia näihin kenttiin, sillä sen oletetaan jo olevan skos:altLabelina kun siihen\n",
    "        # on haluttu viitata vanhalla muodolla\n",
    "        seen_values = set()\n",
    "        \n",
    "        for valueProp in sorted(getValues(g, concept, [SKOS.altLabel, YSOMETA.singularPrefLabel,\n",
    "                                                YSOMETA.singularAltLabel, SKOS.hiddenLabel], language=language),\n",
    "                                key=lambda o: str(o.value)): \n",
    "\n",
    "            if valueProp.prop == SKOS.hiddenLabel:\n",
    "                if str(valueProp.value) in seen_values:\n",
    "                    continue\n",
    "            seen_values.add(str(valueProp.value))\n",
    "            \n",
    "            tag = \"450\"\n",
    "            if (concept, SKOS.inScheme, YSO.places) in g:\n",
    "                tag = \"451\"\n",
    "            elif vocId == \"slm\":\n",
    "                tag = \"455\"\n",
    "\n",
    "            rec.add_field(\n",
    "                Field(\n",
    "                    tag = tag,\n",
    "                    indicators = [' ', ' '],\n",
    "                    subfields = [\n",
    "                        #'i', TERMGROUP[valueProp.prop][language], # nämä selitteet haluttiin jättää pois - kuvailujärjestelmä hoitaa\n",
    "                        'a', decomposedÅÄÖtoUnicodeCharacters(unicodedata.normalize(NORMALIZATION_FORM, str(valueProp.value)))\n",
    "                        #'a', str(valueProp.value)\n",
    "                    ]\n",
    "                )\n",
    "            )\n",
    "        \n",
    "        # broader/narrower/related/successor/predecessor/skosext:partOf\n",
    "        # -> 550 \"katso myos\" viittaus\n",
    "        # HUOM: Objektit vain olioita\n",
    "        # TODO: ysoon lisätään myöhemmin partOf-suhteiden käänteinen suhde\n",
    "        # TODO: useat erityyppiset i-kentät eivät toimi tällä hetkellä\n",
    "        fields = list()\n",
    "        for prop, wval in SEEALSOPROPS.items():\n",
    "            for target in sorted(g.objects(concept, prop)):\n",
    "                if not helper_variables['keepDeprecated'] and \\\n",
    "                (target, OWL.deprecated, Literal(True)) in g:\n",
    "                    continue # skip deprecated concepts\n",
    "                \n",
    "                valueProps = getValues(g, target, SKOS.prefLabel, language=language)\n",
    "                if len(valueProps) == 0:\n",
    "                    logging.warning(\"Could not find preflabel for target %s in language %s. Skipping property %s target for concept %s.\" %\n",
    "                      (target, language, prop, concept))\n",
    "                    continue\n",
    "                elif len(valueProps) != 1:\n",
    "                    logging.warning(\"Multiple prefLabels detected for target %s in language %s. Choosing the first.\" %\n",
    "                          (target, language)) \n",
    "                label = valueProps[0].value\n",
    "                \n",
    "                tag = \"550\" # alustetaan 550-arvoon\n",
    "                if (target, SKOS.inScheme, YSO.places) in g:\n",
    "                        tag = \"551\"\n",
    "                elif vocId == \"slm\":\n",
    "                    tag = \"555\"\n",
    "                \n",
    "                subfields = []\n",
    "                \n",
    "                #TODO: YSOn mahdolliset SKOSEXT-ominaisuudet?\n",
    "                #TODO: tarkista tämä YSOn tietomalliuudistusta varten\n",
    "                if wval == \"i\":\n",
    "                    if (target, SKOS.inScheme, YSO.places) in g:\n",
    "                        if prop == SKOSEXT.partOf:\n",
    "                            subfields.extend(('w', 'g'))\n",
    "                        elif prop == SKOSEXT.hasPart:\n",
    "                            subfields.extend(('w', 'h'))\n",
    "                        else:\n",
    "                            subfields.extend(('w', wval,\n",
    "                                     \"i\", TRANSLATIONS[prop][language]\n",
    "                                    ))\n",
    "                    else:\n",
    "                        subfields.extend(('w', wval,\n",
    "                                     \"i\", TRANSLATIONS[prop][language]\n",
    "                                    ))\n",
    "                else:\n",
    "                    # yso-paikoissa on sekä ISOTHES.broaderPartitive, että\n",
    "                    # SKOS.broader redundanttina, jätetään j. pois\n",
    "                    # samoin ISOTHES.narrowerPartitive - SKOS.narrower\n",
    "                    if (target, SKOS.inScheme, YSO.places) in g and \\\n",
    "                        (prop == SKOS.broader or prop == SKOS.narrower):\n",
    "                        continue\n",
    "                    subfields.extend(('w', wval))\n",
    "                \n",
    "                subfields.extend(('a', \n",
    "                                  decomposedÅÄÖtoUnicodeCharacters(unicodedata.normalize(NORMALIZATION_FORM, str(label)))\n",
    "                                  #str(label)\n",
    "                                 ))\n",
    "                subfields.extend(('0', target))\n",
    "                \n",
    "                fields.append(\n",
    "                    Field(\n",
    "                        tag = tag,\n",
    "                        indicators = [' ', ' '],\n",
    "                        subfields = subfields\n",
    "                    )\n",
    "                )\n",
    "        # järjestä 5XX-kentät ja lisää ne tietueeseen\n",
    "        for sorted_field in sorted(fields, key=lambda o: (\n",
    "            o.tag, \n",
    "            SORT_5XX_W_ORDER[o.get_subfields(\"w\")[0]] if o.get_subfields(\"w\") else \"999\",\n",
    "            o.get_subfields('a')[0]\n",
    "            )):\n",
    "            rec.add_field(sorted_field)\n",
    "        \n",
    "        # TODO: JS: laitetaan 667 kenttään SLM:n käsiteskeemat jokaiselle käsitteelle\n",
    "        \n",
    "        # dc:source -> 670 kasitteen tai kuvauksen lahde\n",
    "        # tulostetaan termin kielen mukaan samankieliset lähteet\n",
    "        # mikäli kielikoodilla ei ole propertille arvoa, ohjelma ei tulosta tätä kenttää\n",
    "        # voidaanko tunnistaa, onko lähteessä URI, jolloin\n",
    "        # $u-osakenttään laitetaan tämä URI\n",
    "        # 4.5.2018 - palataan myöhemmin tähän\n",
    "        # JS: 6.8.2018 - usein pelkkä lähdeviittaus, jolloin kielellä ei merkitystä\n",
    "        for valueProp in sorted(getValues(g, concept, DC.source, language=language), key=lambda o: str(o.value)):  \n",
    "            subfields = [\n",
    "                'a', \n",
    "                decomposedÅÄÖtoUnicodeCharacters(unicodedata.normalize(NORMALIZATION_FORM, str(valueProp.value)))\n",
    "                #str(valueProp.value)\n",
    "            ]\n",
    "            # TODO: linkkien koodaus tarkistetaan/tehdään myöhemmin\n",
    "            #urls = getURLs(valueProp.value)\n",
    "            #for url in urls:\n",
    "            #    subfields.append(\"u\")\n",
    "            #    subfields.append(url)\n",
    "                \n",
    "            rec.add_field(\n",
    "                Field(\n",
    "                    tag='670',\n",
    "                    indicators = [' ', ' '],\n",
    "                    subfields = subfields\n",
    "                )\n",
    "            )\n",
    "        # skos:definition -> 677 huomautus määritelmästä\n",
    "        # määritelmän lähde voidaan merkitä osakenttään $v\n",
    "        # sitä varten tulee sopia tavasta merkitä tämä lähde, jotta\n",
    "        # se voidaan koneellisesti erottaa tekstistä\n",
    "        # JS ehdottaa: jos tekstissä on merkkijono \". Lähde: \",\n",
    "        # kaikki sen perässä oleva teksti merkitään osakenttään $v\n",
    "        # entä jos linkki lähteen perässä?\n",
    "        # JS ehdottaa: linkki aivan viimeisenä sanana\n",
    "        # 4.5.2018 - palataan myöhemmin tähän\n",
    "        # 6.8.2018 - ei vielä käsitelty\n",
    "        # 5.9.2018 - määritelmän lähde tulee määritelmän jälkeen kahdella tavuviivalla (--) erotettuna\n",
    "        # jätetään toistaiseksi paikalleen (13 kpl)\n",
    "        for valueProp in sorted(getValues(g, concept, SKOS.definition, language=language),\n",
    "                                key=lambda o: str(o.value)):\n",
    "            subfields = [\n",
    "                'a', \n",
    "                decomposedÅÄÖtoUnicodeCharacters(unicodedata.normalize(NORMALIZATION_FORM, str(valueProp.value)))\n",
    "                #str(valueProp.value)\n",
    "            ]\n",
    "            # TODO: linkkien koodaus tarkistetaan/tehdään myöhemmin\n",
    "            #urls = getURLs(valueProp.value)\n",
    "            #for url in urls:\n",
    "            #    subfields.append(\"u\")\n",
    "            #    subfields.append(url)\n",
    "                \n",
    "            rec.add_field(\n",
    "                Field(\n",
    "                    tag='677',\n",
    "                    indicators = [' ', ' '],\n",
    "                    subfields = subfields\n",
    "                )\n",
    "            )\n",
    "        \n",
    "        # skos:note -> 680 yleinen huomautus, julkinen\n",
    "        for valueProp in sorted(getValues(g, concept, [SKOS.note, SKOS.scopeNote, SKOS.example], language=language),\n",
    "                                key=lambda o: str(o.value)):\n",
    "            \n",
    "            ysoATagParser.initialize()\n",
    "            ysoATagParser.feed(valueProp.value)\n",
    "            \n",
    "            if len(ysoATagParser.merkkijono)%2 == 1:\n",
    "                logging.warning(\"Parsing the property %s for concept %s into seperate subfields failed. Continuing with complete value.\" % (valueProp.prop, concept))\n",
    "                subfieldCodeValuePair = (\"i\", valueProp.value.strip())\n",
    "                if len(subfieldCodeValuePair[1]) == 0:\n",
    "                    subfieldCodeValuePair = []\n",
    "            else:\n",
    "                subfieldCodeValuePair = [[x[1], ysoATagParser.merkkijono[ind+1].strip()] for (ind,x) in enumerate(ysoATagParser.merkkijono) if ind%2 == 0]\n",
    "                # poistetaan viimeinen i-tägi, jos se on vain 1 merkin mittainen (loppupisteet)\n",
    "                if subfieldCodeValuePair[-1][0] == \"i\" and len(subfieldCodeValuePair[-1][1]) <= 1 and len(subfieldCodeValuePair) > 1:\n",
    "                    subfieldCodeValuePair[-2][1] = subfieldCodeValuePair[-2][1] + subfieldCodeValuePair[-1][1]\n",
    "                    subfieldCodeValuePair = subfieldCodeValuePair[:-1]\n",
    "            \n",
    "            subfield_values = []\n",
    "            \n",
    "            for subfield in subfieldCodeValuePair:\n",
    "                subfield_values.extend(\n",
    "                    (subfield[0], decomposedÅÄÖtoUnicodeCharacters(unicodedata.normalize(NORMALIZATION_FORM, subfield[1])))\n",
    "                    #(subfield[0], subfield[1])\n",
    "                )\n",
    "            \n",
    "            rec.add_field(\n",
    "                Field(\n",
    "                    tag='680',\n",
    "                    indicators = [' ', ' '],\n",
    "                    subfields = subfield_values\n",
    "                )\n",
    "            )\n",
    "        # mahdollinen deprekointitieto lisätään erikseen\n",
    "        if deprecatedString:\n",
    "            rec.add_field(\n",
    "                Field(\n",
    "                    tag='680',\n",
    "                    indicators = [' ', ' '],\n",
    "                    subfields = ['i', deprecatedString]\n",
    "                )\n",
    "            )\n",
    "        # owl:deprecated -> 682 Huomautus poistetusta otsikkomuodosta (ei toistettava)\n",
    "        # Ohjaus uuteen/uusiin käsitteisiin\n",
    "        # seuraaja-suhde\n",
    "        # a-kenttään seuraajan preflabel, 0-kenttään URI, i selite\n",
    "        # TODO: onko seuraajaa vai ei, lisäksi mietittävä deprekoidun käsitteen\n",
    "        # tyyppi (onko hierarkia jne.). Deprekaattorin huomautustekstiä kehitettävä\n",
    "        # (kentät mietittävä uudelleen - EI skos:scopeNote kuten nyt on 4.5.2018)\n",
    "        # 2018-12-05 Huomattiin, että ei ole toistettavissa --> ongelma useiden korvaajien tapauksessa ($0)\n",
    "        # kongressin kirjasto on työstämässä parhaista käytännöistä $0-kentän toistettavuudesta vielä tämän vuoden aikana\n",
    "        # päätettiin jättää tässä vaiheessa $0-kentät kokonaan pois\n",
    "        if (concept, OWL.deprecated, Literal(True)) in g:\n",
    "            target = None\n",
    "            labels = []\n",
    "            for target in sorted(g.objects(concept, DCT.isReplacedBy)):\n",
    "                if not helper_variables['keepDeprecated'] and \\\n",
    "                (target, OWL.deprecated, Literal(True)) in g:\n",
    "                    continue # skip deprecated concepts\n",
    "                    \n",
    "                valueProps = sorted(getValues(g, target, SKOS.prefLabel, language=language), key=lambda o: str(o.value))\n",
    "                if len(valueProps) > 1:\n",
    "                    logging.warning(\"Multiple prefLabels detected for target %s in language %s. Choosing the first.\" %\n",
    "                      (target, language)) \n",
    "                elif len(valueProps) == 0:\n",
    "                    logging.warning(\"Could not find preflabel for target %s in language: %s. Skipping property %s target for concept %s.\" %\n",
    "                          (target, language, DCT.isReplacedBy, concept))\n",
    "                    continue\n",
    "                label = valueProps[0].value\n",
    "                labels.append(valueProps[0].value)\n",
    "                #rec.add_field(\n",
    "                #    Field(\n",
    "                #        tag = '682',\n",
    "                #        indicators = [' ', ' '],\n",
    "                #        subfields = [\n",
    "                #            'i', TRANSLATIONS[\"682iDEFAULT\"][language],\n",
    "                #            'a', decomposedÅÄÖtoUnicodeCharacters(unicodedata.normalize(NORMALIZATION_FORM, str(label))),\n",
    "                #            #'a', str(label),\n",
    "                #            '0', target\n",
    "                #        ]\n",
    "                #    )\n",
    "                #)\n",
    "            if len(labels) > 0:\n",
    "                subfield_values = ['i', TRANSLATIONS[\"682iDEFAULT\"][language]]\n",
    "                \n",
    "                for label in labels[:-1]:\n",
    "                    subfield_values.extend(('a', \n",
    "                                      decomposedÅÄÖtoUnicodeCharacters(unicodedata.normalize(NORMALIZATION_FORM, str(label) + \",\"))\n",
    "                                      #str(label)\n",
    "                                     ))\n",
    "                subfield_values.extend(('a', \n",
    "                                      decomposedÅÄÖtoUnicodeCharacters(unicodedata.normalize(NORMALIZATION_FORM, str(labels[-1])))\n",
    "                                      #str(label)\n",
    "                                     ))\n",
    "                #subfields_values.extend(('0', target)) #TODO: seurataan kongressin kirjaston tulevia ohjeistuksia\n",
    "                rec.add_field(\n",
    "                    Field(\n",
    "                        tag='682',\n",
    "                        indicators = [' ', ' '],\n",
    "                        subfields = subfield_values\n",
    "                    )\n",
    "                )\n",
    "        \n",
    "        if helper_variables[\"write688created\"]:\n",
    "            rec.add_field(\n",
    "                Field(\n",
    "                    tag = '688',\n",
    "                    indicators = [' ', ' '],\n",
    "                    subfields = [\n",
    "                        'a',  TRANSLATIONS[\"688aCREATED\"][language] + \": \" + created.strftime('%Y-%m-%d')\n",
    "                    ]\n",
    "                )\n",
    "            )\n",
    "        \n",
    "        if mod and modified:\n",
    "            rec.add_field(\n",
    "                Field(\n",
    "                    tag = '688',\n",
    "                    indicators = [' ', ' '],\n",
    "                    subfields = [\n",
    "                        'a', TRANSLATIONS[\"688aMODIFIED\"][language] + \": \" + modified.strftime('%Y-%m-%d')\n",
    "                    ]\n",
    "                )\n",
    "            )\n",
    "            try:\n",
    "                if type(modified) == datetime:\n",
    "                    if created > modified.date():\n",
    "                        logging.warning(\"Created date later than modified for concept %s\" % concept)\n",
    "                else:\n",
    "                    if created > modified:\n",
    "                        logging.warning(\"Created date later than modified for concept %s\" % concept)\n",
    "            except Exception:\n",
    "                logging.warning(\"Date comparison failed for concept %s\", concept)\n",
    "\n",
    "                        \n",
    "        # all skos:match*es -> 7XX linkkikenttiin\n",
    "        # halutaan linkit kaikkiin kieliversioihin\n",
    "        # lisäksi saman sanaston erikieliset preflabelit tulevat tänne\n",
    "        # graafit on haettu etukäteen ohjelman muistiin ohjelman alussa\n",
    "        # 750 $a label, $4 relaatiotyyppi, $2 sanastolahde, $0 uri\n",
    "        # miten $w? JS: ei oteta mukaan ollenkaan\n",
    "        # 2.5.2018-kokouksessa päätettiin, että DCT.spatialia ei käännetä\n",
    "        # MARC-muotoon\n",
    "        # 13.8.2018 LCSH/LCGF käsitellään erikseen; niille on tehty oma kansio, joka\n",
    "        # on tallennettu locDirectory-muuttujaan. Puuttuvat loc-linkit haetaan\n",
    "        # dynaamisesti tarvittaessa ja lisätään kansioon, josta ne sitten luetaan ohjelman käyttöön\n",
    "        valueProps = getValues(g, concept, [SKOS.prefLabel, SKOS.exactMatch, SKOS.closeMatch,\n",
    "                                 SKOS.broadMatch, SKOS.narrowMatch, \n",
    "                                 SKOS.relatedMatch])\n",
    "        fields = list() # kerätään kentät tähän muuttujaan, joka sitten lopuksi järjestetään\n",
    "       \n",
    "        for valueProp in valueProps:\n",
    "            if valueProp.prop == SKOS.prefLabel:\n",
    "                # suodatetaan samankieliset, jotka menivät jo 1xx-kenttiin\n",
    "                # valueProp.value sisältää tässä poikkeuksellisesti jo halutun literaalin\n",
    "                # (vrt. kun muissa on solmu)\n",
    "                if valueProp.value.language == language:\n",
    "                    continue\n",
    "                matchURIRef = URIRef(concept)\n",
    "            else:\n",
    "                # tehdään osumasta URIRef \n",
    "                matchURIRef = URIRef(valueProp.value)\n",
    "                #if not helper_variables['keepDeprecated'] and \\\n",
    "                if (matchURIRef, OWL.deprecated, Literal(True)) in g2:\n",
    "                    # skip deprecated matches\n",
    "                    # 19.12.2018 käyty keskustelua tästä - päätetty tässä vaiheessa\n",
    "                    # olla seuraamatta dct:isReplacedBy-suhteita ja lisäämättä näitä\n",
    "                    # TODO-listalle?\n",
    "                    continue \n",
    "                # 27.12.2018 pitäisikö tarkistaa myös groupingClassesien varalta?\n",
    "                # Ratkaisu: Ei - nämä on merkitty omissa tietueissaan ei-käytettäviksi\n",
    "\n",
    "            second_indicator = \"7\"\n",
    "            tag = \"750\"\n",
    "            loc_object = None \n",
    "            \n",
    "            if (matchURIRef, SKOS.inScheme, YSO.places) in g2 or \\\n",
    "            (matchURIRef, SKOS.inScheme, YSO.places) in g: #or matchType == DCT.spatial:\n",
    "                tag = \"751\"\n",
    "            # TODO: nimetyt graafit, kohdista kyselyt niihin?\n",
    "            # Comment: if we want to direct queries to spesific graphs, one per vocab,\n",
    "            # that graph needs to be selected here based on the void:uriSpace\n",
    "            \n",
    "            if matchURIRef.startswith(LCSH):\n",
    "                second_indicator = \"0\"\n",
    "                loc_object = {\"prefix\": str(LCSH), \"id\": matchURIRef.split(\"/\")[-1]}\n",
    "            elif matchURIRef.startswith(LCGF):\n",
    "                sub2 = \"lcgft\" \n",
    "                loc_object = {\"prefix\": str(LCGF), \"id\": matchURIRef.split(\"/\")[-1]}\n",
    "            elif matchURIRef.startswith(ALLARS):\n",
    "                if (matchURIRef, RDF.type, ALLARSMETA.GeographicalConcept) in g2: #or matchType == DCT.spatial:\n",
    "                    tag = \"751\"\n",
    "                sub2 = \"allars\"\n",
    "            elif matchURIRef.startswith(KOKO):\n",
    "                continue # skip KOKO concepts\n",
    "            elif matchURIRef.startswith(SLM):\n",
    "                tag = \"755\"\n",
    "                sub2 = \"slm\"\n",
    "            elif matchURIRef.startswith(YSA):\n",
    "                if (matchURIRef, RDF.type, YSAMETA.GeographicalConcept) in g2: #or matchType == DCT.spatial:\n",
    "                    tag = \"751\"\n",
    "                sub2 = \"ysa\"\n",
    "            elif matchURIRef.startswith(YSO):\n",
    "                sub2 = \"yso\"\n",
    "            else:\n",
    "                second_indicator = \"4\"\n",
    "                if not cs.getboolean(\"ignoreOtherGraphWarnings\", fallback=IGNOREOTHERGRAPHWARNINGS):\n",
    "                    logging.warning(\"Matched target %s did not belong to any known vocabulary\" % (str(matchURIRef)))\n",
    "                    # do not put subfield 2 in this case\n",
    "            \n",
    "            if not ((matchURIRef, None, None) in g or\n",
    "                (matchURIRef, None, None) in g2):\n",
    "                if not loc_object and not cs.getboolean(\"ignoreOtherGraphWarnings\", fallback=IGNOREOTHERGRAPHWARNINGS): \n",
    "                    logging.warning(\"Matched target %s did not belong to any known vocabulary. Skipping.\" % (str(matchURIRef)))\n",
    "                    continue\n",
    "            \n",
    "            sub4 = \"\"\n",
    "            if valueProp.prop == SKOS.broadMatch:\n",
    "                sub4 = \"BM\"\n",
    "            elif valueProp.prop == SKOS.narrowMatch:\n",
    "                sub4 = \"NM\"\n",
    "            elif valueProp.prop == SKOS.exactMatch:\n",
    "                sub4 = \"EQ\"\n",
    "            elif valueProp.prop == SKOS.prefLabel:\n",
    "                sub4 = \"EQ\"\n",
    "                \n",
    "                # kovakoodattu yso ja slm - muuten niiden tulisi olla jossain globaalissa muuttujassa\n",
    "                if sub2 == \"yso\" or sub2 == \"slm\" or cs.getboolean(\"multilanguage\", fallback=False):\n",
    "                    sub2 = sub2 + \"/\" + LANGUAGES[valueProp.value.language]\n",
    "                \n",
    "                fields.append(\n",
    "                    Field(\n",
    "                        tag=tag,\n",
    "                        indicators = [' ', second_indicator],\n",
    "                        subfields = [\n",
    "                            'a', decomposedÅÄÖtoUnicodeCharacters(unicodedata.normalize(NORMALIZATION_FORM, str(valueProp.value))), \n",
    "                            #'a', str(valueProp.value),\n",
    "                            '4', sub4,\n",
    "                            '2', sub2,\n",
    "                            '0', concept\n",
    "                        ]\n",
    "                    )\n",
    "                )\n",
    "                continue\n",
    "            elif valueProp.prop == SKOS.closeMatch:\n",
    "                sub4 = \"~EQ\"\n",
    "            else:\n",
    "                sub4 = \"RM\"\n",
    "                \n",
    "            # library of congress -viitteet käsitellään erikseen\n",
    "            if loc_object:\n",
    "                if cs.get(\"locDirectory\", fallback=None) == None:\n",
    "                    # skipataan\n",
    "                    continue\n",
    "                recordNode = None\n",
    "                local_loc_source = cs.get(\"locDirectory\") + loc_object[\"id\"] + \".marcxml.xml\"\n",
    "                downloaded = False\n",
    "                try:\n",
    "                    #recordNode = lcshRecordNodes[loc_object[\"id\"]]\n",
    "                    with open(local_loc_source, encoding=\"utf-8\") as f:\n",
    "                        recordNode = ET.parse(f)\n",
    "                except OSError as e:\n",
    "                    # haetaan kongressin kirjastosta tarvittava tiedosto ja tallennetaan se\n",
    "                    try:\n",
    "                        with urllib.request.urlopen(loc_object[\"prefix\"] + loc_object[\"id\"] + \".marcxml.xml\") as marcxml, \\\n",
    "                            open(local_loc_source, 'wb') as out_file:\n",
    "                            shutil.copyfileobj(marcxml, out_file)\n",
    "                            logging.info(\"Downloaded LCSH link to %s.\" %\n",
    "                                (local_loc_source))\n",
    "                            downloaded = True\n",
    "                    except urllib.error.URLError as e:\n",
    "                        logging.warning('Unable to load the marcxml for %s. Reason: %s. Skipping the property for concept %s.' %\n",
    "                            (loc_object[\"id\"], e.reason, concept))\n",
    "                    except OSError as e:\n",
    "                        logging.warning(\"Failed to create a file for %s under %s directory. Skipping the property for concept %s.\" %\n",
    "                            (loc_object[\"id\"], cs.get(\"locDirectory\"), concept))\n",
    "                except ET.ParseError as e:\n",
    "                    logging.warning(\"Failed to parse the following file: %s. Skipping the property for concept %s.\" %\n",
    "                            (local_loc_source, concept))\n",
    "                \n",
    "                if downloaded:\n",
    "                    try:\n",
    "                        with open(local_loc_source, encoding=\"utf-8\") as f:\n",
    "                            recordNode = ET.parse(f)\n",
    "                    except OSError as e:\n",
    "                        logging.warning(\"Failed to read the file for %s under %s directory. Skipping the property for concept %s\" %\n",
    "                            (loc_object[\"id\"], cs.get(\"locDirectory\"), concept))\n",
    "                    except ET.ParseError as e:\n",
    "                        logging.warning(\"Failed to parse the following file: %s. Skipping the property for concept %s.\" %\n",
    "                            (local_loc_source, concept))\n",
    "                            \n",
    "                \n",
    "                if recordNode:\n",
    "                    tagNode = None\n",
    "\n",
    "                    for tagNumber in LCSH_1XX_FIELDS:\n",
    "                        tagNode = recordNode.find(\"./marcxml:datafield[@tag='\" + tagNumber + \"']\", ET_namespaces)\n",
    "                        if tagNode:\n",
    "                            # otetaan ensimmäinen\n",
    "                            break\n",
    "\n",
    "                    if tagNode:\n",
    "                        tag = \"7\" + tagNode.attrib[\"tag\"][1:]\n",
    "                        first_indicator = tagNode.attrib[\"ind1\"]\n",
    "                        subfields = []\n",
    "\n",
    "                        for child in tagNode:\n",
    "                            subfields.extend((child.attrib[\"code\"], \n",
    "                                              decomposedÅÄÖtoUnicodeCharacters(unicodedata.normalize(NORMALIZATION_FORM, str(child.text)))\n",
    "                                              #str(child.text)\n",
    "                                             ))\n",
    "\n",
    "                        subfields.extend((\"4\", sub4))\n",
    "                        if second_indicator == \"7\":\n",
    "                            subfields.extend((\"2\", sub2))\n",
    "                        subfields.extend((\"0\", str(matchURIRef)))\n",
    "\n",
    "                        fields.append(\n",
    "                            Field(\n",
    "                                tag = tag,\n",
    "                                indicators = [first_indicator, second_indicator],\n",
    "                                subfields = subfields\n",
    "                            )\n",
    "                        )\n",
    "\n",
    "                    else:\n",
    "                        logging.warning(\"Could not find any marcxml:datafield objects with a tag number in the following list: %s for the following record: %s. %s\" %\n",
    "                          (LCSH_1XX_FIELDS, loc_object[\"id\"], \"Skipping the property for concept \" + concept + \".\"))\n",
    "                        #continue\n",
    "\n",
    "            else:\n",
    "                #käsitellään kaikki muut sanastot paitsi lcsh & lcgf\n",
    "                prefLabel = None\n",
    "                multipleLanguages = False\n",
    "                languagesEncountered = set()\n",
    "                sortedPrefLabels = sorted(g2.preferredLabel(matchURIRef,\n",
    "                                        labelProperties=(SKOS.prefLabel,)))\n",
    "                for label in sortedPrefLabels:\n",
    "                    languagesEncountered.add(label[1].language)\n",
    "                    if len(languagesEncountered) > 1:\n",
    "                        multipleLanguages = True\n",
    "                        break\n",
    "                    \n",
    "                processedLanguages = set()             \n",
    "                for type2, prefLabel in sortedPrefLabels:\n",
    "                    \n",
    "                    prefLabelLanguage = prefLabel.language if prefLabel.language != None else \"\"\n",
    "                    \n",
    "                    if prefLabelLanguage:\n",
    "                        if LANGUAGES.get(prefLabelLanguage):\n",
    "                            pass\n",
    "                        else:\n",
    "                            if not cs.getboolean(\"ignoreOtherGraphWarnings\", fallback=IGNOREOTHERGRAPHWARNINGS):\n",
    "                                logging.warning(\"LANGUAGES dictionary has no key for language '%s' found from the skos:prefLabel %s of target %s. Skipping.\" %\n",
    "                                    (prefLabelLanguage, matchURIRef, concept))\n",
    "                            continue\n",
    "                    \n",
    "                    if prefLabelLanguage in processedLanguages:\n",
    "                        if not cs.getboolean(\"ignoreOtherGraphWarnings\", fallback=IGNOREOTHERGRAPHWARNINGS):\n",
    "                            logging.warning(\"Multiple prefLabels detected for target %s in language %s. Skipping prefLabel %s.\" %\n",
    "                          (matchURIRef, prefLabelLanguage, prefLabel))\n",
    "                        continue\n",
    "\n",
    "                    processedLanguages.add(prefLabelLanguage)\n",
    "                    \n",
    "                    subfields = [\n",
    "                        'a', decomposedÅÄÖtoUnicodeCharacters(unicodedata.normalize(NORMALIZATION_FORM, str(prefLabel))),\n",
    "                        #'a', str(prefLabel),\n",
    "                        '4', sub4\n",
    "                    ]\n",
    "                    \n",
    "                    \n",
    "                    if prefLabelLanguage == \"\":\n",
    "                        multipleLanguagesEnd = \"\"\n",
    "                    else:\n",
    "                        # kovakoodattu yso & slm tännekin\n",
    "                        multipleLanguagesEnd = \"/\" + LANGUAGES[prefLabel.language] if sub2 in [\"yso\", \"slm\"] or multipleLanguages else \"\"\n",
    "                    if second_indicator != \"4\":\n",
    "                        subfields.extend((\"2\", \n",
    "                            sub2 + multipleLanguagesEnd\n",
    "                        ))\n",
    "                        \n",
    "                    subfields.extend((\"0\", str(matchURIRef)))\n",
    "                    \n",
    "                    fields.append(\n",
    "                        Field(\n",
    "                            tag=tag,\n",
    "                            indicators = [' ', second_indicator],\n",
    "                            subfields = subfields\n",
    "                        )\n",
    "                    )\n",
    "\n",
    "                if not prefLabel and not cs.getboolean(\"ignoreOtherGraphWarnings\", fallback=IGNOREOTHERGRAPHWARNINGS): \n",
    "                    logging.warning(\"Could not find preflabel for target %s. Skipping property %s target for concept %s.\" %\n",
    "                      (str(matchURIRef), str(valueProp.prop), concept))\n",
    "                    #continue\n",
    "        \n",
    "        # sort fields and add them\n",
    "        for sorted_field in sorted(fields, key=lambda o: (\n",
    "            o.tag,\n",
    "            o.value().lower()\n",
    "            )):\n",
    "            rec.add_field(sorted_field)\n",
    "\n",
    "        # Konversion tiedot -> 884\n",
    "\n",
    "        tag = \"884\"\n",
    "        rec.add_field(\n",
    "                        Field(\n",
    "                            tag=tag,\n",
    "                            indicators = [' ', \" \"],\n",
    "                            subfields = [\n",
    "                                'a', CONVERSION_PROCESS,\n",
    "                                'u', CONVERSION_URI\n",
    "                            ]\n",
    "                        )\n",
    "                    )\n",
    "        writer_records_counter += 1\n",
    "        writer.write(rec)\n",
    "\n",
    "    if handle is not sys.stdout:\n",
    "        writer.close()\n",
    "    \n",
    "    # lokitetaan vähän tietoa konversiosta\n",
    "    if helper_variables['keepDeprecated']:\n",
    "        logging.info(\n",
    "            \"Processed %s concepts, from which %s were left out because of deprecation. Wrote %s MARCXML records.\" %\n",
    "            (incrementor, deprecated_counter, writer_records_counter)\n",
    "        )\n",
    "    else:\n",
    "        logging.info(\n",
    "            \"Processed %s concepts. Wrote %s MARCXML records.\" %\n",
    "            (incrementor, writer_records_counter)\n",
    "        )\n",
    "    \n",
    "    # also write to stdout if it is spesified except in the case of IPython instance with explicit output\n",
    "    try:\n",
    "        if not sys.stdout.isatty() and cs.get(\"output\", fallback=None) != None:\n",
    "            diverted = False\n",
    "            try:\n",
    "                __IPYTHON__\n",
    "                if cs.get(\"outputSpecified\", fallback=None) == None:\n",
    "                    diverted = True\n",
    "                    raise Exception(\"Raising Exception - diverting code flow.\")\n",
    "                pass\n",
    "            except Exception:\n",
    "                outputChannel = sys.stdout if diverted else sys.stdout.buffer\n",
    "                \n",
    "                if helper_variables.get(\"outputFileName\"):\n",
    "                    with open(helper_variables.get(\"outputFileName\"), \"rb\") as f:\n",
    "                        shutil.copyfileobj(f, outputChannel)\n",
    "                else:\n",
    "                    with open(cs.get(\"output\", fallback=defaultOutputFileName), \"rb\") as f:\n",
    "                        shutil.copyfileobj(f, outputChannel)\n",
    "    except ValueError:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Processing vocabulary with vocabulary code 'slm' in language 'fi'\n",
      "INFO:root:Processing 1000th concept\n",
      "INFO:root:Processed 1189 concepts, from which 0 were left out because of deprecation. Wrote 1189 MARCXML records.\n"
     ]
    }
   ],
   "source": [
    "# MAIN\n",
    "\n",
    "sys.argv = [\n",
    "    '--input', '../Finto-data/vocabularies/slm/slm-skos.ttl',\n",
    "    \"-o\", \"testinki4.txt\", # eksplisiittinen -o estää IPythonissa outputtia tulostumasta näytölle\n",
    "    #\"-m\",\n",
    "    \"--vocabulary_code\", \"slm\",\n",
    "    #\"-e\", \"http://api.dev.finto.fi/sparql\",\n",
    "    #\"--loc_directory\", \"lcsh/\",\n",
    "    \"--languages\", \"fi\",\n",
    "    #\"-log\", \"yso2marc.log\",\n",
    "    #\"-c\", \"config.ini\",\n",
    "    #'-cs', \"yso-paikat\",\n",
    "    #\"-eg\", \" \".join([YSO]),\n",
    "    #\"-keepDeprecatedAfter\", \"NONE\",\n",
    "    \"--ignore_other_graph_warnings\",\n",
    "    ]\n",
    "       \n",
    "\n",
    "def main():\n",
    "    settings = ConfigParser(interpolation=ExtendedInterpolation())\n",
    "    args = readCommandLineArguments()\n",
    "    \n",
    "    if args.config:\n",
    "        settings.read(args.config)\n",
    "    else:\n",
    "        settings.add_section(args.vocabulary_code.upper())\n",
    "    \n",
    "    # for extracting meaningful leading/trailing spaces\n",
    "    # (removing double quotes around the string)\n",
    "    for sec in settings.sections():\n",
    "        for (key, val) in settings.items(sec):\n",
    "            if len(val) > 0 and val[-1] == '\"' and val[0] == '\"':\n",
    "                settings.set(sec, key, val[1:-1])\n",
    "\n",
    "    cs = args.vocabulary_code.upper() # default config section to vocabulary code\n",
    "    settings.set(\"DEFAULT\", \"vocabulary_code\", cs.lower())\n",
    "    # Used in MARC code used in tag 040 subfield f\n",
    "    # and 7XX foreign language prefLabels\n",
    "    \n",
    "    graphi = Graph()\n",
    "    other_graphs = Graph()\n",
    "\n",
    "    if args.config_section:\n",
    "        # override default config section\n",
    "        cs = args.config_section.upper()\n",
    "    \n",
    "    # prepare settings\n",
    "    \n",
    "    # configure logging\n",
    "    \n",
    "    loglevel = logging.INFO\n",
    "    logFormatter = logging.Formatter('%(levelname)s - %(message)s')\n",
    "    logging.basicConfig(level=logging.INFO,\n",
    "        format='%(levelname)s - %(message)s',\n",
    "    )\n",
    "    \n",
    "    loglevel = logging.INFO\n",
    "    logFormatter = logging.Formatter('%(levelname)s - %(message)s')\n",
    "    logging.basicConfig(level=logging.INFO,\n",
    "        format='%(levelname)s - %(message)s',\n",
    "    )\n",
    "    \n",
    "    logger = logging.getLogger()\n",
    "    logger.setLevel(loglevel)\n",
    "    \n",
    "    try:\n",
    "        __IPYTHON__\n",
    "        for handler in logger.handlers:\n",
    "            logger.removeHandler(handler)\n",
    "            logger.handlers = []\n",
    "    except NameError:\n",
    "        pass\n",
    "    \n",
    "    if args.log_file:\n",
    "        settings.set(cs, \"logfile\", args.log_file)\n",
    "    \n",
    "    if settings.get(cs, \"logfile\", fallback=None) != None:\n",
    "    #if args.log_file:\n",
    "        fileHandler = logging.FileHandler(settings.get(cs, \"logfile\"), mode=\"w\")\n",
    "        fileHandler.setFormatter(logFormatter)\n",
    "        logger.addHandler(fileHandler)\n",
    "    \n",
    "    if len(logger.handlers) > 1 and settings.get(cs, \"logfile\", fallback=None) != None:\n",
    "        logging.info(\"Two standard error streams identified. Writing to both sys.stderr and \" + settings.get(cs, \"logfile\") + \".\")\n",
    "    \n",
    "    if args.endpoint:\n",
    "        settings.set(cs, \"endpoint\", args.endpoint)\n",
    "    \n",
    "    # normalize endpoint graphs\n",
    "    if args.endpoint_graphs:\n",
    "        settings.set(cs, \"endpointGraphs\", \",\".join(readConfigVariable(args.endpoint_graphs, \" \")))\n",
    "    elif settings.get(cs, \"endpointGraphs\", fallback=None) != None:\n",
    "        settings.set(cs, \"endpointGraphs\", \",\".join(readConfigVariable(settings.get(cs, \"endpointGraphs\"), \",\")))\n",
    "    else:\n",
    "        settings.set(cs, \"endpointGraphs\", \",\".join(ENDPOINTGRAPHS))\n",
    "    \n",
    "    if args.ignore_other_graph_warnings:\n",
    "        settings.set(cs, \"ignoreOtherGraphWarnings\", \"true\")\n",
    "    \n",
    "    if args.grouping_classes:\n",
    "        settings.set(cs, \"groupingClasses\", \",\".join(readConfigVariable(args.grouping_classes, \" \")))\n",
    "    elif settings.get(cs, \"groupingClasses\", fallback=None) != None:\n",
    "        settings.set(cs, \"groupingClasses\", \",\".join(readConfigVariable(settings.get(cs, \"groupingClasses\"), \",\")))\n",
    "    else:\n",
    "        settings.set(cs, \"groupingClasses\", \"\")\n",
    "    \n",
    "    if args.input:\n",
    "        settings.set(cs, \"input\", args.input)\n",
    "    \n",
    "    if not sys.stdin.isatty() and args.input:\n",
    "        try:\n",
    "            # sallitaan tämä IPythonin tapauksessa - käsittely alempana\n",
    "            __IPYTHON__\n",
    "        except NameError:\n",
    "            logging.error(\"Both piped data and data with --input detected.\")\n",
    "            sys.exit(2)\n",
    "    \n",
    "    if not settings.get(cs, \"input\", fallback=False) and sys.stdin.isatty():\n",
    "        logging.error(\"Input is required. Either pipe data, set with --input or in configuration file.\")\n",
    "        sys.exit(2)\n",
    "    \n",
    "    if args.input_format:\n",
    "        settings.set(cs, \"inputFormat\", args.input_format)\n",
    "    \n",
    "    if not sys.stdin.isatty():\n",
    "        try:\n",
    "            __IPYTHON__\n",
    "            # mahdollisuus syöttää IPythonissa kummalla tahansa tavalla\n",
    "            # Huom. jos molemmat ovat tyhjiä, tulee lopputuloksestakin \"tyhjä\" = <collection/> (ei virhettä)\n",
    "            if settings.get(cs, \"input\", fallback=None) != None:\n",
    "                graphi += Graph().parse(settings.get(cs, \"input\"), format=settings.get(cs, \"inputFormat\", fallback=\"turtle\"))\n",
    "            graphi += Graph().parse(sys.stdin, format=settings.get(cs, \"inputFormat\", fallback=\"turtle\"))\n",
    "        \n",
    "        except NameError:\n",
    "            graphi += Graph().parse(sys.stdin, format=settings.get(cs, \"inputFormat\", fallback=\"turtle\"))\n",
    "        \n",
    "    else:\n",
    "        graphi += Graph().parse(settings.get(cs, \"input\"), format=settings.get(cs, \"inputFormat\", fallback=\"turtle\"))\n",
    "\n",
    "    if args.output:\n",
    "        settings.set(cs, \"output\", args.output)\n",
    "        settings.set(cs, \"outputSpecified\", \"true\")\n",
    "    \n",
    "    if not sys.stdout.isatty() and settings.get(cs, \"output\", fallback=None) != None:\n",
    "        try:\n",
    "            __IPYTHON__\n",
    "            if settings.get(cs, \"outputSpecified\", fallback=False) == False:\n",
    "                raise Exception(\"Raising Exception - diverting code flow.\")\n",
    "        except Exception:\n",
    "            logging.info(\"Two standard output streams identified. Writing to both sys.stdout and \" + settings.get(cs, \"output\") + \".\")\n",
    "    \n",
    "    if args.languages != None:\n",
    "        settings.set(cs, \"languages\", \",\".join(readConfigVariable(args.languages, \" \")))\n",
    "    elif settings.get(cs, \"languages\", fallback=None) == None:\n",
    "        logging.error(\"Language is required. Set with --languages.\")\n",
    "        sys.exit(2)\n",
    "    else:\n",
    "        settings.set(cs, \"languages\", \",\".join(readConfigVariable(settings.get(cs, \"languages\"), \",\")))\n",
    "    \n",
    "    # stdout ja useita kieliä -> estä ajo, paitsi jos kyseessä on iPython\n",
    "    if len(settings.get(cs, \"languages\").split(\",\")) > 1 and not sys.stdout.isatty():\n",
    "        try:\n",
    "            __IPYTHON__\n",
    "        except NameError:\n",
    "            logging.error(\"Multiple languages asked to be processed; however, standard out stream is declared. Cannot generate multiple files into standard out stream.\")\n",
    "            sys.exit(2)\n",
    "        \n",
    "    if args.multilanguage_vocabulary:\n",
    "        settings.set(cs, \"multilanguage\", \"true\")\n",
    "    \n",
    "    if args.loc_directory:\n",
    "        settings.set(cs, \"locDirectory\", args.loc_directory)\n",
    "    # lisätään mahdollinen puuttuva kauttamerkki. TODO: hallinta '\\'-merkeille?\n",
    "    if settings.get(cs, \"locDirectory\", fallback=None) != None:\n",
    "        if settings.get(cs, \"locDirectory\")[-1] != \"/\":\n",
    "            settings.set(cs, \"locDirectory\", settings.get(cs, \"locDirectory\") + \"/\")\n",
    "    \n",
    "    if args.default_creation_date:\n",
    "        settings.set(cs, \"defaultCreationDate\", args.default_creation_date)\n",
    "            \n",
    "    if args.keep_deprecated_after:\n",
    "        settings.set(cs, \"keepDeprecatedAfter\", args.keep_deprecated_after)\n",
    "    if settings.get(cs, \"defaultCreationDate\", fallback=None) != None:\n",
    "        try:\n",
    "            datetime.date(datetime.strptime(settings.get(cs, \"defaultCreationDate\"), \"%Y-%m-%d\"))\n",
    "        except ValueError:\n",
    "            logging.error(\"Cannot interpret 'defaultCreationDate' value set in configuration file or given as a CLI parameter. Possible values: ISO 8601 format for dates.\")\n",
    "            sys.exit(2)\n",
    "\n",
    "    if settings.get(cs, \"keepDeprecatedAfter\", fallback=None) != None:\n",
    "        deprecationLimit = settings.get(cs, \"keepDeprecatedAfter\")\n",
    "        if deprecationLimit.lower() == \"all\":\n",
    "            pass\n",
    "        elif deprecationLimit.lower() == \"none\":\n",
    "            pass\n",
    "        else:\n",
    "            try:\n",
    "                datetime.date(datetime.strptime(deprecationLimit, \"%Y-%m-%d\"))\n",
    "            except ValueError:\n",
    "                logging.error(\"Cannot interpret 'keepDeprecatedAfter' value set in configuration file or given as a CLI parameter. Possible values are 'ALL', 'NONE' and ISO 8601 format for dates.\")\n",
    "                sys.exit(2)\n",
    "    \n",
    "    if settings.get(cs, \"endpointGraphs\"):\n",
    "        if settings.get(cs, \"endpoint\", fallback=None) == None:\n",
    "            logging.warning(\"No endpoint address for endpoint graphs (set with --endpoint). Skipping endpoint graphs.\")\n",
    "        else:\n",
    "            other_graphs += readEndpointGraphs(settings[cs])\n",
    "            pass\n",
    "    \n",
    "    for lang in settings.get(cs, \"languages\").split(\",\"):\n",
    "        convert(settings[cs], lang, graphi, other_graphs)\n",
    "    \n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
