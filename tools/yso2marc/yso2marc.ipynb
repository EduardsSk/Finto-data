{
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  },
  "name": ""
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#!/usr/bin/env python3\n",
      "\n",
      "from rdflib import Graph, Namespace, URIRef, BNode, Literal, RDF\n",
      "from rdflib.namespace import SKOS, XSD, OWL, DC\n",
      "from rdflib.namespace import DCTERMS as DCT\n",
      "from SPARQLWrapper import SPARQLWrapper, SPARQLExceptions\n",
      "#from SPARQLWrapper.SPARQLExceptions import EndpointNotFound\n",
      "from pymarc import Record, Field, XMLWriter, MARCReader\n",
      "import xml.etree.ElementTree as ET\n",
      "import shutil\n",
      "\n",
      "import argparse\n",
      "import unicodedata\n",
      "from configparser import ConfigParser, RawConfigParser, ExtendedInterpolation\n",
      "import sys\n",
      "import logging\n",
      "from datetime import datetime, timedelta, date\n",
      "import subprocess\n",
      "import urllib\n",
      "from collections import namedtuple, Sequence\n",
      "from html.parser import HTMLParser\n",
      "\n",
      "CONVERSION_PROCESS = \"Finto SKOS to MARC 0.72\"\n",
      "CONVERSION_URI = \"https://www.kiwi.fi/x/XoK6B\" # konversio-APIn uri tai muu dokumentti, jossa kuvataan konversio\n",
      "CREATOR_AGENCY = \"FI-NL\" # Tietueen luoja/omistaja & luetteloiva organisaatio, 003 & 040 kentat\n",
      "\n",
      "#LOGGER = None\n",
      "\n",
      "KEEPDEPRECATED = True\n",
      "DEFAULTCREATIONDATE = \"1980-01-01\"\n",
      "DEPRECATIONLIMIT = datetime.date(datetime.strptime(\"09.08.2018\", \"%d.%m.%Y\"))\n",
      "DEPRECATIONLIMIT = \"2018-08-09\"\n",
      "ENDPOINT_ADDRESS = \"http://api.dev.finto.fi/sparql\"\n",
      "OTHERGRAPHS = []\n",
      "IGNOREOTHERGRAPHS = True\n",
      "NORMALIZATION_FORM = \"NFD\"\n",
      "\n",
      "#SKOS=Namespace('http://www.w3.org/2004/02/skos/core#')\n",
      "YSO=Namespace('http://www.yso.fi/onto/yso/')\n",
      "YSOMETA=Namespace('http://www.yso.fi/onto/yso-meta/')\n",
      "YSOPAIKATGRAPH=Namespace(\"http://www.yso.fi/onto/yso-paikat/\")\n",
      "YSA=Namespace('http://www.yso.fi/onto/ysa/')\n",
      "YSAMETA=Namespace('http://www.yso.fi/onto/ysa-meta/')\n",
      "ALLARS=Namespace('http://www.yso.fi/onto/allars/')\n",
      "ALLARSMETA=Namespace(\"http://www.yso.fi/onto/allars-meta/\")\n",
      "KOKO=Namespace('http://www.yso.fi/onto/koko/')\n",
      "LCSH = Namespace(\"http://id.loc.gov/authorities/subjects/\")\n",
      "LCGF = Namespace(\"http://id.loc.gov/authorities/genreForms/\")\n",
      "RDAU=Namespace('http://rdaregistry.info/Elements/u/')\n",
      "ISOTHES=Namespace('http://purl.org/iso25964/skos-thes#')\n",
      "SKOSEXT=Namespace('http://purl.org/finnonto/schema/skosext#')\n",
      "SLM=Namespace(\"http://urn.fi/URN:NBN:fi:au:slm:\")\n",
      "UDC=Namespace(\"http://udcdata.info/\")\n",
      "\n",
      "LANGUAGES = {\n",
      "    'fi': 'fin',\n",
      "    'sv': 'swe',\n",
      "    'en': 'eng',\n",
      "    'de': 'ger',\n",
      "    'et': 'est',\n",
      "    'fr': 'fre',\n",
      "    'it': 'ita',\n",
      "    'ru': 'rus',\n",
      "#    'se': 'sme', # pohjoissaami\n",
      "    'sme': 'sme', # pohjoissaami\n",
      "    'sma': 'sma', # etalasaami\n",
      "    'smn': 'smn', # inarinsaami,\n",
      "    'sms': 'sms', # koltansaami,\n",
      "    'smj': 'smj', # luulajansaami\n",
      "}\n",
      "\n",
      "#LCSH m\u00e4p\u00e4tt\u00e4v\u00e4t 1xx-kent\u00e4t\n",
      "LCSH_1XX_FIELDS = [\"100\", \"110\", \"111\", \"130\", \"147\", \"148\", \"150\", \"151\", \"155\", \"162\", \"180\", \"181\", \"182\", \"185\"]\n",
      "\n",
      "TRANSLATIONS = {\n",
      "    SKOSEXT.partOf: {\n",
      "        \"fi\": \"osa kokonaisuutta/k\u00e4sitett\u00e4\",\n",
      "        \"sv\": \"\u00e4r en del av\",\n",
      "        \"en\": \"is part of\"\n",
      "    },\n",
      "    \"682iDEFAULT\": {\n",
      "        \"fi\": \"K\u00e4yt\u00f6st\u00e4 poistetun termin korvaava termi\",\n",
      "        \"sv\": \"Termen som ers\u00e4ttar den avlagda termen\",\n",
      "        \"en\": \"Term replacing the deprecated term\"\n",
      "    },\n",
      "    \"688aCREATED\": {\n",
      "        \"fi\": \"Luotu\",\n",
      "        \"sv\": \"Skapad\",\n",
      "        \"en\": \"Created\"\n",
      "    },\n",
      "    \"688aMODIFIED\": {\n",
      "        \"fi\": \"Viimeksi muokattu\",\n",
      "        \"sv\": \"Senast editerad\",\n",
      "        \"en\": \"Last modified\"\n",
      "    }\n",
      "}\n",
      "\n",
      "# arvot tulevat osakentan $w 1. merkkipaikkaan\n",
      "SEEALSOPROPS = {\n",
      "    SKOS.broader : 'g',\n",
      "    SKOS.narrower : 'h',\n",
      "    SKOS.related : 'n',\n",
      "    RDAU.P60683 : 'a',\n",
      "    RDAU.P60686 : 'b',\n",
      "    SKOSEXT.partOf : 'i',\n",
      "    ISOTHES.broaderPartitive : \"g\",\n",
      "    ISOTHES.narrowerPartitive : \"h\"\n",
      "}\n",
      "\n",
      "SORT_5XX_W_ORDER = {\n",
      "    'g': '001',\n",
      "    'h': '002',\n",
      "    'n': '003',\n",
      "    'i': '004',\n",
      "    'a': '005',\n",
      "    'b': '006'\n",
      "}\n",
      "\n",
      "#katso-viittauksen kent\u00e4n tyyppi - selite\n",
      "TERMGROUP = {\n",
      "    SKOS.altLabel: {\n",
      "        \"fi\": \"ohjaustermi\",\n",
      "        \"sv\": \"h\u00e4nvisningsterm\",\n",
      "        \"en\": \"entry term\"\n",
      "    },\n",
      "    SKOS.hiddenLabel: {\n",
      "        \"fi\": \"piilotermi\",\n",
      "        \"sv\": \"dold term\",\n",
      "        \"en\": \"hidden term\"\n",
      "    },\n",
      "    YSOMETA.singularPrefLabel: {\n",
      "        \"fi\": \"k\u00e4ytett\u00e4v\u00e4n termin yksikk\u00f6muoto\",\n",
      "        \"sv\": \"f\u00f6redragen term i singular\",\n",
      "        \"en\": \"singular entry term\"\n",
      "    },\n",
      "    YSOMETA.singularAltLabel: {\n",
      "        \"fi\": \"ohjaustermin yksikk\u00f6muoto\",\n",
      "        \"sv\": \"h\u00e4nvisningsterm term i singular\",\n",
      "        \"en\": \"singular entry term\"\n",
      "    }\n",
      "}\n",
      "\n",
      "# paikka 5, 'n' = uusi, 'c' = muuttunut/korjattu, d = poistettu (ei seuraajia), x = 1 seuraaja, s = >= 2 seuraajaa\n",
      "LEADERNEW = '00000nz  a2200000n  4500'\n",
      "LEADERCHANGED = '00000cz  a2200000n  4500'\n",
      "LEADERDELETED0 = '00000dz  a2200000n  4500'\n",
      "LEADERDELETED1 = '00000xz  a2200000n  4500'\n",
      "LEADERDELETED2 = '00000sz  a2200000n  4500'\n",
      "# paikka 10 pitaisiko olla 'z' = muut luettelointisaannot?\n",
      "# paikka 17, pitaisiko taydentaa asialisamaareen tyyppi\n",
      "# (aihe, aika, paikka, kieli, soveltumaton)\n",
      "# paikka 29, pitaako koodata?\n",
      "CATALOGCODES = '|n|anznnbabn           | ana      '\n",
      "CATALOGCODES_NA = '|n|enznnbbbn           | ana      '\n",
      "\n",
      "GROUPINGCLASSES = [ISOTHES.ConceptGroup, ISOTHES.ThesaurusArray,\n",
      "            #YSOMETA.Hierarchy,\n",
      "            SKOS.Collection]"
     ],
     "language": "python",
     "metadata": {
      "scrolled": true
     },
     "outputs": [],
     "prompt_number": 4
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "sys.argv = ['yso2marc', \n",
      "          '../Finto-data/vocabularies/yso/yso-skos.ttl',\n",
      "            \"yso\",\n",
      "           \"sv\",\n",
      "            ]\n",
      "VOCABCODE = \"yso\"\n",
      "NODEFAULTCREATIONDATE = False\n",
      "IGNOREOTHERGRAPHS = True\n",
      "DEFAULTCREATIONDATE = \"1980-01-01\"\n",
      "OTHERGRAPHS = [YSOPAIKATGRAPH, YSA, ALLARS]\n",
      "# TODO: mik\u00e4 tiedosto ladattiin (parametrina), yso, yso-paikat, seko, genre"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": null
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "sys.argv = ['yso2marc', \n",
      "          '../Finto-data/vocabularies/slm/slm-skos.ttl',\n",
      "            \"slm\",\n",
      "           \"sv\",\n",
      "            ]\n",
      "VOCABCODE = \"slm\"\n",
      "NODEFAULTCREATIONDATE = True\n",
      "DEFAULTCREATIONDATE = \"2018-11-21\"\n",
      "IGNOREOTHERGRAPHS = True\n",
      "#OTHERGRAPHS = [YSA, YSO, ALLARS]\n",
      "OTHERGRAPHS = []\n",
      "g2 = Graph()\n",
      "# TODO: mik\u00e4 tiedosto ladattiin (parametrina), yso, yso-paikat, seko, genre"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 28
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "sys.argv = ['yso2marc', \n",
      "          '../Finto-data/vocabularies/yso-paikat/yso-paikat-skos.ttl',\n",
      "            \"yso-paikat\",\n",
      "           \"sv\",\n",
      "            ]\n",
      "\n",
      "VOCABCODE = \"yso\"\n",
      "NODEFAULTCREATIONDATE = False\n",
      "DEFAULTCREATIONDATE = \"1980-01-01\"\n",
      "IGNOREOTHERGRAPHS = True\n",
      "OTHERGRAPHS = [YSA, ALLARS]\n",
      "# TODO: mik\u00e4 tiedosto ladattiin (parametrina), yso, yso-paikat, seko, genre"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 14
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "sys.argv = ['yso2marc', \n",
      "          '../Finto-data/vocabularies/udcs/udcs-skos.ttl',\n",
      "            \"udc\",\n",
      "           \"fi\",\n",
      "            ]\n",
      "\n",
      "VOCABCODE = \"udc\"\n",
      "NODEFAULTCREATIONDATE = True\n",
      "IGNOREOTHERGRAPHS = True\n",
      "#OTHERGRAPHS = [YSA, ALLARS]\n",
      "# TODO: mik\u00e4 tiedosto ladattiin (parametrina), yso, yso-paikat, seko, genre"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": null
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "g = None\n",
      "g = Graph()\n",
      "g.parse(sys.argv[1], format='turtle')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": null
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from SPARQLWrapper import SPARQLWrapper\n",
      "\n",
      "sparql = SPARQLWrapper(ENDPOINT_ADDRESS)\n",
      "queryStart = \"\"\"\n",
      "PREFIX skos: <http://www.w3.org/2004/02/skos/core#>\n",
      "PREFIX owl: <http://www.w3.org/2002/07/owl#>\n",
      "PREFIX yso: <http://www.yso.fi/onto/yso/>\n",
      "PREFIX yso-paikat: <http://www.yso.fi/onto/yso-paikat/>\n",
      "PREFIX ysa: <http://www.yso.fi/onto/ysa/>\n",
      "PREFIX ysameta: <http://www.yso.fi/onto/ysa-meta/>\n",
      "PREFIX allars: <http://www.yso.fi/onto/allars/>\n",
      "PREFIX allarsmeta: <http://www.yso.fi/onto/allars-meta/>\n",
      "CONSTRUCT {\n",
      "    ?concept skos:prefLabel ?prefLabel .\n",
      "    ?concept skos:inScheme ?inScheme .\n",
      "    ?concept owl:deprecated ?deprecated .\n",
      "    ?concept a ?types .\n",
      "}\"\"\"\n",
      "\n",
      "queryFrom = \"\"\n",
      "for other_graph in OTHERGRAPHS:\n",
      "    queryFrom = queryFrom + \"\\nFROM <\" + str(other_graph) + \">\"\n",
      "    \n",
      "#FROM yso-paikat:\n",
      "#FROM ysa:\n",
      "#FROM allars:\n",
      "\n",
      "queryEnd = \"\"\"\n",
      "WHERE {\n",
      "  ?concept a skos:Concept .\n",
      "  ?concept skos:prefLabel ?prefLabel .\n",
      "  ?concept a ?types .\n",
      "  \n",
      "  OPTIONAL {?concept skos:inScheme ?inScheme .}\n",
      "  OPTIONAL {?concept owl:deprecated ?deprecated .}\n",
      "}\n",
      "\"\"\"\n",
      "#print(queryStart + queryFrom + queryEnd)\n",
      "#return\n",
      "sparql.setQuery(queryStart + queryFrom + queryEnd)\n",
      "# TODO: kielifiltter\u00f6inti (toteutus tod. n\u00e4k. helpompi graafin l\u00e4pik\u00e4ynniss\u00e4)\n",
      "# TODO: muokkaa kysely\u00e4 sen mukaan, mik\u00e4 tiedosto luetaan - FROM-lauseet\n",
      "# TODO: 4 eri tiedostoa; yso, yso-paikat, seko, genre\n",
      "sparql.setMethod(\"GET\")\n",
      "if (len(OTHERGRAPHS) == 0):\n",
      "    g2 = Graph()\n",
      "else:\n",
      "    g2 = sparql.query().convert()\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": null
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# MAIN\n",
      "\n",
      "def main():\n",
      "    #for i in globals():\n",
      "    #    print(i)\n",
      "    if len(sys.argv) < 4:\n",
      "        logging.error(\"Usage: python3 yso2marc2.py file outputfilename language generateAllLanguages=False\")\n",
      "        return\n",
      "    PRIMARYLANG = sys.argv[3]\n",
      "    convert_others = sys.argv[4] if len(sys.argv) > 4 else False\n",
      "    if convert_others:\n",
      "        for lang in LANGUAGES:\n",
      "            convert(lang, sys.argv[2], keepDeprecated=False, lcshDirectory=\"lcsh/\")\n",
      "    else:\n",
      "        convert(PRIMARYLANG, sys.argv[2], keepDeprecated=False, lcshDirectory=\"lcsh/\")\n",
      "    \n",
      "if __name__ == \"__main__\":\n",
      "    main()\n",
      "    \n"
     ],
     "language": "python",
     "metadata": {
      "scrolled": true
     },
     "outputs": [],
     "prompt_number": 29
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "len(graphi)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 18
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def testi():\n",
      "    concept = YSO.p108544\n",
      "    g = globals()[\"graphi\"]\n",
      "    handle = open(\"kirjoita.txt\", \"wb\")\n",
      "    writer = XMLWriter(handle)\n",
      "    rec = Record()   \n",
      "    \n",
      "    for valueProp in getValues(g, concept, DC.source, language=\"fi\"):\n",
      "        \n",
      "        \n",
      "        subfields = [\n",
      "                'a',\n",
      "                decomposed\u00c5\u00c4\u00d6toUnicodeCharacters(unicodedata.normalize(NORMALIZATION_FORM, str(valueProp.value)))\n",
      "                #str(valueProp.value)\n",
      "        ]\n",
      "        rec.add_field(\n",
      "            Field(\n",
      "                tag='670',\n",
      "                indicators = [' ', ' '],\n",
      "                subfields = subfields\n",
      "                )\n",
      "        )\n",
      "        \n",
      "    for valueProp in sorted(getValues(g, concept, DC.source, language=\"fi\"),\n",
      "        key=lambda o: str(o.value)):\n",
      "        subfields = [\n",
      "            'a',\n",
      "            decomposed\u00c5\u00c4\u00d6toUnicodeCharacters(unicodedata.normalize(NORMALIZATION_FORM, str(valueProp.value)))\n",
      "            #str(valueProp.value)\n",
      "        ]\n",
      "        rec.add_field(\n",
      "            Field(\n",
      "                tag='670',\n",
      "                indicators = [' ', ' '],\n",
      "                subfields = subfields\n",
      "                )\n",
      "            )\n",
      "    writer.write(rec)\n",
      "    writer.close()\n",
      "    subprocess.run(\"catmandu convert MARC --type XML to MARC --type XML <kirjoita.txt | xmllint --format - >kirjoita-formatted.mrcx\",\n",
      "    stdout=subprocess.PIPE, stderr=subprocess.PIPE, shell=True)\n",
      "\n",
      "testi()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": null
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "graphi = Graph()\n",
      "other_graphs = Graph()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 25
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print(len(graphi))\n",
      "print(len(other_graphs))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 27
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "len(graph)\n",
      "graphi = Graph()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": null
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "kieli = \"sv\"\n",
      "#subprocess.run(\"catmandu convert MARC --type XML to MARC --type XML <testYso.mrcx | xmllint --format - >testYso-\" + kieli + \"-formatted.mrcx\",\n",
      "#    stdout=subprocess.PIPE, stderr=subprocess.PIPE, shell=True)\n",
      "\n",
      "print(\"catmandu convert MARC --type XML to MARC --type XML <testYso-\" + kieli +\".mrcx | xmllint --format - >testYso-\" + kieli + \"-formatted.mrcx\")\n",
      "#subprocess.run(\"catmandu convert MARC --type XML to MARC --type XML <testYso-\" + kieli +\".mrcx | xmllint --format - >testYso-\" + kieli + \"-formatted.mrcx\",\n",
      "#    stdout=subprocess.PIPE, stderr=subprocess.PIPE, shell=True)\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": null
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# MAIN\n",
      "\n",
      "sys.argv = [\n",
      "    '--input', '../Finto-data/vocabularies/slm/slm-skos.ttl',\n",
      "    \"-o\", \"testYso.mrcx\",\n",
      "    #\"-m\",\n",
      "    \"--vocabulary_code\", \"slm\",\n",
      "    #\"-e\", \"http://api.dev.finto.fi/sparql\",\n",
      "    \"--loc_directory\", \"lcsh/\",\n",
      "    \"--languages\", \"sv\",\n",
      "    \"-log\", \"yso2marc.log\",\n",
      "    \"-c\", \"config.ini\",\n",
      "    #'-cs', \"yso-paikat\",\n",
      "    #\"-g\", \" \".join([YSA, ALLARS]),\n",
      "    #\"-g-\", \"fdsa   adffad afdfds\",\n",
      "    \"-keepDeprecatedAfter\", \"NONE\",\n",
      "    \"--ignore_other_graphs\",\n",
      "    ]\n",
      "       \n",
      "print(sys.argv)\n",
      "VOCABCODE = \"yso\"\n",
      "NODEFAULTCREATIONDATE = False\n",
      "DEFAULTCREATIONDATE = \"1980-01-01\"\n",
      "IGNOREOTHERGRAPHS = True\n",
      "OTHERGRAPHS = []\n",
      "#OTHERGRAPHS = [YSA, ALLARS]\n",
      "\n",
      "def readCommandLineArguments():\n",
      "    parser = argparse.ArgumentParser(description=\"Program for converting Finto SKOS-vocabularies into MARC (.mrcx).\")\n",
      "    parser.add_argument(\"-c\", \"--config\",\n",
      "        help=\"Config file location. The key/value pairs defined in the config file are overwritten with possible CLI key/value pairs.\")\n",
      "    parser.add_argument(\"-cs\", \"--config_section\",\n",
      "        help=\"Config section identifier. Set if vocabulary code is different from section identifier.\")    \n",
      "    parser.add_argument(\"-e\", \"--endpoint\", help=\"Endpoint address to be used for querying linked concepts.\")\n",
      "    parser.add_argument(\"-g\", \"--other_graphs\",\n",
      "        help=\"The graphs one wants to query from the endpoint, e.g., http://www.yso.fi/onto/yso/. In case of multiple, separate them with space.\")\n",
      "    parser.add_argument(\"-ignoreG\", \"--ignore_other_graphs\",\n",
      "        help=\"Do you want to limit search for the preferred labels of matched targets to input graph only? Set this flag only if you want to limit the search.\", action=\"store_true\")\n",
      "    parser.add_argument(\"-i\", \"--input\", help=\"Input file location, e.g., yso-skos.ttl\")\n",
      "    parser.add_argument(\"-if\", \"--input_format\", help=\"Input file format. Default: turtle\")\n",
      "    parser.add_argument(\"-o\", \"--output\", help=\"Output file name, e.g., yso.mrcx.\")\n",
      "    parser.add_argument(\"-vocId\", \"--vocabulary_code\", help=\"MARC code used in tag 040 subfield f.\", required=True)\n",
      "    parser.add_argument(\"-lang\", \"--languages\",\n",
      "        help=\"The RDF language tag of the language one is willing to convert. In case of multiple, separate them with space.\")\n",
      "    parser.add_argument(\"-m\", \"--multilanguage_vocabulary\", action='store_true',\n",
      "        help=\"Is the vocabulary using language specified vocabulary codes, e.g., yso/fin? Set this flag only if it is.\")\n",
      "    parser.add_argument(\"-gc\", \"--grouping_classes\",\n",
      "        help=\"Types of classes not meant for describing/cataloging items in the vocabulary, e.g, hierarchical ones. In case of multiple, seperate them with space.\")\n",
      "    parser.add_argument(\"-log\", \"--log_file\", help=\"Log file location.\")\n",
      "    parser.add_argument(\"-locDir\", \"--loc_directory\",\n",
      "        help=\"Library of Congress directory from which to look for and download to LoC marcxml files. One shall not set if one does not want LoC links.\")\n",
      "    parser.add_argument(\"-defaultCreationDate\", \"--default_creation_date\",\n",
      "        help=\"Default creation date (set in YYYY-MM-DD format) for a concept if it has not been declared explicitly. Default: \" + DEFAULTCREATIONDATE)\n",
      "    parser.add_argument(\"-keepDeprecatedAfter\", \"--keep_deprecated_after\",\n",
      "        help=\"Keep deprecated concepts deprecated after (not inclusive) the date given (set in YYYY-MM-DD format). Set to 'ALL' for no limits and 'NONE' to discard all.\")\n",
      "    \n",
      "    args = parser.parse_args(sys.argv)\n",
      "    return args\n",
      "\n",
      "def main():\n",
      "    settings = ConfigParser(interpolation=ExtendedInterpolation())\n",
      "    args = readCommandLineArguments()\n",
      "    \n",
      "    if args.config:\n",
      "        settings.read(args.config)\n",
      "    \n",
      "    # for extracting meaningful leading/trailing spaces\n",
      "    # (removing double quotes around the string)\n",
      "    for sec in settings.sections():\n",
      "        for (key, val) in settings.items(sec):\n",
      "            if len(val) > 0 and val[-1] == '\"' and val[0] == '\"':\n",
      "                settings.set(sec, key, val[1:-1])\n",
      "\n",
      "    cs = args.vocabulary_code.upper() # default config section to vocabulary code\n",
      "    settings.set(\"DEFAULT\", \"vocabulary_code\", cs.lower())\n",
      "    # Used in MARC code used in tag 040 subfield f\n",
      "    # and 7XX foreign language prefLabels\n",
      "    \n",
      "    #graph = Graph()\n",
      "    #other_graphs = Graph()\n",
      "\n",
      "    if args.config_section:\n",
      "        # override default config section\n",
      "        cs = args.config_section.upper()\n",
      "    \n",
      "    # prepare settings\n",
      "    \n",
      "    # configure logging\n",
      "    \n",
      "    loglevel = logging.INFO\n",
      "    logFormatter = logging.Formatter('%(levelname)s - %(message)s')\n",
      "    \n",
      "    #if args.debug:\n",
      "    #    loglevel = logging.DEBUG\n",
      "    #logformat = '%(levelname)s: %(message)s'\n",
      "    #logging.basicConfig(format=logformat, level=loglevel)\n",
      "    \n",
      "    logger = logging.getLogger()\n",
      "    logger.setLevel(loglevel)\n",
      "    \n",
      "    for handler in logger.handlers:\n",
      "        logger.removeHandler(handler)\n",
      "        logger.handlers = []\n",
      "    \n",
      "    #TODO: remove\n",
      "    #args.log_file = None\n",
      "    \n",
      "    if args.log_file:\n",
      "        settings.set(cs, \"logfile\", args.log_file)\n",
      "    \n",
      "    if settings.get(cs, \"logfile\", fallback=None) != None:\n",
      "    #if args.log_file:\n",
      "        fileHandler = logging.FileHandler(settings.get(cs, \"logfile\"), mode=\"w\")\n",
      "        fileHandler.setFormatter(logFormatter)\n",
      "        logger.addHandler(fileHandler)\n",
      "    if not sys.stderr.isatty():\n",
      "        try:\n",
      "            __IPYTHON__\n",
      "            pass\n",
      "        except NameError:\n",
      "            streamHandler = logging.StreamHandler(sys.stderr)\n",
      "            streamHandler.setFormatter(logFormatter)\n",
      "            logger.addHandler(streamHandler) \n",
      "\n",
      "    if len(logger.handlers) > 1:\n",
      "        logging.info(\"Two standard error streams identified. Writing to both sys.stderr and \" + settings.get(cs, \"logfile\") + \".\")\n",
      "    \n",
      "    if args.endpoint:\n",
      "        settings.set(cs, \"endpoint\", args.endpoint)\n",
      "    \n",
      "    # normalize other graphs\n",
      "    if args.other_graphs:\n",
      "        settings.set(cs, \"otherGraphs\", \",\".join(readConfigVariable(args.other_graphs, \" \")))\n",
      "    elif settings.get(cs, \"otherGraphs\", fallback=None) != None:\n",
      "        settings.set(cs, \"otherGraphs\", \",\".join(readConfigVariable(settings.get(cs, \"otherGraphs\"), \",\")))\n",
      "    else:\n",
      "        settings.set(cs, \"otherGraphs\", \",\".join(OTHERGRAPHS))\n",
      "    \n",
      "    if args.ignore_other_graphs:\n",
      "        settings.set(cs, \"ignoreOtherGraphs\", \"true\")\n",
      "    \n",
      "    if args.grouping_classes:\n",
      "        settings.set(cs, \"groupingClasses\", \",\".join(readConfigVariable(args.other_graphs, \" \")))\n",
      "    elif settings.get(cs, \"groupingClasses\", fallback=None):\n",
      "        settings.set(cs, \"groupingClasses\", \",\".join(readConfigVariable(settings.get(cs, \"groupingClasses\"), \",\")))\n",
      "    else:\n",
      "        settings.set(cs, \"groupingClasses\", \"\")\n",
      "    \n",
      "    if args.input:\n",
      "        settings.set(cs, \"input\", args.input)\n",
      "    \n",
      "    if not sys.stdin.isatty() and args.input:\n",
      "        try:\n",
      "            __IPYTHON__\n",
      "            #graphi = globals()[\"graphi\"]\n",
      "            #graphi += Graph().parse(settings.get(cs, \"input\"), format=settings.get(cs, \"inputFormat\", fallback=\"turtle\"))\n",
      "            #return\n",
      "        except NameError:\n",
      "            logging.error(\"Both piped data and data with --input detected.\")\n",
      "            sys.exit(2)\n",
      "    \n",
      "    if not settings.get(cs, \"input\", fallback=True) and sys.stdin.isatty():\n",
      "        logging.error(\"Input is required. Either pipe data, set with --input or in configuration file.\")\n",
      "        sys.exit(2)\n",
      "    \n",
      "    if args.input_format:\n",
      "        settings.set(cs, \"inputFormat\", args.input_format)\n",
      "    \n",
      "    if not sys.stdin.isatty():\n",
      "        try:\n",
      "            __IPYTHON__\n",
      "            #graphi = globals()[\"graphi\"]\n",
      "            #graphi = Graph() # tyhjenn\u00e4\n",
      "            #graphi += Graph().parse(settings.get(cs, \"input\"), format=settings.get(cs, \"inputFormat\", fallback=\"turtle\"))\n",
      "            #graphi = Graph().parse(sys.stdin, format=settings.get(cs, \"inputFormat\", fallback=\"turtle\"))\n",
      "            pass\n",
      "        \n",
      "        except NameError:\n",
      "            #graphi = globals()[\"graphi\"]\n",
      "            #graphi = Graph() # tyhjenn\u00e4\n",
      "            #graphi += Graph().parse(sys.stdin, format=settings.get(cs, \"inputFormat\", fallback=\"turtle\"))\n",
      "            #graphi = Graph().parse(sys.stdin, format=settings.get(cs, \"inputFormat\", fallback=\"turtle\"))\n",
      "            pass\n",
      "        \n",
      "        pass\n",
      "    else:\n",
      "        #graphi = globals()[\"graphi\"]\n",
      "        #graphi = Graph() # tyhjenn\u00e4\n",
      "        #graphi += Graph().parse(settings.get(cs, \"input\"), format=settings.get(cs, \"inputFormat\", fallback=\"turtle\"))\n",
      "        #graphi = Graph().parse(settings.get(cs, \"input\"), format=settings.get(cs, \"inputFormat\", fallback=\"turtle\"))\n",
      "        #return\n",
      "        pass\n",
      "\n",
      "    if args.output:\n",
      "        settings.set(cs, \"output\", args.output)\n",
      "        settings.set(cs, \"outputSpecified\", \"true\")\n",
      "    \n",
      "    if not sys.stdout.isatty() and settings.get(cs, \"output\", fallback=None) != None:\n",
      "        try:\n",
      "            __IPYTHON__\n",
      "            if settings.get(cs, \"outputSpecified\", fallback=False) == False:\n",
      "                raise NameError(\"Raising NameError - diverting code flow.\")\n",
      "        except NameError:\n",
      "            logging.info(\"Two standard output streams identified. Writing to both sys.stdout and \" + settings.get(cs, \"output\") + \".\")\n",
      "    \n",
      "    #print(type(settings.get(cs, \"languages\", fallback=None)))\n",
      "    if args.languages != None:\n",
      "        settings.set(cs, \"languages\", \",\".join(readConfigVariable(args.languages, \" \")))\n",
      "    elif settings.get(cs, \"languages\", fallback=None) == None:\n",
      "        logging.error(\"Language is required. Set with --languages.\")\n",
      "        sys.exit(2)\n",
      "    else:\n",
      "        settings.set(cs, \"languages\", \",\".join(readConfigVariable(settings.get(cs, \"languages\"), \",\")))\n",
      "    \n",
      "    # stdout ja useita kieli\u00e4 -> est\u00e4 ajo, paitsi jos kyseess\u00e4 on iPython\n",
      "    if len(settings.get(cs, \"languages\").split(\",\")) > 1 and not sys.stdout.isatty():\n",
      "        try:\n",
      "            __IPYTHON__\n",
      "            pass\n",
      "        except NameError:\n",
      "            logging.error(\"Multiple languages asked to be processed; however, standard out stream is declared. Cannot generate multiple files into standard out stream.\")\n",
      "            sys.exit(2)\n",
      "            pass\n",
      "        \n",
      "    if args.multilanguage_vocabulary:\n",
      "        settings.set(cs, \"multilanguage\", \"true\")\n",
      "    \n",
      "    if args.loc_directory:\n",
      "        settings.set(cs, \"locDirectory\", args.loc_directory)\n",
      "    # lis\u00e4t\u00e4\u00e4n mahdollinen puuttuva kauttamerkki\n",
      "    if settings.get(cs, \"locDirectory\", fallback=None) != None:\n",
      "        if settings.get(cs, \"locDirectory\")[-1] != \"/\":\n",
      "            settings.set(cs, \"locDirectory\", settings.get(cs, \"locDirectory\") + \"/\")\n",
      "    \n",
      "    if args.default_creation_date:\n",
      "        settings.set(cs, \"defaultCreationDate\", args.default_creation_date)\n",
      "            \n",
      "    if args.keep_deprecated_after:\n",
      "        settings.set(cs, \"keepDeprecatedAfter\", args.keep_deprecated_after)\n",
      "    if settings.get(cs, \"defaultCreationDate\", fallback=None) != None:\n",
      "        try:\n",
      "            datetime.date(datetime.strptime(settings.get(cs, \"defaultCreationDate\"), \"%Y-%m-%d\"))\n",
      "        except ValueError:\n",
      "            logging.error(\"Cannot interpret 'defaultCreationDate' value set in configuration file or given as a CLI parameter. Possible values: ISO 8601 format for dates.\")\n",
      "            sys.exit(2)\n",
      "\n",
      "    if settings.get(cs, \"keepDeprecatedAfter\", fallback=None) != None:\n",
      "        deprecationLimit = settings.get(cs, \"keepDeprecatedAfter\")\n",
      "        if deprecationLimit.lower() == \"all\":\n",
      "            pass\n",
      "        elif deprecationLimit.lower() == \"none\":\n",
      "            pass\n",
      "        else:\n",
      "            try:\n",
      "                datetime.date(datetime.strptime(deprecationLimit, \"%Y-%m-%d\"))\n",
      "            except ValueError:\n",
      "                logging.error(\"Cannot interpret 'keepDeprecatedAfter' value set in configuration file or given as a CLI parameter. Possible values are 'ALL', 'NONE' and ISO 8601 format for dates.\")\n",
      "                sys.exit(2)\n",
      "    \n",
      "    if settings.get(cs, \"otherGraphs\"):\n",
      "        if settings.get(cs, \"endpoint\", fallback=None) == None:\n",
      "            logging.warning(\"No endpoint address for other graphs (set with --endpoint). Skipping other graphs.\")\n",
      "        else:\n",
      "            #other_graphs = globals()[\"other_graphs\"]\n",
      "            #other_graphs += readEndpointGraphs(settings[cs])\n",
      "            pass\n",
      "    \n",
      "    #return\n",
      "    \n",
      "    for lang in settings.get(cs, \"languages\").split(\",\"):\n",
      "        print(lang)\n",
      "        convertNew(settings[cs], lang, graphi, other_graphs)\n",
      "        #return\n",
      "    \n",
      "if __name__ == \"__main__\":\n",
      "    main()\n",
      "    \n"
     ],
     "language": "python",
     "metadata": {
      "scrolled": true
     },
     "outputs": [],
     "prompt_number": 26
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def convertNew(cs, language, graph, other_graphs):\n",
      "    # k\u00e4\u00e4nt\u00e4\u00e4 graafin (graph) kielell\u00e4 (language) ConfigParser-sektion (cs) ohjeiden mukaisesti MARCXML-muotoon\n",
      "    # other_graphs sis\u00e4lt\u00e4\u00e4 vieraat graafit, joista etsit\u00e4\u00e4n k\u00e4ytettyj\u00e4 termej\u00e4 7XX kenttiin\n",
      "    \n",
      "    vocId = cs.get(\"vocabulary_code\")\n",
      "    g = graph\n",
      "    g2 = other_graphs\n",
      "    \n",
      "    # variable for a bit complicated constants and casting/converting them to appropiate types\n",
      "    helper_variables = {\n",
      "        \"vocCode\" : (cs.get(\"vocabulary_code\") + \"/\" + LANGUAGES[language] \\\n",
      "            if cs.getboolean(\"multilanguage\", fallback=False) \\\n",
      "            else vocId),\n",
      "        \"groupingClasses\" : [URIRef(x) for x in cs.get(\"groupingClasses\", fallback=\",\".join(GROUPINGCLASSES)).split(\",\")],\n",
      "        \"groupingClassesDefault\" : [URIRef(x) for x in cs.parser.get(\"DEFAULT\", \"groupingClasses\", fallback=\",\".join(GROUPINGCLASSES)).split(\",\")],\n",
      "        'keepDeprecated' : cs.get(\"keepDeprecatedAfter\", fallback=\"ALL\").lower() != \"none\",\n",
      "        'write688created' : cs.get(\"defaultCreationDate\", fallback=None) != None\n",
      "    }\n",
      "    if helper_variables['keepDeprecated']:   \n",
      "        helper_variables['keepDeprecatedLimit'] = False \\\n",
      "        if cs.get(\"keepDeprecatedAfter\", fallback=\"ALL\").lower() == \"all\" \\\n",
      "        else datetime.date(datetime.strptime(cs.get(\"keepDeprecatedAfter\"), \"%Y-%m-%d\"))\n",
      "    \n",
      "    logging.info(\"Processing vocabulary with vocabulary code '%s' in language '%s'\" % (vocId, language))\n",
      "    #logging.info(\"Processing %s\" % (helper_variables[\"vocCode\"]))\n",
      "    incrementor = 0\n",
      "    deprecated_counter = 0\n",
      "    writer_records_counter = 0\n",
      "    ysoATagParser = ConvertHTMLYSOATags()\n",
      "    ET_namespaces = {\"marcxml\": \"http://www.loc.gov/MARC21/slim\"}\n",
      "    defaultOutputFileName = \"yso2marc-\" + cs.name.lower() + \"-\" + language + \".mrcx\"\n",
      "    \n",
      "    if cs.get(\"output\", fallback=None) == None:\n",
      "        handle = sys.stdout\n",
      "    else:\n",
      "        parts = cs.get(\"languages\").split(\",\")\n",
      "        if len(parts) > 1:\n",
      "            output = cs.get(\"output\")\n",
      "            if len(output.split(\".\")) > 1:\n",
      "                helper_variables[\"outputFileName\"] = \".\".join(output.split(\".\")[:-1]) + \"-\" + language + \".\" + output.split(\".\")[-1]\n",
      "                handle = open(helper_variables[\"outputFileName\"], \"wb\")\n",
      "            else:\n",
      "                helper_variables[\"outputFileName\"] = output + \"-\" + language\n",
      "                handle = open(helper_variables[\"outputFileName\"], \"wb\")\n",
      "        else:\n",
      "            handle = open(cs.get(\"output\", fallback=defaultOutputFileName), \"wb\")\n",
      "        \n",
      "    writer = XMLWriter(handle)\n",
      "    # for concept (a skos:Concept) in graph\n",
      "    for concept in sorted(g.subjects(RDF.type, SKOS.Concept)):\n",
      "        incrementor += 1\n",
      "        if incrementor % 1000 == 0:\n",
      "            logging.info(\"Processing %sth concept\" % (incrementor))\n",
      "            #logging.info(\"Processing %sth concept in language '%s'\" % (incrementor, language))\n",
      "        \n",
      "        # if deprecated, skip\n",
      "        if (concept, OWL.deprecated, Literal(True)) in g:\n",
      "            if not helper_variables['keepDeprecated']:# and \\\n",
      "            #(concept, OWL.deprecated, Literal(True)) in g:\n",
      "                deprecated_counter += 1\n",
      "                continue\n",
      "        \n",
      "        rec = Record()   \n",
      "        deprecatedString = \"\"\n",
      "        # Organisaation ISIL-tunniste -> 003\n",
      "        rec.add_field(\n",
      "            Field(\n",
      "                tag='003',\n",
      "                data = cs.get(\"creatorAgency\", fallback=CREATOR_AGENCY)\n",
      "            )\n",
      "        )\n",
      "        # dct:modified -> 005 EI TULOSTETA, 688 \n",
      "        # tutkitaan, onko k\u00e4site muuttunut vai alkuper\u00e4inen\n",
      "        # ja valitaan leader sen perusteella\n",
      "        mod = g.value(concept, DCT.modified, None)\n",
      "        if mod is None:\n",
      "            rec.leader = cs.get(\"leaderNew\", fallback=LEADERNEW)\n",
      "        else:\n",
      "            rec.leader = cs.get(\"leaderChanged\", fallback=LEADERCHANGED)\n",
      "            modified = mod.toPython() # datetime.date or datetime.datetime object\n",
      "            \n",
      "        # dct:created -> 008\n",
      "        crt = g.value(concept, DCT.created, None)\n",
      "        if crt is None:\n",
      "            created = datetime.date(datetime.strptime(cs.get(\"defaultCreationDate\", fallback=DEFAULTCREATIONDATE), \"%Y-%m-%d\"))\n",
      "        else:\n",
      "            created = crt.toPython() # datetime.date or datetime.datetime object\n",
      "            if type(created) == datetime:\n",
      "                created = datetime.date(created) # datetime.date\n",
      "        \n",
      "        code = cs.get(\"catalogCodes\", fallback=CATALOGCODES)\n",
      "        \n",
      "        for conceptType in g.objects(concept, RDF.type):\n",
      "            if conceptType in helper_variables[\"groupingClasses\"]:\n",
      "                code = cs.get(\"catalogCodes_na\", fallback=CATALOGCODES_NA)\n",
      "                break\n",
      "        if (concept, OWL.deprecated, Literal(True)) in g:\n",
      "            replacers = sorted(g.objects(concept, DCT.isReplacedBy))\n",
      "            if len(replacers) == 0:\n",
      "                rec.leader = cs.get(\"leaderDeleted0\", fallback=LEADERDELETED0)\n",
      "            elif len(replacers) == 1:\n",
      "                rec.leader = cs.get(\"leaderDeleted1\", fallback=LEADERDELETED1)\n",
      "            else:\n",
      "                rec.leader = cs.get(\"leaderDeleted2\", fallback=LEADERDELETED2)\n",
      "             \n",
      "            code = cs.get(\"catalogCodes_na\", fallback=CATALOGCODES_NA)\n",
      "            \n",
      "            # jos on asetettu jokin limitti\n",
      "            if helper_variables['keepDeprecatedLimit']:\n",
      "                # mik\u00e4li scopeNote puuttuu, poistettu tulkitaan uudeksi poistoksi ja sen tulkitaan\n",
      "                # \"ylitt\u00e4v\u00e4n\" DEPRECATIONLIMITin.\n",
      "                for valueProp in sorted(getValues(g, concept, SKOS.scopeNote, language=\"\"),\n",
      "                                                           key=lambda o: str(o.value)):    \n",
      "                    if valueProp.value.startswith(\"deprecated on\"):\n",
      "                        deprecatedString = str(valueProp.value)\n",
      "                        break\n",
      "                if deprecatedString:\n",
      "                    deprecatedDateString = deprecatedString.split(\" \")[-1]\n",
      "                    try:\n",
      "                        # yritet\u00e4\u00e4n parsia p\u00e4iv\u00e4m\u00e4\u00e4r\u00e4 kahdessa eri formaatissa\n",
      "                        deprecatedDate = datetime.date(datetime.strptime(deprecatedDateString, \"%d.%m.%Y\"))\n",
      "                        if helper_variables['keepDeprecatedLimit'] > deprecatedDate:\n",
      "                            continue # skipataan ennen vanhentamisrajaa vanhennetut termit\n",
      "                    except ValueError:\n",
      "                        try:\n",
      "                            deprecatedDate = datetime.date(datetime.strptime(deprecatedDateString, \"%Y-%m-%d\"))\n",
      "                            if helper_variables['keepDeprecatedLimit'] > deprecatedDate:\n",
      "                                continue # skipataan ennen vanhentamisrajaa vanhennetut termit\n",
      "                        except ValueError:\n",
      "                            logging.warning(\"Converting deprecated date failed for concept %s. Proceeding.\" %\n",
      "                          (concept))\n",
      "        \n",
      "        if not helper_variables[\"write688created\"]:\n",
      "            logging.warning(\"No explicit creation date defined for concept %s. Using default value '%s' for character positions 00-05 in tag 008.\" % (concept, DEFAULTCREATIONDATE.strftime('%y%m%d')))\n",
      "\n",
      "        rec.add_field(\n",
      "            Field(\n",
      "                tag='008',\n",
      "                data=created.strftime('%y%m%d') + code\n",
      "            )\n",
      "        )\n",
      "        \n",
      "        # 024 muut standarditunnukset - k\u00e4sitteen URI tallennetaan t\u00e4h\u00e4n\n",
      "        rec.add_field(\n",
      "            Field(\n",
      "                tag='024',\n",
      "                indicators = ['7', ' '],\n",
      "                subfields = [\n",
      "                    'a', concept,\n",
      "                    '2', \"uri\"\n",
      "                ]\n",
      "            )\n",
      "        )\n",
      "        \n",
      "        # 034 paikkojen koordinaatit - yso-paikat?\n",
      "        # 035 yso-tietueen numero?\n",
      "        \n",
      "        # 040 luetteloiva organisaatio\n",
      "        # TODO: tarkista miten vocabcode merkit\u00e4\u00e4n muille kuin YSOlle, muista my\u00f6s muut kent\u00e4t\n",
      "        # Jarmo: ei kielikoodia muille sanastoille?\n",
      "        rec.add_field(\n",
      "            Field(\n",
      "                tag='040',\n",
      "                indicators = [' ', ' '],\n",
      "                subfields = [\n",
      "                    'a', cs.get(\"creatorAgency\", fallback=CREATOR_AGENCY),\n",
      "                    'b', LANGUAGES[language],\n",
      "                    #'e', \"rda\",\n",
      "                    'f', helper_variables[\"vocCode\"]\n",
      "                ]\n",
      "            )\n",
      "        )\n",
      "        # 043 - ysopaikat, kaytetaanko\n",
      "        # http://marc21.kansalliskirjasto.fi/aukt/01X-09X.htm#043\n",
      "        \n",
      "        # 045 - yso-ajanjaksot, kaytetaanko\n",
      "        # http://marc21.kansalliskirjasto.fi/aukt/01X-09X.htm#045\n",
      "        \n",
      "        # 046 - erikoiskoodatut ajanjaksot? \n",
      "        \n",
      "        # 052 - maantieteellinen luokitus\n",
      "        # 7#$a(480)$2udc$0http://udcdata.info/004604\n",
      "        # jos 151 kaytossa, pitaisiko kayttaa? Jarmo: UDC-luokitus, Suomi \"(480)\"\n",
      "        \n",
      "        #ConceptGroup / skos:member -> 065 yso-aihealuekoodi\n",
      "        # vain siina tapauksessa, kun ne halutaan mukaan Asteriin\n",
      "        # jos luokkanumeroa ei l\u00f6ydy, ei tulosteta\n",
      "        # TODO: vain jos vocId = \"yso\", tehd\u00e4\u00e4n t\u00e4m\u00e4\n",
      "        if vocId == \"yso\":\n",
      "            for group in sorted(g.subjects(SKOS.member, concept)):\n",
      "                if not helper_variables['keepDeprecated'] and \\\n",
      "                (group, OWL.deprecated, Literal(True)) in g:\n",
      "                    continue # skip deprecated group concepts\n",
      "                if (group, RDF.type, ISOTHES.ConceptGroup) not in g:\n",
      "                    continue\n",
      "                # group code: first try using skos:notation, otherwise extract from label\n",
      "                groupno = g.value(group, SKOS.notation, None)\n",
      "                if groupno is None:\n",
      "                    valueProps = sorted(getValues(g, group, SKOS.prefLabel, language=language),\n",
      "                                       key=lambda o: o.value)\n",
      "\n",
      "                    if len(valueProps) == 0: \n",
      "                        logging.warning(\"Could not find preflabel for target %s in language: %s. Skipping property %s target for concept %s.\" %\n",
      "                          (group, language, SKOS.member, concept))\n",
      "                        continue\n",
      "                    elif len(valueProps) != 1:\n",
      "                        logging.warning(\"Multiple prefLabels detected for concept %s in language %s. Taking the first only.\" %\n",
      "                          (concept, language)) \n",
      "                    groupname = str(valueProps[0].value)\n",
      "                    try:\n",
      "                        groupno = str(groupname[0:groupname.index(\" \")])\n",
      "                        groupname = str(groupname[len(groupno) + 1:])\n",
      "                    except ValueError:\n",
      "                        logging.warning(\"Tried to parse group number for group %s from preflabel %s in language %s but failed.\" %\n",
      "                          (group, language))\n",
      "                        continue\n",
      "\n",
      "                rec.add_field(\n",
      "                    Field(\n",
      "                           tag='065',\n",
      "                           indicators = [' ', ' '],\n",
      "                           subfields = [\n",
      "                               'a', groupno,\n",
      "                               'c', decomposed\u00c5\u00c4\u00d6toUnicodeCharacters(unicodedata.normalize(NORMALIZATION_FORM, groupname)),\n",
      "                               #'c', groupname,\n",
      "                               '0', group,\n",
      "                               '2', vocId\n",
      "                           ]\n",
      "                    )\n",
      "                )\n",
      "        \n",
      "        # 080 - UDK-luokka. Asiasanaan liittyva UDK-luokka\n",
      "        \n",
      "        # 147 Tapahtuman nimi. Ei kayteta?\n",
      "        \n",
      "        # 148 Aikaa merkitseva termi. Selvitetaan.\n",
      "        \n",
      "        # skos:prefLabel -> 150 aihetta ilmaiseva termi\n",
      "        valueProps = sorted(getValues(g, concept, SKOS.prefLabel, language=language),\n",
      "                                   key=lambda o: o.value)\n",
      "        if len(valueProps) == 0:\n",
      "            logging.warning(\"Could not find preflabel for concept %s in language %s. Skipping the whole concept.\" %\n",
      "              (concept, language))\n",
      "            continue\n",
      "        elif len(valueProps) != 1:\n",
      "            logging.warning(\"Multiple prefLabels detected for concept %s in language %s. Choosing the first.\" %\n",
      "                  (concept, language)) \n",
      "        #for prefLabel in prefLabels:\n",
      "        # TODO: tunnista kasitteen tyyppi, aika, yleinen, paikka, genre\n",
      "        # -> 148, 150, 151, 155, 162\n",
      "        # tukee t\u00e4ll\u00e4 hetkell\u00e4 tavallisia asiasanoja (150), YSO-paikkoja (151) & SLM:\u00e4\u00e4 (155)\n",
      "        tag = \"150\"\n",
      "        if (concept, SKOS.inScheme, YSO.places) in g:\n",
      "            tag = \"151\"\n",
      "        elif vocId == \"slm\":\n",
      "            tag = \"155\"\n",
      "\n",
      "        rec.add_field(\n",
      "            Field(\n",
      "                tag=tag,\n",
      "                indicators = [' ', ' '],\n",
      "                subfields=[\n",
      "                            'a', decomposed\u00c5\u00c4\u00d6toUnicodeCharacters(unicodedata.normalize(NORMALIZATION_FORM, str(valueProps[0].value)))\n",
      "                            #'a', str(valueProps[0].value)\n",
      "                          ]\n",
      "            )\n",
      "        )\n",
      "        \n",
      "        # skos:altLabel -> 447, 448, 450, 451, 455\n",
      "        #450 katso-viittaus\n",
      "        # poistetaan toisteiset skos:hiddenLabelit\n",
      "        # OLETUS: poistettujen k\u00e4sitteiden seuraajien tietoihin EI merkit\u00e4 poistetun k\u00e4sitteen\n",
      "        # skos:prefLabelia n\u00e4ihin kenttiin, sill\u00e4 sen oletetaan jo olevan skos:altLabelina kun siihen\n",
      "        # on haluttu viitata vanhalla muodolla\n",
      "        seen_values = set()\n",
      "        \n",
      "        for valueProp in sorted(getValues(g, concept, [SKOS.altLabel, YSOMETA.singularPrefLabel,\n",
      "                                                YSOMETA.singularAltLabel, SKOS.hiddenLabel], language=language),\n",
      "                                key=lambda o: str(o.value)): \n",
      "\n",
      "            if valueProp.prop == SKOS.hiddenLabel:\n",
      "                if str(valueProp.value) in seen_values:\n",
      "                    continue\n",
      "            seen_values.add(str(valueProp.value))\n",
      "            \n",
      "            tag = \"450\"\n",
      "            if (concept, SKOS.inScheme, YSO.places) in g:\n",
      "                tag = \"451\"\n",
      "            elif vocId == \"slm\":\n",
      "                tag = \"455\"\n",
      "\n",
      "            rec.add_field(\n",
      "                Field(\n",
      "                    tag = tag,\n",
      "                    indicators = [' ', ' '],\n",
      "                    subfields = [\n",
      "                        #'i', TERMGROUP[valueProp.prop][language],\n",
      "                        'a', decomposed\u00c5\u00c4\u00d6toUnicodeCharacters(unicodedata.normalize(NORMALIZATION_FORM, str(valueProp.value)))\n",
      "                        #'a', str(valueProp.value)\n",
      "                    ]\n",
      "                )\n",
      "            )\n",
      "        \n",
      "        # broader/narrower/related/successor/predecessor/skosext:partOf\n",
      "        # -> 550 \"katso myos\" viittaus\n",
      "        # HUOM: Objektit vain olioita\n",
      "        # TODO: ysoon lis\u00e4t\u00e4\u00e4n my\u00f6hemmin partOf-suhteiden k\u00e4\u00e4nteinen suhde\n",
      "        # TODO: useat erityyppiset i-kent\u00e4t eiv\u00e4t toimi t\u00e4ll\u00e4 hetkell\u00e4\n",
      "        fields = list()\n",
      "        for prop, wval in SEEALSOPROPS.items():\n",
      "            for target in sorted(g.objects(concept, prop)):\n",
      "                if not helper_variables['keepDeprecated'] and \\\n",
      "                (target, OWL.deprecated, Literal(True)) in g:\n",
      "                    continue # skip deprecated concepts\n",
      "                \n",
      "                valueProps = getValues(g, target, SKOS.prefLabel, language=language)\n",
      "                if len(valueProps) == 0:\n",
      "                    logging.warning(\"Could not find preflabel for target %s in language %s. Skipping property %s target for concept %s.\" %\n",
      "                      (target, language, prop, concept))\n",
      "                    continue\n",
      "                elif len(valueProps) != 1:\n",
      "                    logging.warning(\"Multiple prefLabels detected for target %s in language %s. Choosing the first.\" %\n",
      "                          (target, language)) \n",
      "                label = valueProps[0].value\n",
      "                \n",
      "                tag = \"550\" # alustetaan 550-arvoon\n",
      "                if (target, SKOS.inScheme, YSO.places) in g:\n",
      "                        tag = \"551\"\n",
      "                elif vocId == \"slm\":\n",
      "                    tag = \"555\"\n",
      "                \n",
      "                subfields = []\n",
      "                \n",
      "                #TODO: YSOn mahdolliset SKOSEXT-ominaisuudet?\n",
      "                #TODO: tarkista t\u00e4m\u00e4 YSOn tietomalliuudistusta varten\n",
      "                if wval == \"i\":\n",
      "                    if (target, SKOS.inScheme, YSO.places) in g:\n",
      "                        if prop == SKOSEXT.partOf:\n",
      "                            subfields.extend(('w', 'g'))\n",
      "                        elif prop == SKOSEXT.hasPart:\n",
      "                            subfields.extend(('w', 'h'))\n",
      "                        else:\n",
      "                            subfields.extend(('w', wval,\n",
      "                                     \"i\", TRANSLATIONS[prop][language]\n",
      "                                    ))\n",
      "                    else:\n",
      "                        subfields.extend(('w', wval,\n",
      "                                     \"i\", TRANSLATIONS[prop][language]\n",
      "                                    ))\n",
      "                else:\n",
      "                    # yso-paikoissa on sek\u00e4 ISOTHES.broaderPartitive, ett\u00e4\n",
      "                    # SKOS.broader redundanttina, j\u00e4tet\u00e4\u00e4n j. pois\n",
      "                    # samoin ISOTHES.narrowerPartitive - SKOS.narrower\n",
      "                    if (target, SKOS.inScheme, YSO.places) in g and \\\n",
      "                        (prop == SKOS.broader or prop == SKOS.narrower):\n",
      "                        continue\n",
      "                    subfields.extend(('w', wval))\n",
      "                \n",
      "                subfields.extend(('a', \n",
      "                                  decomposed\u00c5\u00c4\u00d6toUnicodeCharacters(unicodedata.normalize(NORMALIZATION_FORM, str(label)))\n",
      "                                  #str(label)\n",
      "                                 ))\n",
      "                subfields.extend(('0', target))\n",
      "                \n",
      "                #rec.add_field(\n",
      "                fields.append(\n",
      "                    Field(\n",
      "                        tag = tag,\n",
      "                        indicators = [' ', ' '],\n",
      "                        subfields = subfields\n",
      "                    )\n",
      "                )\n",
      "        # j\u00e4rjest\u00e4 5XX-kent\u00e4t ja lis\u00e4\u00e4 ne tietueeseen\n",
      "        for sorted_field in sorted(fields, key=lambda o: (\n",
      "            o.tag, \n",
      "            SORT_5XX_W_ORDER[o.get_subfields(\"w\")[0]] if o.get_subfields(\"w\") else \"999\",\n",
      "            o.get_subfields('a')[0]\n",
      "            )):\n",
      "            rec.add_field(sorted_field)\n",
      "        \n",
      "        # TODO: JS: laitetaan 667 kentt\u00e4\u00e4n SLM:n k\u00e4siteskeemat jokaiselle k\u00e4sitteelle\n",
      "        \n",
      "        # dc:source -> 670 kasitteen tai kuvauksen lahde\n",
      "        # tulostetaan termin kielen mukaan samankieliset l\u00e4hteet\n",
      "        # mik\u00e4li kielikoodilla ei ole propertille arvoa, ohjelma ei tulosta t\u00e4t\u00e4 kentt\u00e4\u00e4\n",
      "        # voidaanko tunnistaa, onko lahteessa URI, jolloin\n",
      "        # $u-osakenttaan laitetaan URI\n",
      "        # 4.5.2018 - palataan my\u00f6hemmin t\u00e4h\u00e4n\n",
      "        # JS: 6.8.2018 - usein pelkk\u00e4 l\u00e4hdeviittaus, jolloin kielell\u00e4 ei merkityst\u00e4\n",
      "        for valueProp in sorted(getValues(g, concept, DC.source, language=language), key=lambda o: str(o.value)):  \n",
      "            subfields = [\n",
      "                'a', \n",
      "                decomposed\u00c5\u00c4\u00d6toUnicodeCharacters(unicodedata.normalize(NORMALIZATION_FORM, str(valueProp.value)))\n",
      "                #str(valueProp.value)\n",
      "            ]\n",
      "            # TODO: linkkien koodaus tarkistetaan/tehd\u00e4\u00e4n my\u00f6hemmin\n",
      "            #urls = getURLs(valueProp.value)\n",
      "            #for url in urls:\n",
      "            #    subfields.append(\"u\")\n",
      "            #    subfields.append(url)\n",
      "                \n",
      "            rec.add_field(\n",
      "                Field(\n",
      "                    tag='670',\n",
      "                    indicators = [' ', ' '],\n",
      "                    subfields = subfields\n",
      "                )\n",
      "            )\n",
      "        # skos:definition -> 677 huomautus maaritelmasta\n",
      "        # maaritelman lahde voidaan merkita osakenttaan $v\n",
      "        # sita varten tulee sopia tavasta merkita tama lahde, jotta\n",
      "        # se voidaan koneellisesti erottaa tekstista\n",
      "        # JS ehdottaa: jos tekstissa on merkkijono \". Lahde: \",\n",
      "        # kaikki sen perassa oleva teksti merkitaan osakenttaan $v\n",
      "        # enta jos linkki lahteen perassa?\n",
      "        # JS ehdottaa: linkki aivan viimeisena sanana\n",
      "        # 4.5.2018 - palataan my\u00f6hemmin t\u00e4h\u00e4n\n",
      "        # 6.8.2018 - ei viel\u00e4 k\u00e4sitelty\n",
      "        # 5.9.2018 - m\u00e4\u00e4ritelm\u00e4n l\u00e4hde tulee m\u00e4\u00e4ritelm\u00e4n j\u00e4lkeen kahdella tavuviivalla (--) erotettuna\n",
      "        # j\u00e4tet\u00e4\u00e4n toistaiseksi paikalleen (13 kpl)\n",
      "        for valueProp in sorted(getValues(g, concept, SKOS.definition, language=language),\n",
      "                                key=lambda o: str(o.value)):\n",
      "            subfields = [\n",
      "                'a', \n",
      "                decomposed\u00c5\u00c4\u00d6toUnicodeCharacters(unicodedata.normalize(NORMALIZATION_FORM, str(valueProp.value)))\n",
      "                #str(valueProp.value)\n",
      "            ]\n",
      "            # TODO: linkkien koodaus tarkistetaan/tehd\u00e4\u00e4n my\u00f6hemmin\n",
      "            #urls = getURLs(valueProp.value)\n",
      "            #for url in urls:\n",
      "            #    subfields.append(\"u\")\n",
      "            #    subfields.append(url)\n",
      "                \n",
      "            rec.add_field(\n",
      "                Field(\n",
      "                    tag='677',\n",
      "                    indicators = [' ', ' '],\n",
      "                    subfields = subfields\n",
      "                )\n",
      "            )\n",
      "        \n",
      "        # skos:note -> 680 yleinen huomautus, julkinen\n",
      "        for valueProp in sorted(getValues(g, concept, [SKOS.note, SKOS.scopeNote, SKOS.example], language=language),\n",
      "                                key=lambda o: str(o.value)):\n",
      "            \n",
      "            ysoATagParser.initialize()\n",
      "            ysoATagParser.feed(valueProp.value)\n",
      "            \n",
      "            if len(ysoATagParser.merkkijono)%2 == 1:\n",
      "                logging.warning(\"Parsing the property %s for concept %s into seperate subfields failed. Continuing with complete value.\" % (valueProp.prop, concept))\n",
      "                subfieldCodeValuePair = (\"i\", valueProp.value.strip())\n",
      "                if len(subfieldCodeValuePair[1]) == 0:\n",
      "                    subfieldCodeValuePair = []\n",
      "            else:\n",
      "                subfieldCodeValuePair = [[x[1], ysoATagParser.merkkijono[ind+1].strip()] for (ind,x) in enumerate(ysoATagParser.merkkijono) if ind%2 == 0]\n",
      "                # poistetaan viimeinen i-t\u00e4gi, jos se on vain 1 merkin mittainen\n",
      "                if subfieldCodeValuePair[-1][0] == \"i\" and len(subfieldCodeValuePair[-1][1]) <= 1 and len(subfieldCodeValuePair) > 1:\n",
      "                    subfieldCodeValuePair[-2][1] = subfieldCodeValuePair[-2][1] + subfieldCodeValuePair[-1][1]\n",
      "                    subfieldCodeValuePair = subfieldCodeValuePair[:-1]\n",
      "            \n",
      "            subfield_values = []\n",
      "            \n",
      "            for subfield in subfieldCodeValuePair:\n",
      "                subfield_values.extend(\n",
      "                    (subfield[0], decomposed\u00c5\u00c4\u00d6toUnicodeCharacters(unicodedata.normalize(NORMALIZATION_FORM, subfield[1])))\n",
      "                    #(subfield[0], subfield[1])\n",
      "                )\n",
      "            \n",
      "            rec.add_field(\n",
      "                Field(\n",
      "                    tag='680',\n",
      "                    indicators = [' ', ' '],\n",
      "                    subfields = subfield_values\n",
      "                )\n",
      "            )\n",
      "        # mahdollinen deprekointitieto lis\u00e4t\u00e4\u00e4n erikseen\n",
      "        if deprecatedString:\n",
      "            rec.add_field(\n",
      "                Field(\n",
      "                    tag='680',\n",
      "                    indicators = [' ', ' '],\n",
      "                    subfields = ['i', deprecatedString]\n",
      "                )\n",
      "            )\n",
      "        # owl:deprecated -> 682 Huomautus poistetusta otsikkomuodosta (ei toistettava)\n",
      "        # Ohjaus uuteen/uusiin k\u00e4sitteisiin\n",
      "        # seuraaja-suhde\n",
      "        # a-kentt\u00e4\u00e4n seuraajan preflabel, 0-kentt\u00e4\u00e4n URI, i selite\n",
      "        # TODO: onko seuraajaa vai ei, lis\u00e4ksi mietitt\u00e4v\u00e4 deprekoidun k\u00e4sitteen\n",
      "        # tyyppi (onko hierarkia jne.). Deprekaattorin huomautusteksti\u00e4 kehitett\u00e4v\u00e4\n",
      "        # (kent\u00e4t mietitt\u00e4v\u00e4 uudelleen - EI skos:scopeNote kuten nyt on 4.5.2018)\n",
      "        # 2018-12-05 Huomattiin, ett\u00e4 ei ole toistettavissa --> ongelma useiden korvaajien tapauksessa ($0)\n",
      "        # kongressin kirjasto on ty\u00f6st\u00e4m\u00e4ss\u00e4 parhaista k\u00e4yt\u00e4nn\u00f6ist\u00e4 $0-kent\u00e4n toistettavuudesta viel\u00e4 t\u00e4m\u00e4n vuoden aikana\n",
      "        # p\u00e4\u00e4tettiin j\u00e4tt\u00e4\u00e4 t\u00e4ss\u00e4 vaiheessa $0-kent\u00e4t kokonaan pois\n",
      "        if (concept, OWL.deprecated, Literal(True)) in g:\n",
      "            target = None\n",
      "            labels = []\n",
      "            for target in sorted(g.objects(concept, DCT.isReplacedBy)):\n",
      "                if not helper_variables['keepDeprecated'] and \\\n",
      "                (target, OWL.deprecated, Literal(True)) in g:\n",
      "                    continue # skip deprecated concepts\n",
      "                    \n",
      "                valueProps = sorted(getValues(g, target, SKOS.prefLabel, language=language), key=lambda o: str(o.value))\n",
      "                if len(valueProps) > 1:\n",
      "                    logging.warning(\"Multiple prefLabels detected for target %s in language %s. Choosing the first.\" %\n",
      "                      (target, language)) \n",
      "                elif len(valueProps) == 0:\n",
      "                    '''\n",
      "                    tryPrefLabelInOtherGraphs = getValues(g2, target, SKOS.prefLabel, language=language)\n",
      "                    if len(tryPrefLabelInOtherGraphs) > 0:\n",
      "                        if not helper_variables['keepDeprecated'] and\n",
      "                        (target, OWL.deprecated, Literal(True)) in g2:\n",
      "                            continue # skip deprecated concepts\n",
      "                        label = tryPrefLabelInOtherGraphs[0].value\n",
      "                    else:\n",
      "                        logging.warning(\"Could not find preflabel for target %s in language: %s. Skipping property %s target for concept %s.\" %\n",
      "                          (target, language, DCT.isReplacedBy, concept))\n",
      "                        continue # skip concepts with no preferred label\n",
      "                    '''\n",
      "                    \n",
      "                    logging.warning(\"Could not find preflabel for target %s in language: %s. Skipping property %s target for concept %s.\" %\n",
      "                          (target, language, DCT.isReplacedBy, concept))\n",
      "                    continue\n",
      "                label = valueProps[0].value\n",
      "                labels.append(valueProps[0].value)\n",
      "                #rec.add_field(\n",
      "                #    Field(\n",
      "                #        tag = '682',\n",
      "                #        indicators = [' ', ' '],\n",
      "                #        subfields = [\n",
      "                #            'i', TRANSLATIONS[\"682iDEFAULT\"][language],\n",
      "                #            'a', decomposed\u00c5\u00c4\u00d6toUnicodeCharacters(unicodedata.normalize(NORMALIZATION_FORM, str(label))),\n",
      "                #            #'a', str(label),\n",
      "                #            '0', target\n",
      "                #        ]\n",
      "                #    )\n",
      "                #)\n",
      "            if len(labels) > 0:\n",
      "                subfield_values = ['i', TRANSLATIONS[\"682iDEFAULT\"][language]]\n",
      "                \n",
      "                for label in labels[:-1]:\n",
      "                    subfield_values.extend(('a', \n",
      "                                      decomposed\u00c5\u00c4\u00d6toUnicodeCharacters(unicodedata.normalize(NORMALIZATION_FORM, str(label) + \",\"))\n",
      "                                      #str(label)\n",
      "                                     ))\n",
      "                subfield_values.extend(('a', \n",
      "                                      decomposed\u00c5\u00c4\u00d6toUnicodeCharacters(unicodedata.normalize(NORMALIZATION_FORM, str(labels[-1])))\n",
      "                                      #str(label)\n",
      "                                     ))\n",
      "                #subfields_values.extend(('0', target)) #TODO: seurataan kongressin kirjaston tulevia ohjeistuksia\n",
      "                rec.add_field(\n",
      "                    Field(\n",
      "                        tag='682',\n",
      "                        indicators = [' ', ' '],\n",
      "                        subfields = subfield_values\n",
      "                    )\n",
      "                )\n",
      "        \n",
      "        if helper_variables[\"write688created\"]:\n",
      "            rec.add_field(\n",
      "                Field(\n",
      "                    tag = '688',\n",
      "                    indicators = [' ', ' '],\n",
      "                    subfields = [\n",
      "                        'a',  TRANSLATIONS[\"688aCREATED\"][language] + \": \" + created.strftime('%Y-%m-%d')\n",
      "                    ]\n",
      "                )\n",
      "            )\n",
      "        \n",
      "        if mod and modified:\n",
      "            rec.add_field(\n",
      "                Field(\n",
      "                    tag = '688',\n",
      "                    indicators = [' ', ' '],\n",
      "                    subfields = [\n",
      "                        'a', TRANSLATIONS[\"688aMODIFIED\"][language] + \": \" + modified.strftime('%Y-%m-%d')\n",
      "                    ]\n",
      "                )\n",
      "            )\n",
      "            try:\n",
      "                if type(modified) == datetime:\n",
      "                    if created > modified.date():\n",
      "                        logging.warning(\"Created date later than modified for concept %s\" % concept)\n",
      "                else:\n",
      "                    if created > modified:\n",
      "                        logging.warning(\"Created date later than modified for concept %s\" % concept)\n",
      "            except Exception:\n",
      "                logging.warning(\"Date comparison failed for concept %s\", concept)\n",
      "\n",
      "                        \n",
      "        # all skos:match*es -> 7XX linkkikenttiin\n",
      "        # halutaan linkit kaikkiin kieliversioihin\n",
      "        # YSOn erikieliset preflabelit tulevat t\u00e4nne\n",
      "        # graafit haetaan etukateen ohjelman muistiin ohjelman alussa\n",
      "        # haetaan api.dev.finto.fi/sparql -endpointista\n",
      "        # tarvittavat graafit: ysa, allars, yso, yso-paikat, lcsh\n",
      "        # miten LCSH haetaan? Yli 400 000 prefLabelia\n",
      "        # tarjotaan talla hetkella vain api.skosmos.dev.finto.fi:n kautta\n",
      "        # jolle ei paase ulkoa kasin ollenkaan.\n",
      "        # 750 $a label, $4 relaatiotyyppi, $2 sanastolahde, $0 uri\n",
      "        # miten $w? JS: ei oteta mukaan ollenkaan\n",
      "        # 2.5.2018-kokouksessa p\u00e4\u00e4tettiin, ett\u00e4 DCT.spatialia ei k\u00e4\u00e4nnet\u00e4\n",
      "        # MARC-muotoon\n",
      "        # 13.8.2018 LCSH/LCGF k\u00e4sitell\u00e4\u00e4n erikseen; niille on tehty oma kansio, joka\n",
      "        # on tallennettu locDirectory-muuttujaan. Puuttuvat loc-linkit haetaan\n",
      "        # dynaamisesti tarvittaessa ja lis\u00e4t\u00e4\u00e4n kansioon\n",
      "        valueProps = getValues(g, concept, [SKOS.prefLabel, SKOS.exactMatch, SKOS.closeMatch,\n",
      "                                 SKOS.broadMatch, SKOS.narrowMatch, \n",
      "                                 SKOS.relatedMatch])\n",
      "        fields = list() # ker\u00e4t\u00e4\u00e4n kent\u00e4t t\u00e4h\u00e4n muuttujaan, joka sitten lopuksi j\u00e4rjestet\u00e4\u00e4n\n",
      "       \n",
      "        #sortedValueProps = sorted(valueProps, key=lambda o: getValuePropObjectPrefLabel(o, g2))\n",
      "        #for valueProp in sortedValueProps:\n",
      "        for valueProp in valueProps:\n",
      "            if valueProp.prop == SKOS.prefLabel:\n",
      "                # suodatetaan samankieliset, jotka meniv\u00e4t jo 1xx-kenttiin\n",
      "                # valueProp.value sis\u00e4lt\u00e4\u00e4 t\u00e4ss\u00e4 poikkeuksellisesti jo halutun literaalin\n",
      "                # (vrt. kun muissa on solmu)\n",
      "                if valueProp.value.language == language:\n",
      "                    continue\n",
      "                matchURIRef = URIRef(concept)\n",
      "            else:\n",
      "                # tehd\u00e4\u00e4n osumasta URIRef \n",
      "                matchURIRef = URIRef(valueProp.value)\n",
      "                #if not helper_variables['keepDeprecated'] and \\\n",
      "                if (matchURIRef, OWL.deprecated, Literal(True)) in g2:\n",
      "                    # skip deprecated matches\n",
      "                    # 19.12.2018 k\u00e4yty keskustelua t\u00e4st\u00e4 - p\u00e4\u00e4tetty t\u00e4ss\u00e4 vaiheessa\n",
      "                    # olla seuraamatta dct:isReplacedBy-suhteita ja lis\u00e4\u00e4m\u00e4tt\u00e4 n\u00e4it\u00e4\n",
      "                    # TODO-listalle?\n",
      "                    continue \n",
      "                # 27.12.2018 pit\u00e4isik\u00f6 tarkistaa my\u00f6s groupingClassesien varalta?\n",
      "                # Ratkaisu: Ei - n\u00e4m\u00e4 on merkitty omissa tietueissaan ei-k\u00e4ytett\u00e4viksi\n",
      "\n",
      "            second_indicator = \"7\"\n",
      "            tag = \"750\"\n",
      "            loc_object = None \n",
      "            \n",
      "            if (matchURIRef, SKOS.inScheme, YSO.places) in g2 or \\\n",
      "            (matchURIRef, SKOS.inScheme, YSO.places) in g: #or matchType == DCT.spatial:\n",
      "                tag = \"751\"\n",
      "            # TODO: nimetyt graafit, kohdista kyselyt niihin?\n",
      "            # if we want to direct queries to spesific graphs, one per vocab, that graph\n",
      "            # needs to be selected here based on the void:uriSpace\n",
      "            \n",
      "            if matchURIRef.startswith(LCSH):\n",
      "                second_indicator = \"0\"\n",
      "                loc_object = {\"prefix\": str(LCSH), \"id\": matchURIRef.split(\"/\")[-1]}\n",
      "            elif matchURIRef.startswith(LCGF):\n",
      "                sub2 = \"lcgft\" \n",
      "                loc_object = {\"prefix\": str(LCGF), \"id\": matchURIRef.split(\"/\")[-1]}\n",
      "            elif matchURIRef.startswith(ALLARS):\n",
      "                if (matchURIRef, RDF.type, ALLARSMETA.GeographicalConcept) in g2: #or matchType == DCT.spatial:\n",
      "                    tag = \"751\"\n",
      "                sub2 = \"allars\"\n",
      "            elif matchURIRef.startswith(KOKO):\n",
      "                continue # skip KOKO concepts\n",
      "            elif matchURIRef.startswith(SLM):\n",
      "                tag = \"755\"\n",
      "                sub2 = \"slm\"\n",
      "            elif matchURIRef.startswith(YSA):\n",
      "                if (matchURIRef, RDF.type, YSAMETA.GeographicalConcept) in g2: #or matchType == DCT.spatial:\n",
      "                    tag = \"751\"\n",
      "                sub2 = \"ysa\"\n",
      "            elif matchURIRef.startswith(YSO):\n",
      "                sub2 = \"yso\"\n",
      "            else:\n",
      "                second_indicator = \"4\"\n",
      "                if not cs.getboolean(\"ignoreOtherGraphs\", fallback=IGNOREOTHERGRAPHS):\n",
      "                    logging.warning(\"Matched target %s did not belong to any known vocabulary\" % (str(matchURIRef)))\n",
      "                    # do not put subfield 2 in this case\n",
      "            \n",
      "            if not ((matchURIRef, None, None) in g or\n",
      "                (matchURIRef, None, None) in g2):\n",
      "                if not loc_object and not cs.getboolean(\"ignoreOtherGraphs\", fallback=IGNOREOTHERGRAPHS): \n",
      "                    logging.warning(\"Matched target %s did not belong to any known vocabulary. Skipping.\" % (str(matchURIRef)))\n",
      "                    continue\n",
      "            \n",
      "            sub4 = \"\"\n",
      "            if valueProp.prop == SKOS.broadMatch:\n",
      "                sub4 = \"BM\"\n",
      "            elif valueProp.prop == SKOS.narrowMatch:\n",
      "                sub4 = \"NM\"\n",
      "            elif valueProp.prop == SKOS.exactMatch:\n",
      "                sub4 = \"EQ\"\n",
      "            elif valueProp.prop == SKOS.prefLabel:\n",
      "                sub4 = \"EQ\"\n",
      "                \n",
      "                # kovakoodattu yso ja slm - muuten niiden tulisi olla jossain globaalissa muuttujassa\n",
      "                if sub2 == \"yso\" or sub2 == \"slm\" or cs.getboolean(\"multilanguage\", fallback=False):\n",
      "                    sub2 = sub2 + \"/\" + LANGUAGES[valueProp.value.language]\n",
      "                \n",
      "                fields.append(\n",
      "                    Field(\n",
      "                        tag=tag,\n",
      "                        indicators = [' ', second_indicator],\n",
      "                        subfields = [\n",
      "                            'a', decomposed\u00c5\u00c4\u00d6toUnicodeCharacters(unicodedata.normalize(NORMALIZATION_FORM, str(valueProp.value))), \n",
      "                            #'a', str(valueProp.value),\n",
      "                            '4', sub4,\n",
      "                            '2', sub2,\n",
      "                            '0', concept\n",
      "                        ]\n",
      "                    )\n",
      "                )\n",
      "                continue\n",
      "            elif valueProp.prop == SKOS.closeMatch:\n",
      "                sub4 = \"~EQ\"\n",
      "            else:\n",
      "                sub4 = \"RM\"\n",
      "                \n",
      "            # library of congress -viitteet k\u00e4sitell\u00e4\u00e4n erikseen\n",
      "            if loc_object and cs.get(\"locDirectory\", fallback=None) != None:\n",
      "                recordNode = None\n",
      "                local_loc_source = cs.get(\"locDirectory\") + loc_object[\"id\"] + \".marcxml.xml\"\n",
      "                downloaded = False\n",
      "                try:\n",
      "                    #recordNode = lcshRecordNodes[loc_object[\"id\"]]\n",
      "                    with open(local_loc_source, encoding=\"utf-8\") as f:\n",
      "                        recordNode = ET.parse(f)\n",
      "                except OSError as e:\n",
      "                    # haetaan kongressin kirjastosta tarvittava tiedosto ja tallennetaan se\n",
      "                    try:\n",
      "                        with urllib.request.urlopen(loc_object[\"prefix\"] + loc_object[\"id\"] + \".marcxml.xml\") as marcxml, \\\n",
      "                            open(local_loc_source, 'wb') as out_file:\n",
      "                            shutil.copyfileobj(marcxml, out_file)\n",
      "                            logging.info(\"Downloaded LCSH link to %s.\" %\n",
      "                                (local_loc_source))\n",
      "                            downloaded = True\n",
      "                    except urllib.error.URLError as e:\n",
      "                        logging.warning('Unable to load the marcxml for %s. Reason: %s. Skipping the property for concept %s.' %\n",
      "                            (loc_object[\"id\"], e.reason, concept))\n",
      "                    except OSError as e:\n",
      "                        logging.warning(\"Failed to create a file for %s under %s directory. Skipping the property for concept %s.\" %\n",
      "                            (loc_object[\"id\"], cs.get(\"locDirectory\"), concept))\n",
      "                except ET.ParseError as e:\n",
      "                    logging.warning(\"Failed to parse the following file: %s. Skipping the property for concept %s.\" %\n",
      "                            (local_loc_source, concept))\n",
      "                \n",
      "                if downloaded:\n",
      "                    try:\n",
      "                        with open(local_loc_source, encoding=\"utf-8\") as f:\n",
      "                            recordNode = ET.parse(f)\n",
      "                    except OSError as e:\n",
      "                        logging.warning(\"Failed to read the file for %s under %s directory. Skipping the property for concept %s\" %\n",
      "                            (loc_object[\"id\"], cs.get(\"locDirectory\"), concept))\n",
      "                    except ET.ParseError as e:\n",
      "                        logging.warning(\"Failed to parse the following file: %s. Skipping the property for concept %s.\" %\n",
      "                            (local_loc_source, concept))\n",
      "                            \n",
      "                \n",
      "                if recordNode:\n",
      "                    tagNode = None\n",
      "\n",
      "                    for tagNumber in LCSH_1XX_FIELDS:\n",
      "                        tagNode = recordNode.find(\"./marcxml:datafield[@tag='\" + tagNumber + \"']\", ET_namespaces)\n",
      "                        if tagNode:\n",
      "                            # otetaan ensimm\u00e4inen\n",
      "                            break\n",
      "\n",
      "                    if tagNode:\n",
      "                        tag = \"7\" + tagNode.attrib[\"tag\"][1:]\n",
      "                        first_indicator = tagNode.attrib[\"ind1\"]\n",
      "                        subfields = []\n",
      "\n",
      "                        for child in tagNode:\n",
      "                            subfields.extend((child.attrib[\"code\"], \n",
      "                                              decomposed\u00c5\u00c4\u00d6toUnicodeCharacters(unicodedata.normalize(NORMALIZATION_FORM, str(child.text)))\n",
      "                                              #str(child.text)\n",
      "                                             ))\n",
      "\n",
      "                        subfields.extend((\"4\", sub4))\n",
      "                        if second_indicator == \"7\":\n",
      "                            subfields.extend((\"2\", sub2))\n",
      "                        subfields.extend((\"0\", str(matchURIRef)))\n",
      "\n",
      "                        fields.append(\n",
      "                            Field(\n",
      "                                tag = tag,\n",
      "                                indicators = [first_indicator, second_indicator],\n",
      "                                subfields = subfields\n",
      "                            )\n",
      "                        )\n",
      "\n",
      "                    else:\n",
      "                        logging.warning(\"Could not find any marcxml:datafield objects with a tag number in the following list: %s for the following record: %s. %s\" %\n",
      "                          (LCSH_1XX_FIELDS, loc_object[\"id\"], \"Skipping the property for concept \" + concept + \".\"))\n",
      "                        #continue\n",
      "\n",
      "            else:\n",
      "                prefLabel = None\n",
      "                multipleLanguages = False\n",
      "                languagesEncountered = set()\n",
      "                sortedPrefLabels = sorted(g2.preferredLabel(matchURIRef,\n",
      "                                        labelProperties=(SKOS.prefLabel,)))\n",
      "                for label in sortedPrefLabels:\n",
      "                    languagesEncountered.add(label.language)\n",
      "                    if len(languagesEncountered > 1):\n",
      "                        multipleLanguages = True\n",
      "                        break\n",
      "                    \n",
      "                processedLanguages = set()             \n",
      "                for type2, prefLabel in sortedPrefLabels:\n",
      "                    \n",
      "                    prefLabelLanguage = prefLabel.language if prefLabel.language != None else \"\"\n",
      "                    \n",
      "                    if prefLabelLanguage:\n",
      "                        if LANGUAGES.get(prefLabelLanguage):\n",
      "                            pass\n",
      "                        else:\n",
      "                            logging.warning(\"LANGUAGES dictionary has no key for language '%s' found from the skos:prefLabel %s of target %s. Skipping.\" %\n",
      "                                (prefLabelLanguage, matchURIRef, concept))\n",
      "                            continue\n",
      "                    \n",
      "                    if prefLabelLanguage in processedLanguages:\n",
      "                        logging.warning(\"Multiple prefLabels detected for target %s in language %s. Skipping prefLabel %s.\" %\n",
      "                      (matchURIRef, prefLabelLanguage, prefLabel))\n",
      "                        continue\n",
      "\n",
      "                    processedLanguages.add(prefLabelLanguage)\n",
      "                    \n",
      "                    subfields = [\n",
      "                        'a', decomposed\u00c5\u00c4\u00d6toUnicodeCharacters(unicodedata.normalize(NORMALIZATION_FORM, str(prefLabel))),\n",
      "                        #'a', str(prefLabel),\n",
      "                        '4', sub4\n",
      "                    ]\n",
      "                    \n",
      "                    \n",
      "                    if prefLabelLanguage == \"\":\n",
      "                        multipleLanguagesEnd = \"\"\n",
      "                    else:\n",
      "                        multipleLanguagesEnd = \"/\" + LANGUAGES[prefLabel.language] if sub2 in [\"yso\", \"slm\"] or multipleLanguages else \"\"\n",
      "                    if second_indicator != \"4\":\n",
      "                        subfields.extend((\"2\", \n",
      "                            sub2 + multipleLanguagesEnd\n",
      "                        ))\n",
      "                        \n",
      "                    subfields.extend((\"0\", str(matchURIRef)))\n",
      "                    \n",
      "                    fields.append(\n",
      "                        Field(\n",
      "                            tag=tag,\n",
      "                            indicators = [' ', second_indicator],\n",
      "                            subfields = subfields\n",
      "                        )\n",
      "                    )\n",
      "\n",
      "                if not prefLabel and not cs.getboolean(\"ignoreOtherGraphs\", fallback=IGNOREOTHERGRAPHS): \n",
      "                    logging.warning(\"Could not find preflabel for target %s. Skipping property %s target for concept %s.\" %\n",
      "                      (str(matchURIRef), str(valueProp.prop), concept))\n",
      "                    #continue\n",
      "        \n",
      "        # sort fields and add them\n",
      "        for sorted_field in sorted(fields, key=lambda o: (\n",
      "            o.tag,\n",
      "            o.value().lower()\n",
      "            )):\n",
      "            rec.add_field(sorted_field)\n",
      "\n",
      "        # Konversion tiedot -> 884\n",
      "\n",
      "        tag = \"884\"\n",
      "        rec.add_field(\n",
      "                        Field(\n",
      "                            tag=tag,\n",
      "                            indicators = [' ', \" \"],\n",
      "                            subfields = [\n",
      "                                'a', CONVERSION_PROCESS,\n",
      "                                'u', CONVERSION_URI\n",
      "                            ]\n",
      "                        )\n",
      "                    )\n",
      "        writer_records_counter += 1\n",
      "        writer.write(rec)\n",
      "\n",
      "    if handle is not sys.stdout:\n",
      "        writer.close()\n",
      "    \n",
      "    logging.info(\n",
      "        \"Processed %s concepts, from which %s were deprecated and left out. Wrote %s MARCXML records.\" %\n",
      "        (incrementor, deprecated_counter, writer_records_counter)\n",
      "    )\n",
      "    #logging.info(\n",
      "    #    \"Ending processing vocabulary with vocabulary code '%s' in language '%s'. Processed %s concepts, from which %s were deprecated. Wrote %s MARCXML records.\" %\n",
      "    #    (vocId, language, incrementor, deprecated_counter, writer_records_counter)\n",
      "    #)\n",
      "    \n",
      "    \n",
      "    # write also to stdout if it is spesified except in the case of IPython instance with explicit output\n",
      "    if not sys.stdout.isatty() and cs.get(\"output\", fallback=None) != None:\n",
      "        try:\n",
      "            __IPYTHON__\n",
      "            if cs.get(\"outputSpecified\", fallback=None) == None:\n",
      "                raise NameError(\"Raising NameError - diverting code flow.\")\n",
      "            pass\n",
      "        except NameError:\n",
      "            if helper_variables.get(\"outputFileName\"):\n",
      "                with open(helper_variables.get(\"outputFileName\"), \"rb\") as f:\n",
      "                    shutil.copyfileobj(f, sys.stdout)\n",
      "            else:\n",
      "                with open(cs.get(\"output\", fallback=defaultOutputFileName), \"rb\") as f:\n",
      "                    shutil.copyfileobj(f, sys.stdout)\n",
      "\n",
      "    #processCatmandu(language)\n",
      "    \n",
      "\n",
      "def processCatmandu(language=\"fi\", vocabulary=\"yso\"):\n",
      "    print(\"catmandu convert MARC --type XML to MARC --type XML <\" + vocabulary + \"MARC-\" + language + \n",
      "        \".mrcx | xmllint --format - >\" + vocabulary + \"MARC-\" + language + \"-formatted.mrcx\")\n",
      "    subprocess.run(\n",
      "        \"catmandu convert MARC --type XML to MARC --type XML <\" + vocabulary + \"MARC-\" + language + \n",
      "        \".mrcx | xmllint --format - >\" + vocabulary + \"MARC-\" + language + \"-formatted.mrcx\",\n",
      "        stdout=subprocess.PIPE, stderr=subprocess.PIPE, shell=True\n",
      "    )"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 10
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "subprocess.run(\"catmandu convert MARC --type XML to MARC --type XML <testYso-fi.mrcx | xmllint --format - >testYso-formatted.mrcx\",\n",
      "    stdout=subprocess.PIPE, stderr=subprocess.PIPE, shell=True)\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": null
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# apufunktiot\n",
      "\n",
      "def decomposed\u00c5\u00c4\u00d6toUnicodeCharacters(string):\n",
      "    return (string.replace(\"A\\u030a\", \"\u00c5\").replace(\"a\\u030a\", \"\u00e5\").\n",
      "          replace(\"A\\u0308\", \"\u00c4\").replace(\"a\\u0308\", \"\u00e4\").\n",
      "          replace(\"O\\u0308\", \"\u00d6\").replace(\"o\\u0308\", \"\u00f6\"))\n",
      "\n",
      "def readEndpointGraphs(settings): \n",
      "    #, loadToGraph):\n",
      "    sparql = SPARQLWrapper(settings.get(\"endpoint\"))\n",
      "    queryStart = \"\"\"\n",
      "    PREFIX skos: <http://www.w3.org/2004/02/skos/core#>\n",
      "    PREFIX owl: <http://www.w3.org/2002/07/owl#>\n",
      "    CONSTRUCT {\n",
      "        ?concept skos:prefLabel ?prefLabel .\n",
      "        ?concept skos:inScheme ?inScheme .\n",
      "        ?concept owl:deprecated ?deprecated .\n",
      "        ?concept a ?types .\n",
      "    }\"\"\"\n",
      "\n",
      "    queryEnd = \"\"\"\n",
      "    WHERE {\n",
      "      ?concept a skos:Concept .\n",
      "      ?concept skos:prefLabel ?prefLabel .\n",
      "      ?concept a ?types .\n",
      "\n",
      "      OPTIONAL {?concept skos:inScheme ?inScheme .}\n",
      "      OPTIONAL {?concept owl:deprecated ?deprecated .}\n",
      "    }\n",
      "    \"\"\"\n",
      "    \n",
      "    queryFrom = \"\"\n",
      "    ret = Graph()\n",
      "    for other_graph in settings.get(\"otherGraphs\").split(\",\"):\n",
      "        sparql.setQuery(queryStart + \"\\nFROM <\" + str(other_graph) + \">\" + queryEnd)\n",
      "        sparql.setMethod(\"GET\")\n",
      "        ret_length = len(ret)\n",
      "        try:\n",
      "            ret += sparql.query().convert()\n",
      "            if ret_length == len(ret):\n",
      "                logging.warning(\"Querying graph <\" + str(other_graph) +\n",
      "                \"> from endpoint \" + settings.get(\"endpoint\") +\n",
      "                \" returned 0 triples. Continuing.\")\n",
      "        except (SPARQLExceptions.SPARQLWrapperException) as err:\n",
      "            logging.warning(\"Whilst querying endpoint \" + settings.get(\"endpoint\") + \n",
      "                  \" for graph <\" + str(other_graph) +\n",
      "                  \"> the following error occurred: \" + err.__class__.__name__ + \": \" + err.msg + \n",
      "                  \". Skipping the graph.\")\n",
      "        except (urllib.error.HTTPError, urllib.error.URLError) as err:\n",
      "            logging.warning(\"SPARQL endpoint not found in url \" + settings.get(\"endpoint\") +\n",
      "                \". Skipping querying linked concepts.\")\n",
      "            break\n",
      "            \n",
      "    return ret\n",
      "\n",
      "def mapToTagsByVocab(first_tag_char, vocab, graph):\n",
      "    # get tag number for vocabulary\n",
      "    # defaults to X50, where X is the parametrized first character\n",
      "    # support for yso-paikat and slm vocabularies currently (X51 and X55, respectively)\n",
      "    # TODO: missing e.g., rdf:type ALLARSMETA.GeographicalConcept\n",
      "    \n",
      "    if (concept, SKOS.inScheme, YSO.places) in graph:\n",
      "        tagEnd = \"51\"\n",
      "    elif vocId == \"slm\":\n",
      "        tagEnd = \"55\"\n",
      "    else:\n",
      "        tagEnd = \"50\"\n",
      "    \n",
      "    return first_tag_char + tagEnd\n",
      "\n",
      "def readConfigVariable(string, separator=None):\n",
      "    if separator:\n",
      "        return [x.strip() for x in string.split(separator) if len(x.strip()) > 0]\n",
      "    else:\n",
      "        return string.strip()\n",
      "\n",
      "ValueProp = namedtuple(\"ValueProp\", ['value', 'prop'])\n",
      "\n",
      "def getValues(graph, target, props, language=None, literal_datatype=None):\n",
      "    \"\"\"Given a subject, get all values for a list of properties\n",
      "    in the order in which those properties were defined.\n",
      "\n",
      "    Args:\n",
      "        graph (Graph): The graph from which to search for the properties of the target.\n",
      "        target (URIRef|BNode): Concept.\n",
      "        props (URIRef|sequence(URIRef)): Property or list of properties to search for.\n",
      "        language (str, optional): Language of literals. Defaults to None (return all literals with languages).\n",
      "            Set to empty string (\"\") for empty lang tag.\n",
      "        literal_datatype (URIRef, optional): Datatype of datatyped literals. Defaults to None (return all literals with datatypes).\n",
      "        \n",
      "    Returns:\n",
      "        list(TypeValue): List containing TypeValue namedtuples\n",
      "            prop (URIRef): Matched property\n",
      "            value (URIRef|BNode|Literal): For matched property, object value\n",
      "\n",
      "    Raises:\n",
      "        ValueError: If parameters do not respect the required types\n",
      "\n",
      "    \"\"\"\n",
      "    if isinstance(props, URIRef):\n",
      "        # cast to list in order to uniform code\n",
      "        props = [props]\n",
      "    \n",
      "    if not (isinstance(target, URIRef) or isinstance(target, BNode)):\n",
      "        raise ValueError(\"Parameter 'target' must be of type URIRef or BNode.\")\n",
      "    elif isinstance(props, str) or not isinstance(props, Sequence):\n",
      "        raise ValueError(\n",
      "            \"Type of parameter 'props' must be a URIRef or sequence; got %s.\" % (type(props)))\n",
      "    elif language is not None and not isinstance(language, str):\n",
      "        raise ValueError(\"Parameter 'language' must be string if set.\")\n",
      "    elif literal_datatype is not None and not isinstance(literal_datatype, URIRef):\n",
      "        raise ValueError(\"Parameter 'datatype' must be URIRef if set.\") \n",
      "    \n",
      "    v = []\n",
      "    \n",
      "    # setup the language filtering\n",
      "    if language is not None:\n",
      "        if language == '':  # we only want not language-tagged literals\n",
      "            langfilter = lambda l: l.language == None\n",
      "        else:\n",
      "            langfilter = lambda l: l.language == language\n",
      "    else:  # we don't care about language tags\n",
      "        langfilter = lambda l: True\n",
      "    \n",
      "    # setup the datatype filtering\n",
      "    if literal_datatype is not None:\n",
      "        typefilter = lambda l: l.datatype == literal_datatype\n",
      "    else:\n",
      "        typefilter = lambda l: True\n",
      "    \n",
      "    for prop in props:\n",
      "        if not isinstance(prop, URIRef):\n",
      "            raise ValueError(\n",
      "            \"Types of properties must be URIRefs; got %s from property '%s'.\" % (type(prop), str(prop)))\n",
      "        \n",
      "        # values that pass restrictions are returned\n",
      "        values = [l for l in graph.objects(target, prop) if \n",
      "                  (isinstance(l, URIRef) or isinstance(l, BNode)) or \n",
      "                  (l.datatype == None and langfilter(l)) or\n",
      "                  (l.datatype != None and typefilter(l))\n",
      "                 ]\n",
      "        \n",
      "        # loop through the values and add them to the list\n",
      "        for val in values:\n",
      "            v.append(ValueProp(value=val, prop=prop))\n",
      "    return v\n",
      "\n",
      "def getInvValues(graph, target, props):\n",
      "    #TODO: todo\n",
      "    return\n",
      "\n",
      "# apufunktio urlien parsimiseen merkkijonosta\n",
      "# mietitt\u00e4v\u00e4 uudelleen, jos n\u00e4it\u00e4 rakenteistetaan\n",
      "def getURLs(string):\n",
      "    urls = []\n",
      "    for word in string:\n",
      "        if len(word) < 10:\n",
      "            continue\n",
      "        if word[0] in [\"(\", \"[\"]:\n",
      "            word = word[1:-1]\n",
      "        res = urllib.parse.urlparse(word)\n",
      "        if res.scheme in (\"http\", \"https\") and \\\n",
      "            len(res.netloc) > 3 and \".\" in res.netloc:\n",
      "            urls.append(word)\n",
      "    return urls\n",
      "\n",
      "# TODO: language support!\n",
      "# Currently supports only 1-language vocabularies\n",
      "def getValuePropObjectPrefLabel(valuePropObj, graph):\n",
      "    if valuePropObj.prop == SKOS.prefLabel:\n",
      "        return str(valuePropObj.value)\n",
      "    else:\n",
      "        matchURIRef = URIRef(valuePropObj.value)\n",
      "        prefLabel = None\n",
      "        \n",
      "        for type2, prefLabel in sorted(graph.preferredLabel(matchURIRef,\n",
      "                                    labelProperties=(SKOS.prefLabel,))):\n",
      "            return str(prefLabel)\n",
      "        return str(valuePropObj.value)\n",
      "\n",
      "class ConvertHTMLYSOATags(HTMLParser):\n",
      "    '''\n",
      "    Korvaa mahdolliset yso-linkit $a-osakentt\u00e4merkill\u00e4 siten, ett\u00e4 k\u00e4ytett\u00e4v\u00e4 termi\n",
      "    j\u00e4\u00e4 n\u00e4kyviin. Muu osa tekstist\u00e4 on $i-osakentiss\u00e4. K\u00e4ytet\u00e4\u00e4n mm. kent\u00e4ss\u00e4 680\n",
      "    \n",
      "    TODO: Error handling\n",
      "    '''\n",
      "    merkkijono = [\"$i\"]\n",
      "    in_a_yso = False\n",
      "    ended_a_yso = False\n",
      "    \n",
      "    def initialize(self):\n",
      "        self.merkkijono = [\"$i\"]\n",
      "        self.in_a_yso = False\n",
      "        self.ended_a_yso = False\n",
      "    \n",
      "    def handle_starttag(self, tag, attrs):\n",
      "        if tag == \"a\":\n",
      "            for attr in attrs:\n",
      "                if attr[0] == \"href\":\n",
      "                    link = attr[1]\n",
      "                    if link.startswith(YSO):\n",
      "                        self.in_a_yso = True\n",
      "                        self.merkkijono[-1] = self.merkkijono[-1].rstrip()\n",
      "                        self.merkkijono.append(\"$a\")\n",
      "                        return\n",
      "        \n",
      "        self.merkkijono.append(\"<\" + tag)\n",
      "        for attr in attrs:\n",
      "            self.merkkijono.append(\" \" + attr[0] + \"='\" + attr[1] + \"'\")\n",
      "        \n",
      "        self.merkkijono.append(\">\")\n",
      "        \n",
      "    def handle_endtag(self, tag):\n",
      "        if tag == \"a\" and self.in_a_yso:\n",
      "            self.in_a_yso = False\n",
      "            self.ended_a_yso = True\n",
      "        else:\n",
      "            self.merkkijono.append(\"</\" + tag + \">\")\n",
      "        \n",
      "        \n",
      "    def handle_data(self, data):\n",
      "        if self.ended_a_yso:\n",
      "            self.merkkijono.append(\"$i\")\n",
      "            self.ended_a_yso = False\n",
      "        \n",
      "        # korjaa normaalit tekstiss\u00e4 olevien '<'-merkkien k\u00e4sittelyn\n",
      "        if self.merkkijono[-1] != \"$i\" and self.merkkijono[-1] != \"$a\":\n",
      "            self.merkkijono[-1] += data\n",
      "        else:\n",
      "            # tavallinen tapaus - lis\u00e4t\u00e4\u00e4n vain k\u00e4sitelty teksti uuteen osioon\n",
      "            self.merkkijono.append(data)\n",
      "        \n",
      "\n",
      "    def handle_comment(self, data):\n",
      "        self.merkkijono.append(data)\n",
      "\n",
      "    def handle_entityref(self, name):\n",
      "        #c = chr(name2codepoint[name])\n",
      "        self.merkkijono.append(name)\n",
      "\n",
      "    def handle_charref(self, name):\n",
      "        #if name.startswith('x'):\n",
      "        #    c = chr(int(name[1:], 16))\n",
      "        #else:\n",
      "        #    c = chr(int(name))\n",
      "        self.merkkijono.append(name)\n",
      "\n",
      "    def handle_decl(self, data):\n",
      "        self.merkkijono.append(data)\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 9
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def convert(language, outputfilename, ignoreOtherGraphs=True, keepDeprecated=False, lcshDirectory=None):\n",
      "    # keepDeprecated: False tarkoittaa, ett\u00e4 EI haluta, ja TRUE, ett\u00e4 halutaan\n",
      "    # vanhennetut k\u00e4sitteet lopputulokseen, jos niiden deprekointip\u00e4iv\u00e4 on DEPRECATIONLIMITn j\u00e4lkeen.\n",
      "    #NORMALIZATION_FORM = \"NFD\"\n",
      "    g = globals()[\"graphi\"]\n",
      "    g2 = globals()[\"other_graphs\"]\n",
      "    DEFAULTCREATIONDATE = datetime.date(datetime.strptime(globals()[\"DEFAULTCREATIONDATE\"], \"%Y-%m-%d\"))\n",
      "    #DEFAULTCREATIONDATE = datetime.date(DEFAULTCREATIONDATE)\n",
      "    DEPRECATIONLIMIT = datetime.date(datetime.strptime(globals()[\"DEPRECATIONLIMIT\"], \"%Y-%m-%d\"))\n",
      "    #DEPRECATIONLIMIT = datetime.date(DEPRECATIONLIMIT)\n",
      "    print(\"Processing '%s' language\" % (language))\n",
      "    incrementor = 0\n",
      "    ysoATagParser = ConvertHTMLYSOATags()\n",
      "    ET_namespaces = {\"marcxml\": \"http://www.loc.gov/MARC21/slim\"}\n",
      "\n",
      "    writer = XMLWriter(open(outputfilename + \"MARC-\" + language + \".mrcx\", 'wb'))\n",
      "    # for concept (a skos:Concept) in graph\n",
      "    for concept in sorted(g.subjects(RDF.type, SKOS.Concept)):\n",
      "        incrementor += 1\n",
      "        if incrementor % 1000 == 0:\n",
      "            print(\"Processing %sth concept\" % incrementor)\n",
      "        \n",
      "        # if deprecated, skip\n",
      "        if not keepDeprecated and (concept, OWL.deprecated, Literal(True)) in g:\n",
      "            continue\n",
      "        \n",
      "        rec = Record()   \n",
      "        deprecatedString = \"\"\n",
      "        # Organisaation ISIL-tunniste -> 003\n",
      "        rec.add_field(\n",
      "            Field(\n",
      "                tag='003',\n",
      "                data = CREATOR_AGENCY\n",
      "            )\n",
      "        )\n",
      "        # dct:modified -> 005 EI TULOSTETA, 688 \n",
      "        # tutkitaan, onko k\u00e4site muuttunut vai alkuper\u00e4inen\n",
      "        # ja valitaan leader sen perusteella\n",
      "        mod = g.value(concept, DCT.modified, None)\n",
      "        if mod is None:\n",
      "            rec.leader = LEADERNEW\n",
      "        else:\n",
      "            rec.leader = LEADERCHANGED\n",
      "            modified = mod.toPython() # datetime.date or datetime.datetime object\n",
      "            \n",
      "        # dct:created -> 008\n",
      "        crt = g.value(concept, DCT.created, None)\n",
      "        if crt is None:\n",
      "            if NODEFAULTCREATIONDATE:\n",
      "                try:\n",
      "                    del created\n",
      "                except UnboundLocalError:\n",
      "                    pass\n",
      "            else:\n",
      "                #created = datetime.date(DEFAULTCREATIONDATE)\n",
      "                created = DEFAULTCREATIONDATE\n",
      "        else:\n",
      "            created = crt.toPython() # datetime.date or datetime.datetime object\n",
      "        \n",
      "        code = CATALOGCODES\n",
      "        \n",
      "        for conceptType in g.objects(concept, RDF.type):\n",
      "            if conceptType in GROUPINGCLASSES:\n",
      "                code = CATALOGCODES_NA\n",
      "                break\n",
      "        if (concept, OWL.deprecated, Literal(True)) in g:\n",
      "            \n",
      "            replacers = sorted(g.objects(concept, DCT.isReplacedBy))\n",
      "            if len(replacers) == 0:\n",
      "                rec.leader = LEADERDELETED0\n",
      "            elif len(replacers) == 1:\n",
      "                rec.leader = LEADERDELETED1\n",
      "            else:\n",
      "                rec.leader = fallback=LEADERDELETED2\n",
      "            \n",
      "            code = CATALOGCODES_NA\n",
      "            # mik\u00e4li scopeNote puuttuu, poistettu tulkitaan uudeksi poistoksi ja se tulkitaan\n",
      "            # \"ylitt\u00e4v\u00e4n\" DEPRECATIONLIMITn.\n",
      "            for valueProp in sorted(getValues(g, concept, SKOS.scopeNote, language=\"\"),\n",
      "                                                       key=lambda o: str(o.value)):    \n",
      "                if valueProp.value.startswith(\"deprecated on\"):\n",
      "                    deprecatedString = str(valueProp.value)\n",
      "                    break\n",
      "            if deprecatedString:\n",
      "                try:\n",
      "                    deprecatedDate = datetime.date(datetime.strptime(deprecatedString.split(\" \")[-1], \"%d.%m.%Y\"))\n",
      "                    if DEPRECATIONLIMIT > deprecatedDate:\n",
      "                        continue # skipataan ennen vanhentamisrajaa vanhennetut termit\n",
      "                except ValueError as e:\n",
      "                    print(\"WARNING: Converting deprecated date failed for concept %s. Proceeding.\" %\n",
      "                      (concept), sys.stderr)\n",
      "        try:\n",
      "            rec.add_field(\n",
      "                Field(\n",
      "                    tag='008',\n",
      "                    data=created.strftime('%y%m%d') + code\n",
      "                )\n",
      "            )\n",
      "        except UnboundLocalError:\n",
      "            rec.add_field(\n",
      "                Field(\n",
      "                    tag='008',\n",
      "                    data=DEFAULTCREATIONDATE.strftime('%y%m%d') + code\n",
      "                )\n",
      "            )\n",
      "            if NODEFAULTCREATIONDATE:\n",
      "                created = None\n",
      "                \n",
      "            else:\n",
      "                print(\"WARNING: No creation date defined for concept %s.\" % (concept))\n",
      "        except AttributeError:\n",
      "            print(\"WARNING: could not convert date to another format: Concept %s, value: %s\" %\n",
      "                 (concept, created))\n",
      "            rec.add_field(\n",
      "                Field(\n",
      "                    tag='008',\n",
      "                    data=DEFAULTCREATIONDATE.strftime('%y%m%d') + code\n",
      "                )\n",
      "            )\n",
      "        \n",
      "        # 024 muut standarditunnukset - k\u00e4sitteen URI tallennetaan t\u00e4h\u00e4n\n",
      "        rec.add_field(\n",
      "            Field(\n",
      "                tag='024',\n",
      "                indicators = ['7', ' '],\n",
      "                subfields = [\n",
      "                    'a', concept,\n",
      "                    '2', \"uri\"\n",
      "                ]\n",
      "            )\n",
      "        )\n",
      "        \n",
      "        # 034 paikkojen koordinaatit - yso-paikat?\n",
      "        # 035 yso-tietueen numero?\n",
      "        \n",
      "        # 040 luetteloiva organisaatio\n",
      "        # TODO: tarkista miten vocabcode merkit\u00e4\u00e4n muille kuin YSOlle, muista my\u00f6s muut kent\u00e4t\n",
      "        # Jarmo: ei kielikoodia muille sanastoille?\n",
      "        rec.add_field(\n",
      "            Field(\n",
      "                tag='040',\n",
      "                indicators = [' ', ' '],\n",
      "                subfields = [\n",
      "                    'a', CREATOR_AGENCY,\n",
      "                    'b', LANGUAGES[language],\n",
      "                    #'e', \"rda\",\n",
      "                    'f', VOCABCODE + \"/\" + LANGUAGES[language]\n",
      "                ]\n",
      "            )\n",
      "        )\n",
      "        # 043 - ysopaikat, kaytetaanko\n",
      "        # http://marc21.kansalliskirjasto.fi/aukt/01X-09X.htm#043\n",
      "        \n",
      "        # 045 - yso-ajanjaksot, kaytetaanko\n",
      "        # http://marc21.kansalliskirjasto.fi/aukt/01X-09X.htm#045\n",
      "        \n",
      "        # 046 - erikoiskoodatut ajanjaksot? \n",
      "        \n",
      "        # 052 - maantieteellinen luokitus\n",
      "        # 7#$a(480)$2udc$0http://udcdata.info/004604\n",
      "        # jos 151 kaytossa, pitaisiko kayttaa? Jarmo: UDC-luokitus, Suomi \"(480)\"\n",
      "        \n",
      "        #ConceptGroup / skos:member -> 065 yso-aihealuekoodi\n",
      "        # vain siina tapauksessa, kun ne halutaan mukaan Asteriin\n",
      "        # jos luokkanumeroa ei l\u00f6ydy, ei tulosteta\n",
      "        # TODO: vain jos VOCABCODE = \"yso\", tehd\u00e4\u00e4n t\u00e4m\u00e4\n",
      "        if VOCABCODE == \"yso\":\n",
      "            for group in sorted(g.subjects(SKOS.member, concept)):\n",
      "                if not keepDeprecated and (group, OWL.deprecated, Literal(True)) in g:\n",
      "                    continue # skip deprecated group concepts\n",
      "                if (group, RDF.type, ISOTHES.ConceptGroup) not in g:\n",
      "                    #print(\"Not ISOTHES.ConceptGroup\", concept)\n",
      "                    continue\n",
      "                # group code: first try using skos:notation, otherwise extract from label\n",
      "                groupno = g.value(group, SKOS.notation, None)\n",
      "                if groupno is None:\n",
      "                    valueProps = sorted(getValues(g, group, SKOS.prefLabel, language=language),\n",
      "                                       key=lambda o: o.value)\n",
      "\n",
      "                    if len(valueProps) == 0: \n",
      "                        print(\"WARNING: Couldn't find preflabel for target %s in language: %s. Skipping property %s target for concept %s.\" %\n",
      "                          (group, language, SKOS.member, concept), sys.stderr)\n",
      "                        continue\n",
      "                    elif len(valueProps) != 1:\n",
      "                        print(\"WARNING: Multiple prefLabels detected for concept %s in language %s. Taking the first only.\" %\n",
      "                          (concept, language), sys.stderr) \n",
      "                    groupname = str(valueProps[0].value)\n",
      "                    try:\n",
      "                        groupno = str(groupname[0:groupname.index(\" \")])\n",
      "                        groupname = str(groupname[len(groupno) + 1:])\n",
      "                    except ValueError:\n",
      "                        print(\"WARNING: Tried to parse group number for group %s from preflabel %s in language %s but failed.\" %\n",
      "                          (group, language), sys.stderr)\n",
      "                        continue\n",
      "\n",
      "                rec.add_field(\n",
      "                    Field(\n",
      "                           tag='065',\n",
      "                           indicators = [' ', ' '],\n",
      "                           subfields = [\n",
      "                               'a', groupno,\n",
      "                               'c', decomposed\u00c5\u00c4\u00d6toUnicodeCharacters(unicodedata.normalize(NORMALIZATION_FORM, groupname)),\n",
      "                               #'c', groupname,\n",
      "                               '0', group,\n",
      "                               '2', VOCABCODE\n",
      "                           ]\n",
      "                    )\n",
      "                )\n",
      "        \n",
      "        # 080 - UDK-luokka. Asiasanaan liittyva UDK-luokka\n",
      "        \n",
      "        # 147 Tapahtuman nimi. Ei kayteta?\n",
      "        \n",
      "        # 148 Aikaa merkitseva termi. Selvitetaan.\n",
      "        \n",
      "        # skos:prefLabel -> 150 aihetta ilmaiseva termi\n",
      "        valueProps = sorted(getValues(g, concept, SKOS.prefLabel, language=language),\n",
      "                                   key=lambda o: o.value)\n",
      "        if len(valueProps) == 0:\n",
      "            print(\"WARNING: Couldn't find preflabel for concept %s in language %s. Skipping the whole concept.\" %\n",
      "              (concept, language), sys.stderr)\n",
      "            continue\n",
      "        elif len(valueProps) != 1:\n",
      "            print(\"WARNING: Multiple prefLabels detected for concept %s in language %s. Choosing the first.\" %\n",
      "                  (concept, language), sys.stderr) \n",
      "        #for prefLabel in prefLabels:\n",
      "        # TODO: tunnista kasitteen tyyppi, aika, yleinen, paikka, genre\n",
      "        # -> 148, 150, 151, 155, 162\n",
      "        tag = \"150\"\n",
      "        if (concept, SKOS.inScheme, YSO.places) in g:\n",
      "            tag = \"151\"\n",
      "        elif VOCABCODE == \"slm\":\n",
      "            tag = \"155\"\n",
      "\n",
      "        rec.add_field(\n",
      "            Field(\n",
      "                tag=tag,\n",
      "                indicators = [' ', ' '],\n",
      "                subfields=[\n",
      "                            'a', decomposed\u00c5\u00c4\u00d6toUnicodeCharacters(unicodedata.normalize(NORMALIZATION_FORM, str(valueProps[0].value)))\n",
      "                            #'a', str(valueProps[0].value)\n",
      "                          ]\n",
      "            )\n",
      "        )\n",
      "        \n",
      "        # skos:altLabel -> 447, 448, 450, 451, 455\n",
      "        #450 katso-viittaus\n",
      "        # poistetaan toisteiset skos:hiddenLabelit\n",
      "        seen_values = set()\n",
      "        for valueProp in sorted(getValues(g, concept, [SKOS.altLabel, YSOMETA.singularPrefLabel,\n",
      "                                                YSOMETA.singularAltLabel, SKOS.hiddenLabel], language=language),\n",
      "                                key=lambda o: str(o.value)): \n",
      "\n",
      "            if valueProp.prop == SKOS.hiddenLabel:\n",
      "                if str(valueProp.value) in seen_values:\n",
      "                    continue\n",
      "            seen_values.add(str(valueProp.value))\n",
      "            \n",
      "            tag = \"450\"\n",
      "            if (concept, SKOS.inScheme, YSO.places) in g:\n",
      "                tag = \"451\"\n",
      "            elif VOCABCODE == \"slm\":\n",
      "                tag = \"455\"\n",
      "\n",
      "            rec.add_field(\n",
      "                Field(\n",
      "                    tag = tag,\n",
      "                    indicators = [' ', ' '],\n",
      "                    subfields = [\n",
      "                        #'i', TERMGROUP[valueProp.prop][language],\n",
      "                        'a', decomposed\u00c5\u00c4\u00d6toUnicodeCharacters(unicodedata.normalize(NORMALIZATION_FORM, str(valueProp.value)))\n",
      "                        #'a', str(valueProp.value)\n",
      "                    ]\n",
      "                )\n",
      "            )\n",
      "        \n",
      "        # broader/narrower/related/successor/predecessor/skosext:partOf\n",
      "        # -> 550 \"katso myos\" viittaus\n",
      "        # HUOM: Objektit vain olioita\n",
      "        # TODO: ysoon lis\u00e4t\u00e4\u00e4n my\u00f6hemmin partOf-suhteiden k\u00e4\u00e4nteinen suhde\n",
      "        # TODO: useat erityyppiset i-kent\u00e4t eiv\u00e4t toimi t\u00e4ll\u00e4 hetkell\u00e4\n",
      "        fields = list()\n",
      "        for prop, wval in SEEALSOPROPS.items():\n",
      "            for target in sorted(g.objects(concept, prop)):\n",
      "                if not keepDeprecated and (target, OWL.deprecated, Literal(True)) in g:\n",
      "                    continue # skip deprecated concepts\n",
      "                \n",
      "                valueProps = getValues(g, target, SKOS.prefLabel, language=language)\n",
      "                if len(valueProps) == 0:\n",
      "                    print(\"WARNING: Couldn't find preflabel for target %s in language %s. Skipping the whole concept.\" %\n",
      "                      (target, language), sys.stderr)\n",
      "                    continue;\n",
      "                elif len(valueProps) != 1:\n",
      "                    print(\"WARNING: Multiple prefLabels detected for target %s in language %s. Choosing the first.\" %\n",
      "                          (target, language), sys.stderr) \n",
      "                label = valueProps[0].value\n",
      "                \n",
      "                tag = \"550\" # alustetaan 550-arvoon\n",
      "                if (target, SKOS.inScheme, YSO.places) in g:\n",
      "                        tag = \"551\"\n",
      "                elif VOCABCODE == \"slm\":\n",
      "                    tag = \"555\"\n",
      "                \n",
      "                subfields = []\n",
      "                \n",
      "                if wval == \"i\":\n",
      "                    if (target, SKOS.inScheme, YSO.places) in g:\n",
      "                        if prop == SKOSEXT.partOf:\n",
      "                            subfields.extend(('w', 'g'))\n",
      "                        elif prop == SKOSEXT.hasPart:\n",
      "                            subfields.extend(('w', 'h'))\n",
      "                        else:\n",
      "                            subfields.extend(('w', wval,\n",
      "                                     \"i\", TRANSLATIONS[prop][language]\n",
      "                                    ))\n",
      "                    else:\n",
      "                        subfields.extend(('w', wval,\n",
      "                                     \"i\", TRANSLATIONS[prop][language]\n",
      "                                    ))\n",
      "                else:\n",
      "                    # yso-paikoissa on sek\u00e4 ISOTHES.broaderPartitive, ett\u00e4\n",
      "                    # SKOS.broader redundanttina, j\u00e4tet\u00e4\u00e4n j. pois\n",
      "                    # samoin ISOTHES.narrowerPartitive - SKOS.narrower\n",
      "                    if (target, SKOS.inScheme, YSO.places) in g and \\\n",
      "                        (prop == SKOS.broader or prop == SKOS.narrower):\n",
      "                        continue\n",
      "                    subfields.extend(('w', wval))\n",
      "                \n",
      "                subfields.extend(('a', \n",
      "                                  decomposed\u00c5\u00c4\u00d6toUnicodeCharacters(unicodedata.normalize(NORMALIZATION_FORM, str(label)))\n",
      "                                  #str(label)\n",
      "                                 ))\n",
      "                subfields.extend(('0', target))\n",
      "                \n",
      "                #rec.add_field(\n",
      "                fields.append(\n",
      "                    Field(\n",
      "                        tag = tag,\n",
      "                        indicators = [' ', ' '],\n",
      "                        subfields = subfields\n",
      "                    )\n",
      "                )\n",
      "        # sort fields and add them\n",
      "        for sorted_field in sorted(fields, key=lambda o: (\n",
      "            o.tag, \n",
      "            SORT_5XX_W_ORDER[o.get_subfields(\"w\")[0]] if o.get_subfields(\"w\") else \"999\",\n",
      "            o.get_subfields('a')[0]\n",
      "            )):\n",
      "            rec.add_field(sorted_field)\n",
      "        \n",
      "        # key = o.value().lower()\n",
      "        #unsorted_fields.sort(key= lambda f: f.value() )\n",
      "        \n",
      "        # TODO: JS: laitetaan 667 kentt\u00e4\u00e4n SLM:n k\u00e4siteskeemat jokaiselle k\u00e4sitteelle\n",
      "        \n",
      "        # dc:source -> 670 kasitteen tai kuvauksen lahde\n",
      "        # tulostetaan termin kielen mukaan samankieliset l\u00e4hteet\n",
      "        # mik\u00e4li kielikoodilla ei ole propertille arvoa, ohjelma ei tulosta t\u00e4t\u00e4 kentt\u00e4\u00e4\n",
      "        # voidaanko tunnistaa, onko lahteessa URI, jolloin\n",
      "        # $u-osakenttaan laitetaan URI\n",
      "        # 4.5.2018 - palataan my\u00f6hemmin t\u00e4h\u00e4n\n",
      "        # JS: 6.8.2018 - usein pelkk\u00e4 l\u00e4hdeviittaus, jolloin kielell\u00e4 ei merkityst\u00e4\n",
      "        for valueProp in sorted(getValues(g, concept, DC.source, language=language),\n",
      "                                key=lambda o: str(o.value)):\n",
      "            subfields = [\n",
      "                'a',\n",
      "                decomposed\u00c5\u00c4\u00d6toUnicodeCharacters(unicodedata.normalize(NORMALIZATION_FORM, str(valueProp.value)))\n",
      "                #str(valueProp.value)\n",
      "            ]\n",
      "            # TODO: linkkien koodaus tarkistetaan/tehd\u00e4\u00e4n my\u00f6hemmin\n",
      "            #urls = getURLs(valueProp.value)\n",
      "            #for url in urls:\n",
      "            #    subfields.append(\"u\")\n",
      "            #    subfields.append(url)\n",
      "                \n",
      "            rec.add_field(\n",
      "                Field(\n",
      "                    tag='670',\n",
      "                    indicators = [' ', ' '],\n",
      "                    subfields = subfields\n",
      "                )\n",
      "            )\n",
      "        # skos:definition -> 677 huomautus maaritelmasta\n",
      "        # maaritelman lahde voidaan merkita osakenttaan $v\n",
      "        # sita varten tulee sopia tavasta merkita tama lahde, jotta\n",
      "        # se voidaan koneellisesti erottaa tekstista\n",
      "        # JS ehdottaa: jos tekstissa on merkkijono \". Lahde: \",\n",
      "        # kaikki sen perassa oleva teksti merkitaan osakenttaan $v\n",
      "        # enta jos linkki lahteen perassa?\n",
      "        # JS ehdottaa: linkki aivan viimeisena sanana\n",
      "        # 4.5.2018 - palataan my\u00f6hemmin t\u00e4h\u00e4n\n",
      "        # 6.8.2018 - ei viel\u00e4 k\u00e4sitelty\n",
      "        # 5.9.2018 - m\u00e4\u00e4ritelm\u00e4n l\u00e4hde tulee m\u00e4\u00e4ritelm\u00e4n j\u00e4lkeen kahdella tavuviivalla (--) erotettuna\n",
      "        # j\u00e4tet\u00e4\u00e4n toistaiseksi paikalleen (13 kpl)\n",
      "        for valueProp in sorted(getValues(g, concept, SKOS.definition, language=language),\n",
      "                                key=lambda o: str(o.value)):\n",
      "            subfields = [\n",
      "                'a', \n",
      "                decomposed\u00c5\u00c4\u00d6toUnicodeCharacters(unicodedata.normalize(NORMALIZATION_FORM, str(valueProp.value)))\n",
      "                #str(valueProp.value)\n",
      "            ]\n",
      "            # TODO: linkkien koodaus tarkistetaan/tehd\u00e4\u00e4n my\u00f6hemmin\n",
      "            #urls = getURLs(valueProp.value)\n",
      "            #for url in urls:\n",
      "            #    subfields.append(\"u\")\n",
      "            #    subfields.append(url)\n",
      "                \n",
      "            rec.add_field(\n",
      "                Field(\n",
      "                    tag='677',\n",
      "                    indicators = [' ', ' '],\n",
      "                    subfields = subfields\n",
      "                )\n",
      "            )\n",
      "        \n",
      "        # skos:note -> 680 yleinen huomautus, julkinen\n",
      "        for valueProp in sorted(getValues(g, concept, [SKOS.note, SKOS.scopeNote, SKOS.example], language=language),\n",
      "                                key=lambda o: str(o.value)):\n",
      "            #if valueProp.value.lang != language:\n",
      "            #    continue\n",
      "            #if valueProp.prop == SKOS.hiddenLabel:\n",
      "            #    if str(valueProp.value) in seen_values:\n",
      "            #        continue\n",
      "            #seen_values.add(str(valueProp.value))\n",
      "            # 'a', str(valueProp.value),\n",
      "            # 'i', TERMGROUP[valueProp.prop][language]\n",
      "            \n",
      "            \n",
      "            if \"$\" in valueProp.value:\n",
      "                print(\"WARNING: A dollar sign was detected in %s predicate for concept %s!\" %\n",
      "                      (valueProp.prop, concept))\n",
      "            \n",
      "            ysoATagParser.initialize()\n",
      "            ysoATagParser.feed(valueProp.value)\n",
      "            \n",
      "            convertedTags = \"\".join(ysoATagParser.merkkijono)\n",
      "            convertedTags_split = convertedTags.split(\"$\")[1:]\n",
      "            convertedTags_split_last = convertedTags_split[-1]\n",
      "            convertedTags_last_string = convertedTags_split_last[1:].strip()\n",
      "            # poistetaan viimeinen i-t\u00e4gi, jos se on vain 1 merkin mittainen.\n",
      "            if convertedTags_split_last[0] == \"i\" and len(convertedTags_last_string) <= 1 and len(convertedTags_split) > 1:\n",
      "                convertedTags_split[-2] = convertedTags_split[-2] + convertedTags_last_string\n",
      "                convertedTags_split = convertedTags_split[:-1]\n",
      "            \n",
      "            subfield_values = []\n",
      "            \n",
      "            for subfield in convertedTags_split:\n",
      "                subfield_values.extend(\n",
      "                    (subfield[0], decomposed\u00c5\u00c4\u00d6toUnicodeCharacters(unicodedata.normalize(NORMALIZATION_FORM, subfield[1:].strip())))\n",
      "                    #(subfield[0], subfield[1:])\n",
      "                )\n",
      "\n",
      "            rec.add_field(\n",
      "                Field(\n",
      "                    tag='680',\n",
      "                    indicators = [' ', ' '],\n",
      "                    subfields = subfield_values\n",
      "                )\n",
      "            )\n",
      "        # mahdollinen deprekointitieto lis\u00e4t\u00e4\u00e4n erikseen\n",
      "        if deprecatedString:\n",
      "            rec.add_field(\n",
      "                Field(\n",
      "                    tag='680',\n",
      "                    indicators = [' ', ' '],\n",
      "                    subfields = ['i', deprecatedString]\n",
      "                )\n",
      "            )\n",
      "        # owl:deprecated -> 682 Huomautus poistetusta otsikkomuodosta\n",
      "        # Ohjaus uuteen/uusiin k\u00e4sitteisiin\n",
      "        # seuraaja-suhde\n",
      "        # a-kentt\u00e4\u00e4n seuraajan preflabel, 0-kentt\u00e4\u00e4n URI, i selite\n",
      "        # TODO: onko seuraajaa vai ei, lis\u00e4ksi mietitt\u00e4v\u00e4 deprekoidun k\u00e4sitteen\n",
      "        # tyyppi (onko hierarkia jne.). Deprekaattorin huomautusteksti\u00e4 kehitett\u00e4v\u00e4\n",
      "        # (kent\u00e4t mietitt\u00e4v\u00e4 uudelleen - EI skos:scopeNote kuten nyt on 4.5.2018)\n",
      "        if (concept, OWL.deprecated, Literal(True)) in g:\n",
      "            target = None\n",
      "            for target in sorted(g.objects(concept, DCT.isReplacedBy)):\n",
      "                if not keepDeprecated and (target, OWL.deprecated, Literal(True)) in g:\n",
      "                    continue # skip deprecated concepts\n",
      "                    \n",
      "                valueProps = getValues(g, target, SKOS.prefLabel, language=language)\n",
      "                if len(valueProps) > 1:\n",
      "                    print(\"WARNING: Multiple prefLabels detected for target %s in language %s. Choosing the first.\" %\n",
      "                      (target, language), sys.stderr) \n",
      "                elif len(valueProps) == 0:\n",
      "                    '''\n",
      "                    tryPrefLabelInOtherGraphs = getValues(g2, target, SKOS.prefLabel, language=language)\n",
      "                    if len(tryPrefLabelInOtherGraphs) > 0:\n",
      "                        if not keepDeprecated and (target, OWL.deprecated, Literal(True)) in g2:\n",
      "                            continue # skip deprecated concepts\n",
      "                        label = tryPrefLabelInOtherGraphs[0].value\n",
      "                    else:\n",
      "                        print(\"WARNING: Couldn't find preflabel for target %s in language: %s. Skipping property %s target for concept %s.\" %\n",
      "                          (target, language, DCT.isReplacedBy, concept), sys.stderr)\n",
      "                        continue # skip concepts with no preferred label\n",
      "                    '''\n",
      "                    \n",
      "                    print(\"WARNING: Couldn't find preflabel for target %s in language: %s. Skipping property %s target for concept %s.\" %\n",
      "                          (target, language, DCT.isReplacedBy, concept), sys.stderr)\n",
      "                    continue\n",
      "                label = valueProps[0].value\n",
      "                rec.add_field(\n",
      "                    Field(\n",
      "                        tag = '682',\n",
      "                        indicators = [' ', ' '],\n",
      "                        subfields = [\n",
      "                            'i', TRANSLATIONS[\"682iDEFAULT\"][language],\n",
      "                            'a', \n",
      "                            decomposed\u00c5\u00c4\u00d6toUnicodeCharacters(unicodedata.normalize(NORMALIZATION_FORM, str(label))),\n",
      "                            #str(label),\n",
      "                            '0', target\n",
      "                        ]\n",
      "                    )\n",
      "                )\n",
      "        \n",
      "        if created:\n",
      "            rec.add_field(\n",
      "                Field(\n",
      "                    tag = '688',\n",
      "                    indicators = [' ', ' '],\n",
      "                    subfields = [\n",
      "                        'a',  TRANSLATIONS[\"688aCREATED\"][language] + \": \" + created.strftime('%Y-%m-%d')\n",
      "                    ]\n",
      "                )\n",
      "            )\n",
      "        \n",
      "        if mod and modified:\n",
      "            rec.add_field(\n",
      "                Field(\n",
      "                    tag = '688',\n",
      "                    indicators = [' ', ' '],\n",
      "                    subfields = [\n",
      "                        'a', TRANSLATIONS[\"688aMODIFIED\"][language] + \": \" + modified.strftime('%Y-%m-%d')\n",
      "                    ]\n",
      "                )\n",
      "            )\n",
      "            try:\n",
      "                if type(modified) == datetime:\n",
      "                    if created > modified.date():\n",
      "                        print(\"WARNING: Created date later than modified for concept %s\" % concept)\n",
      "                else:\n",
      "                    if created > modified:\n",
      "                        print(\"WARNING: Created date later than modified for concept %s\" % concept)\n",
      "            except Exception:\n",
      "                print(\"Date comparison failed for concept %s\", concept)\n",
      "\n",
      "                        \n",
      "        # all skos:match*es -> 7XX linkkikenttiin\n",
      "        # halutaan linkit kaikkiin kieliversioihin\n",
      "        # YSOn erikieliset preflabelit tulevat t\u00e4nne\n",
      "        # graafit haetaan etukateen ohjelman muistiin ohjelman alussa\n",
      "        # haetaan api.dev.finto.fi/sparql -endpointista\n",
      "        # tarvittavat graafit: ysa, allars, yso, yso-paikat, lcsh\n",
      "        # miten LCSH haetaan? Yli 400 000 prefLabelia\n",
      "        # tarjotaan talla hetkella vain api.skosmos.dev.finto.fi:n kautta\n",
      "        # jolle ei paase ulkoa kasin ollenkaan.\n",
      "        # 750 $a label, $4 relaatiotyyppi, $2 sanastolahde, $0 uri\n",
      "        # miten $w? JS: ei oteta mukaan ollenkaan\n",
      "        # 2.5.2018-kokouksessa p\u00e4\u00e4tettiin, ett\u00e4 DCT.spatialia ei k\u00e4\u00e4nnet\u00e4\n",
      "        # MARC-muotoon\n",
      "        # 13.8.2018 LCSH k\u00e4sitell\u00e4\u00e4n erikseen; niille on tehty oma kansio, joka\n",
      "        # on tallennettu lcshDirectory-muuttujaan. Puuttuvat lcsh-linkit haetaan\n",
      "        # dynaamisesti tarvittaessa ja lis\u00e4t\u00e4\u00e4n kansioon\n",
      "        valueProps = getValues(g, concept, [SKOS.prefLabel, SKOS.exactMatch, SKOS.closeMatch,\n",
      "                                 SKOS.broadMatch, SKOS.narrowMatch, \n",
      "                                 SKOS.relatedMatch])\n",
      "        fields = list() # ker\u00e4t\u00e4\u00e4n kent\u00e4t t\u00e4h\u00e4n muuttujaan\n",
      "       \n",
      "        #sortedValueProps = sorted(valueProps, key=lambda o: getValuePropObjectPrefLabel(o, g2))\n",
      "        #for valueProp in sortedValueProps:\n",
      "        for valueProp in valueProps:\n",
      "            if valueProp.prop == SKOS.prefLabel:\n",
      "                # suodatetaan samankieliset, jotka meniv\u00e4t jo 1xx-kenttiin\n",
      "                # valueProp.value sis\u00e4lt\u00e4\u00e4 t\u00e4ss\u00e4 poikkeuksellisesti halutun literaalin\n",
      "                if valueProp.value.language == language:\n",
      "                    continue\n",
      "                matchURIRef = URIRef(concept)\n",
      "            else:\n",
      "                # tehd\u00e4\u00e4n osumasta URIRef \n",
      "                matchURIRef = URIRef(valueProp.value)\n",
      "                if not keepDeprecated and (matchURIRef, OWL.deprecated, Literal(True)) in g2:\n",
      "                    continue # skip deprecated matches\n",
      "\n",
      "            second_indicator = \"7\"\n",
      "            tag = \"750\"\n",
      "            loc_object = None \n",
      "            \n",
      "            if (matchURIRef, SKOS.inScheme, YSO.places) in g2 or \\\n",
      "            (matchURIRef, SKOS.inScheme, YSO.places) in g: #or matchType == DCT.spatial:\n",
      "                tag = \"751\"\n",
      "            # TODO: nimetyt graafit, kohdista kyselyt niihin?\n",
      "            # if we want to direct queries to spesific graphs, one per vocab, that graph\n",
      "            # needs to be selected here based on the void:uriSpace\n",
      "            \n",
      "            if matchURIRef.startswith(LCSH):\n",
      "                second_indicator = \"0\"\n",
      "                loc_object = {\"prefix\": str(LCSH), \"id\": matchURIRef.split(\"/\")[-1]}\n",
      "            elif matchURIRef.startswith(LCGF):\n",
      "                sub2 = \"lcgft\" \n",
      "                loc_object = {\"prefix\": str(LCGF), \"id\": matchURIRef.split(\"/\")[-1]}\n",
      "            elif matchURIRef.startswith(ALLARS):\n",
      "                if (matchURIRef, RDF.type, ALLARSMETA.GeographicalConcept) in g2: #or matchType == DCT.spatial:\n",
      "                    tag = \"751\"\n",
      "                sub2 = \"allars\"\n",
      "            elif matchURIRef.startswith(KOKO):\n",
      "                continue # skip KOKO concepts\n",
      "            elif matchURIRef.startswith(SLM):\n",
      "                tag = \"755\"\n",
      "                sub2 = \"slm\"\n",
      "            elif matchURIRef.startswith(YSA):\n",
      "                if (matchURIRef, RDF.type, YSAMETA.GeographicalConcept) in g2: #or matchType == DCT.spatial:\n",
      "                    tag = \"751\"\n",
      "                sub2 = \"ysa\"\n",
      "            elif matchURIRef.startswith(YSO):\n",
      "                sub2 = \"yso\"\n",
      "            else:\n",
      "                second_indicator = \"4\"\n",
      "                if not ignoreOtherGraphs:\n",
      "                    print(\"WARNING: Matched target %s did not belong to any known vocabulary\" % (str(matchURIRef)))\n",
      "                    # do not put subfield 2 in this case\n",
      "            \n",
      "            if not ((matchURIRef, None, None) in g or\n",
      "                (matchURIRef, None, None) in g2):\n",
      "                if not loc_object: \n",
      "                    print(\"WARNING: Matched target %s did not belong to any known vocabulary. Skipping.\" % (str(matchURIRef)))\n",
      "                    continue\n",
      "            \n",
      "            sub4 = \"\"\n",
      "            if valueProp.prop == SKOS.broadMatch:\n",
      "                sub4 = \"BM\"\n",
      "            elif valueProp.prop == SKOS.narrowMatch:\n",
      "                sub4 = \"NM\"\n",
      "            elif valueProp.prop == SKOS.exactMatch:\n",
      "                sub4 = \"EQ\"\n",
      "            elif valueProp.prop == SKOS.prefLabel:\n",
      "                sub4 = \"EQ\"\n",
      "                if sub2 == \"yso\" or sub2 == \"slm\":\n",
      "                    sub2 = sub2 + \"/\" + LANGUAGES[valueProp.value.language]\n",
      "                #rec.add_field(\n",
      "                fields.append(\n",
      "                    Field(\n",
      "                        tag=tag,\n",
      "                        indicators = [' ', second_indicator],\n",
      "                        subfields = [\n",
      "                            'a', \n",
      "                            decomposed\u00c5\u00c4\u00d6toUnicodeCharacters(unicodedata.normalize(NORMALIZATION_FORM, str(valueProp.value))),\n",
      "                            #str(valueProp.value),\n",
      "                            '4', sub4,\n",
      "                            '2', sub2,\n",
      "                            '0', concept\n",
      "                        ]\n",
      "                    )\n",
      "                )\n",
      "                continue\n",
      "            elif valueProp.prop == SKOS.closeMatch:\n",
      "                sub4 = \"~EQ\"\n",
      "            else:\n",
      "                sub4 = \"RM\"\n",
      "                \n",
      "            # library of congress -viitteet k\u00e4sitell\u00e4\u00e4n erikseen\n",
      "            if loc_object:\n",
      "                recordNode = None\n",
      "                local_lcsh_source = lcshDirectory + loc_object[\"id\"] + \".marcxml.xml\"\n",
      "                downloaded = False\n",
      "                try:\n",
      "                    #recordNode = lcshRecordNodes[loc_object[\"id\"]]\n",
      "                    with open(local_lcsh_source, encoding=\"utf-8\") as f:\n",
      "                        recordNode = ET.parse(f)\n",
      "                except OSError as e:\n",
      "                    # haetaan kongressin kirjastosta tarvittava tiedosto ja tallennetaan se\n",
      "                    try:\n",
      "                        with urllib.request.urlopen(loc_object[\"prefix\"] + loc_object[\"id\"] + \".marcxml.xml\") as marcxml, \\\n",
      "                            open(local_lcsh_source, 'wb') as out_file:\n",
      "                            shutil.copyfileobj(marcxml, out_file)\n",
      "                            print(\"INFO: Downloaded LCSH link to %s.\" %\n",
      "                                (local_lcsh_source))\n",
      "                            downloaded = True\n",
      "                    except urllib.error.URLError as e:\n",
      "                        print('WARNING: Unable to load the marcxml for %s. Reason: %s. Skipping the property for concept %s.' %\n",
      "                            (loc_object[\"id\"], e.reason, concept), sys.stderr)\n",
      "                    except OSError as e:\n",
      "                        print(\"WARNING: Failed to create a file for %s under %s directory. Skipping the property for concept %s.\" %\n",
      "                            (loc_object[\"id\"], lcshDirectory, concept), sys.stderr)\n",
      "                except ET.ParseError as e:\n",
      "                    print(\"WARNING: Failed to parse the following file: %s. Skipping the property for concept %s.\" %\n",
      "                            (local_lcsh_source, concept), sys.stderr)\n",
      "                \n",
      "                if downloaded:\n",
      "                    try:\n",
      "                        with open(local_lcsh_source, encoding=\"utf-8\") as f:\n",
      "                            recordNode = ET.parse(f)\n",
      "                    except OSError as e:\n",
      "                        print(\"WARNING: Failed to read the file for %s under %s directory. Skipping the property for concept %s\" %\n",
      "                            (loc_object[\"id\"], lcshDirectory, concept), sys.stderr)\n",
      "                    except ET.ParseError as e:\n",
      "                        print(\"WARNING: Failed to parse the following file: %s. Skipping the property for concept %s.\" %\n",
      "                            (local_lcsh_source, concept), sys.stderr)\n",
      "                            \n",
      "                \n",
      "                if recordNode:\n",
      "                    tagNode = None\n",
      "\n",
      "                    for tagNumber in LCSH_1XX_FIELDS:\n",
      "                        tagNode = recordNode.find(\"./marcxml:datafield[@tag='\" + tagNumber + \"']\", ET_namespaces)\n",
      "                        if tagNode:\n",
      "                            # otetaan ensimm\u00e4inen\n",
      "                            break\n",
      "\n",
      "                    if tagNode:\n",
      "                        tag = \"7\" + tagNode.attrib[\"tag\"][1:]\n",
      "                        first_indicator = tagNode.attrib[\"ind1\"]\n",
      "                        subfields = []\n",
      "\n",
      "                        for child in tagNode:\n",
      "                            subfields.extend((child.attrib[\"code\"], \n",
      "                                              decomposed\u00c5\u00c4\u00d6toUnicodeCharacters(unicodedata.normalize(NORMALIZATION_FORM, str(child.text)))\n",
      "                                              #str(child.text)\n",
      "                                 ))\n",
      "\n",
      "                        subfields.extend((\"4\", sub4))\n",
      "                        if second_indicator == \"7\":\n",
      "                            subfields.extend((\"2\", sub2))\n",
      "                        subfields.extend((\"0\", str(matchURIRef)))\n",
      "\n",
      "                        #rec.add_field(\n",
      "                        fields.append(\n",
      "                            Field(\n",
      "                                tag = tag,\n",
      "                                indicators = [first_indicator, second_indicator],\n",
      "                                subfields = subfields\n",
      "                            )\n",
      "                        )\n",
      "\n",
      "                    else:\n",
      "                        print(\"WARNING: Couldn't find any marcxml:datafield objects with a tag number in the following list: %s for the following record: %s. %s\" %\n",
      "                          (LCSH_1XX_FIELDS, loc_object[\"id\"], \"Skipping the property for concept \" + concept + \".\"), sys.stderr)\n",
      "                        #continue\n",
      "\n",
      "            else:\n",
      "                prefLabel = None\n",
      "                for type2, prefLabel in sorted(g2.preferredLabel(matchURIRef,\n",
      "                                        labelProperties=(SKOS.prefLabel,))):\n",
      "\n",
      "                    #TODO: Warn if many prefLabels for same language\n",
      "                    subfields = [\n",
      "                        'a', \n",
      "                        decomposed\u00c5\u00c4\u00d6toUnicodeCharacters(unicodedata.normalize(NORMALIZATION_FORM, str(prefLabel))),\n",
      "                        #str(prefLabel),\n",
      "                        '4', sub4\n",
      "                    ]\n",
      "                    \n",
      "                    if second_indicator != \"4\":\n",
      "                        subfields.append(\"2\")\n",
      "                        subfields.append(sub2)\n",
      "                    subfields.append(\"0\")\n",
      "                    subfields.append(str(matchURIRef))\n",
      "                    #subfields.append(\"9\")\n",
      "                    #try:\n",
      "                    #    subfields.append(LANGUAGES[prefLabel.language])\n",
      "                    #except KeyError:\n",
      "                    #    print(\"WARNING: LANGUAGES dictionary has no key for language '%s' found from %s skos:prefLabel. Skipping.\" %\n",
      "                    #      (prefLabel.language, matchURIRef), sys.stderr)\n",
      "                    #    continue\n",
      "\n",
      "                    #rec.add_field(\n",
      "                    fields.append(\n",
      "                        Field(\n",
      "                            tag=tag,\n",
      "                            indicators = [' ', second_indicator],\n",
      "                            subfields = [\n",
      "                                'a',\n",
      "                                decomposed\u00c5\u00c4\u00d6toUnicodeCharacters(unicodedata.normalize(NORMALIZATION_FORM, str(prefLabel))),\n",
      "                                #str(prefLabel),\n",
      "                                '4', sub4,\n",
      "                                '2', sub2 if sub2 not in [\"yso\", \"slm\"] else sub2 + \"/\" + LANGUAGES[prefLabel.language],\n",
      "                                '0', str(matchURIRef)\n",
      "                                #'9', LANGUAGES[prefLabel.language]\n",
      "                            ]\n",
      "                        )\n",
      "                    )\n",
      "\n",
      "\n",
      "                if not prefLabel and not ignoreOtherGraphs: \n",
      "                    print(\"WARNING: Couldn't find preflabel for target %s. Skipping property %s target for concept %s.\" %\n",
      "                      (str(matchURIRef), str(valueProp.prop), concept), sys.stderr)\n",
      "                    #continue\n",
      "        \n",
      "        # sort fields and add them\n",
      "        for sorted_field in sorted(fields, key=lambda o: (\n",
      "            o.tag,\n",
      "            o.value().lower()\n",
      "            )):\n",
      "            rec.add_field(sorted_field)\n",
      "\n",
      "        #for sorted_field in sorted(fields, key=lambda o: o.value().lower()):\n",
      "        #    rec.add_field(sorted_field)\n",
      "\n",
      "        # Konversion tiedot -> 884\n",
      "\n",
      "        tag = \"884\"\n",
      "        rec.add_field(\n",
      "                        Field(\n",
      "                            tag=tag,\n",
      "                            indicators = [' ', \" \"],\n",
      "                            subfields = [\n",
      "                                'a', CONVERSION_PROCESS,\n",
      "                                'u', CONVERSION_URI\n",
      "                            ]\n",
      "                        )\n",
      "                    )\n",
      "        writer.write(rec)\n",
      "\n",
      "    writer.close()\n",
      "    logging.info(\"Processed %s concepts in language '%s'\" % (incrementor, language))\n",
      "    logging.shutdown()\n",
      "    \n",
      "    #processCatmandu(language)\n",
      "    \n",
      "\n",
      "def processCatmandu(language=\"fi\", vocabulary=\"yso\"):\n",
      "    print(\"catmandu convert MARC --type XML to MARC --type XML <\" + vocabulary + \"MARC-\" + language + \n",
      "        \".mrcx | xmllint --format - >\" + vocabulary + \"MARC-\" + language + \"-formatted.mrcx\")\n",
      "    subprocess.run(\n",
      "        \"catmandu convert MARC --type XML to MARC --type XML <\" + vocabulary + \"MARC-\" + language + \n",
      "        \".mrcx | xmllint --format - >\" + vocabulary + \"MARC-\" + language + \"-formatted.mrcx\",\n",
      "        stdout=subprocess.PIPE, stderr=subprocess.PIPE, shell=True\n",
      "    )"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 16
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# aja generoidaksesi formatoitu versio tietynkielisesta filusta\n",
      "kieli = \"fi\"\n",
      "vocabulary = \"yso\"\n",
      "processCatmandu(kieli, vocabulary)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": null
    }
   ],
   "metadata": {}
  }
 ]
}